# Claude Code Instructions for LLM Evals tutorial

This project combines the **AI Dev Tasks** workflow with **Compound Engineering** principles for building an intelligent LLM evaluation tutorial.

## Project Philosophy

"Stop thinking in terms of files and functions. Start thinking about outcomes and delegation."

We use a structured approach:
1. **AI Dev Tasks**: PRD → Task List → Implementation with checkpoints
2. **Compound Engineering**: Orchestrate AI agents for parallel execution
3. **TDD First**: Write tests before implementation
4. **Quality Gates**: Ruff, pytest, and clear documentation

## Available Workflows

### AI Dev Tasks Workflow
- Use `@create-prd.md` to generate Product Requirement Documents
- Use `@generate-tasks.md` to break PRDs into actionable tasks
- Use `@process-task-list.md` to execute tasks with approval checkpoints

### Compound Engineering Commands
- `/explore` - Analyze and understand codebases
- `/issue` - Create GitHub issues with proper templates
- `/work` - Execute tasks from GitHub project board
- `/review` - Code review and quality checks
- `/test` - Run comprehensive test suites
- `/docs` - Generate and update documentation
- `/reflect` - Post-implementation analysis

### Project Maintenance Commands
- `/compress-claude` - Optimize CLAUDE.md by extracting verbose sections to modular files with `@` imports
  - `analyze` - Scan for compression opportunities (sections >100 lines)
  - `extract [section]` - Move content to `.claude/instructions/` with summary + import
  - `validate` - Test all imports resolve correctly
  - `revert [section]` - Undo extraction and restore original content

## Development Principles

**TDD & Defensive Coding:** @.claude/instructions/tdd-principles.md

**Quick Reference:**
1. **TDD Always:** Follow RED → GREEN → REFACTOR cycle
2. **Defensive Function Template:** Type checking → Input validation → Edge cases → Main logic → Return
3. **Test Naming:** `test_should_[expected_result]_when_[condition]()`

**For full TDD & defensive coding details:** @.claude/instructions/tdd-principles.md

2. **Parallel Execution**: Use Claude's Task tool for independent operations
3. **Clear Specifications**: Document requirements thoroughly before coding
4. **Quality First**: Ruff formatting, type hints, comprehensive tests
5. **User-Centric**: Focus on outcomes that matter to users
6. **Pattern Library**: Use documented patterns from `/patterns/` directory for consistent, maintainable code

## Project Structure

```
├── .claude/commands/     # Custom slash commands
├── src/                 # Source code (Bhagavad Gita chatbot)
├── tests/               # Test suite
├── tasks/               # AI Dev Tasks (PRDs and task lists)
├── patterns/            # Reusable code patterns documentation
│   ├── README.md               # Pattern library catalog
│   ├── tdd-workflow.md         # TDD pattern (RED→GREEN→REFACTOR)
│   ├── threadpool-parallel.md  # ThreadPoolExecutor concurrency pattern
│   └── abstract-base-class.md  # Abstract Base Class OOP pattern
├── analysis/            # Design docs and decisions
├── Gita/                # Bhagavad Gita datasets
│   ├── Bhagwat-Gita-Infinity/  # 737 verse JSON files with commentaries
│   └── Bhagavad-Gita-QA/       # 3,500 Q&A pairs for evaluation
├── data/                # Vector database storage
├── logs/                # Application logs
├── outputs/             # Generated outputs
├── create-prd.md        # AI Dev Tasks: PRD creation
├── generate-tasks.md    # AI Dev Tasks: Task generation
├── process-task-list.md # AI Dev Tasks: Task execution
├── env.example          # Environment configuration template
└── pyproject.toml       # Project configuration with all dependencies
```

## Pattern Library

This project includes a comprehensive **Pattern Library** documenting reusable code patterns for building robust, maintainable AI evaluation systems.

### Available Patterns

**Location:** `/patterns/` directory

**Quick Reference:**

| Pattern | Complexity | Use Case |
|---------|-----------|----------|
| [TDD Workflow](patterns/tdd-workflow.md) | ⭐⭐ | Testing & development methodology (RED→GREEN→REFACTOR) |
| [ThreadPoolExecutor Parallel](patterns/threadpool-parallel.md) | ⭐⭐⭐ | Concurrent batch processing for I/O-bound tasks |
| [Abstract Base Class](patterns/abstract-base-class.md) | ⭐⭐⭐ | OOP interface enforcement & polymorphism |

**When to use patterns:**

1. **TDD Workflow** - When building new features, refactoring code, or fixing bugs
   - Write tests BEFORE implementation
   - Follow RED (failing test) → GREEN (minimal code) → REFACTOR (improve quality)
   - Use test naming convention: `test_should_[result]_when_[condition]()`

2. **ThreadPoolExecutor Parallel** - When batch processing I/O-bound tasks
   - Processing multiple API calls, database queries, or file operations in parallel
   - Use `future_to_index` mapping to preserve result order
   - Include exception handling with fallbacks and `tqdm` progress tracking

3. **Abstract Base Class** - When creating frameworks with multiple implementations
   - Define common interface with `ABC` and `@abstractmethod`
   - Share functionality (retry logic, validation) in base class
   - Enforce contract: subclasses must call `super().__init__()` and implement abstract methods

**For AI Assistants (Claude Code):**

When generating code, check if a pattern applies and use the template from the pattern documentation. All patterns include:
- Copy-paste code templates with defensive coding
- Real examples from codebase with file:line references
- Common pitfalls and how to avoid them
- Integration with defensive coding principles

**See:** [Pattern Library README](patterns/README.md) for full documentation and contribution guidelines.

---

## Quality Standards

- **Line Length**: 120 characters (Ruff configuration)
- **Type Hints**: Required for all functions
- **Async/Await**: Preferred for I/O operations
- **Test Coverage**: Aim for 90%+ coverage
- **Documentation**: Keep CLAUDE.md updated with project patterns
- **Code Patterns**: Follow documented patterns from `/patterns/` directory

---

## Context Engineering Principles

**Core Thesis:**
> "Bigger models aren't enough. Intelligence emerges from orchestration."

This project implements **Context Engineering** - the discipline of managing what information gets included in an LLM's context window, how it's structured, and when it's retrieved.

### Critical Distinctions

**Before writing any context-aware code, read:** [google-context/TERMINOLOGY.md](google-context/TERMINOLOGY.md)

#### 1. Session History vs. Context Window

| Session History | Context Window |
|----------------|---------------|
| Full conversation log (50K tokens) | Curated subset sent to LLM (8K tokens) |
| Stored in database | Sent at inference time |
| Grows unbounded | Fixed size constraint |
| Raw material | Refined input |

**Example:**
```python
# ❌ WRONG: Sending entire session history
response = llm.generate(messages=session_history)  # 50K tokens!

# ✅ RIGHT: Compress and curate
context_window = session.get_context_window()  # 8K tokens
response = llm.generate(messages=context_window)
```

#### 2. Memory vs. RAG (Knowledge Retrieval)

| Memory | RAG |
|--------|-----|
| User-specific facts | General knowledge |
| "User prefers Sivananda translations" | "Chapter 3 discusses karma yoga" |
| Personal assistant | Research librarian |
| Cross-session persistence | Domain knowledge retrieval |

**Example:**
```python
# Memory: User-specific
memory = "User is beginner in Bhagavad Gita study"

# RAG: General knowledge
rag_result = "Chapter 2, Verse 47: You have right to work, not to fruits thereof"
```

#### 3. Proactive vs. Reactive Memory Retrieval

| Proactive | Reactive |
|-----------|----------|
| Auto-load memories into context | Agent tool call retrieves on-demand |
| Higher token usage | Lower token usage |
| No misses (memories always available) | Requires smart agent to know when to retrieve |
| Good for critical preferences | Good for optional enhancements |

### Protected Context Pattern

**Rule:** Events that must survive compression across long conversations.

**Protected Event Types:**
- **Turn 0**: Initial user objectives
- **`event_type == "constraint"`**: Explicit user constraints
- **`event_type == "auth_checkpoint"`**: Authentication state
- **Goal statements**: User's learning goals

**Code:**
```python
def identify_protected_context(event: dict[str, Any]) -> dict[str, Any]:
    """Identify if an event contains protected context.

    Args:
        event: Conversation event with turn, role, content, event_type

    Returns:
        Dict with is_protected flag and reason
    """
    # Step 1: Type checking (defensive)
    if not isinstance(event, dict):
        raise TypeError("event must be a dict")

    # Step 2: Check protection criteria
    event_type = event["event_type"]
    turn = event["turn"]

    # Initial objectives (turn 0)
    if turn == 0:
        return {"is_protected": True, "reason": "initial_objective"}

    # Explicit constraints
    if event_type == "constraint":
        return {"is_protected": True, "reason": "explicit_constraint"}

    # Authentication checkpoints
    if event_type == "auth_checkpoint":
        return {"is_protected": True, "reason": "authentication"}

    # Step 3: Default to not protected
    return {"is_protected": False, "reason": "compressible"}
```

**See:** [patterns/context-engineering-sessions.md](patterns/context-engineering-sessions.md)

### Memory Provenance (Mandatory)

**Rule:** Every memory must have full lineage tracking for audit and trustworthiness.

**Mandatory Metadata:**
```python
@dataclass
class MemoryProvenance:
    memory_id: str  # UUID
    source_session_id: str  # Which session extracted this
    extraction_timestamp: datetime  # When
    confidence_score: float  # 0.0-1.0
    validation_status: Literal["agent_inferred", "user_confirmed", "disputed"]
    confidence_history: list[dict[str, float | str]]  # Evolution over time
```

**Confidence Evolution Rules:**
- **user_confirmed**: +0.1 boost (capped at 1.0)
- **disputed**: -0.2 penalty (floored at 0.0)
- **agent_inferred**: No adjustment

**Example:**
```python
# Day 1: Agent infers preference
provenance = MemoryProvenance(
    memory_id="mem_123",
    source_session_id="sess_day1",
    extraction_timestamp=datetime.now(),
    confidence_score=0.7,
    validation_status="agent_inferred"
)

# Day 5: User confirms
provenance.add_confidence_update(0.9, "User confirmed")
provenance.validation_status = "user_confirmed"

# Effective confidence: 0.9 + 0.1 = 1.0 (boost for user_confirmed)
print(provenance.effective_confidence)  # 1.0
```

**See:** [patterns/context-engineering-memory.md](patterns/context-engineering-memory.md)

### PII Redaction for Spiritual Context

**Rule:** Redact personally identifiable information while preserving spiritual/emotional context.

**What to Redact:**
- Emails: `john@example.com` → `[EMAIL_REDACTED]`
- Phone numbers: `555-1234` → `[PHONE_REDACTED]`
- Full names: `John Smith` → `[NAME_REDACTED]`
- Addresses: `123 Main Street` → `[LOCATION_REDACTED]`

**What NOT to Redact (Whitelist):**
- Bhagavad Gita characters: Arjuna, Krishna, Sanjaya
- Philosophical terms: Brahman, Atman, Karma, Dharma
- Emotional context: anxiety, fear, confusion
- Situational context: job interview, family conflict

**Code:**
```python
class PIIRedactor:
    def __init__(self) -> None:
        self.email_pattern = re.compile(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b')
        self.phone_pattern = re.compile(r'\b(\+?\d{1,3}[-.\s]?)?\(?\d{3}\)?[-.\s]?\d{3,4}[-.\s]?\d{4}\b')
        self.name_pattern = re.compile(r'\b[A-Z][a-z]+ (?:[A-Z]\. )?[A-Z][a-z]+\b')

        # Whitelist for Gita characters and terms
        self.whitelist = {"Arjuna", "Krishna", "Brahman", "Karma", "Dharma"}

    def redact(self, text: str) -> tuple[str, bool]:
        pii_found = False
        redacted_text = text

        # Redact emails, phones, locations
        if self.email_pattern.search(redacted_text):
            redacted_text = self.email_pattern.sub("[EMAIL_REDACTED]", redacted_text)
            pii_found = True

        # Redact names (with whitelist check)
        for name in self.name_pattern.findall(redacted_text):
            if name not in self.whitelist:
                redacted_text = redacted_text.replace(name, "[NAME_REDACTED]")
                pii_found = True

        return redacted_text, pii_found
```

**Example:**
```python
user_message = "I'm John Smith at john@email.com. I'm anxious about my job interview. Can Krishna's teachings help?"

redactor = PIIRedactor()
redacted, pii_found = redactor.redact(user_message)

# Result:
# "[NAME_REDACTED] at [EMAIL_REDACTED]. I'm anxious about my job interview. Can Krishna's teachings help?"
# Krishna preserved (whitelist), John Smith redacted, emotional context preserved
```

### Implementation Checklist

When implementing context-aware AI systems:

- [ ] **Read terminology first**: [google-context/TERMINOLOGY.md](google-context/TERMINOLOGY.md)
- [ ] **Sessions pattern**: Compress at 95% threshold, protect turn 0 and constraints
- [ ] **Memory provenance**: Track source_session_id, confidence_score, validation_status
- [ ] **PII redaction**: Redact identifiers, preserve domain-specific terms (whitelist)
- [ ] **Confidence evolution**: Implement boost/penalty rules for validation status
- [ ] **Token efficiency**: Target 6x reduction (50K → 8K) while preserving intelligence
- [ ] **Test coverage**: ≥90% for sessions and memory modules

### Learning Resources

**Quick Start (30 minutes):**
1. Read [TERMINOLOGY.md](google-context/TERMINOLOGY.md) - Critical distinctions
## Context Engineering Principles

**Full Documentation:** @.claude/instructions/context-engineering.md

**Core Thesis:** Intelligence emerges from orchestration, not just bigger models.

**Quick Reference:**
1. **Session History vs. Context Window:** Full conversation log (50K) vs. curated subset (8K)
2. **Memory vs. RAG:** User-specific facts vs. general knowledge retrieval
3. **Protected Context:** Turn 0, constraints, auth checkpoints must survive compression
4. **Memory Provenance:** Track source_session_id, confidence_score, validation_status
5. **PII Redaction:** Redact identifiers, preserve domain-specific terms (whitelist)

**Implementation Checklist:**
- [ ] Sessions pattern: Compress at 95% threshold, protect turn 0
- [ ] Memory provenance: Full lineage tracking with confidence evolution
- [ ] PII redaction: Email, phone, names → preserve Gita characters
- [ ] Token efficiency: Target 6x reduction (50K → 8K)
- [ ] Test coverage: ≥90% for sessions and memory modules

**For full context engineering details:** @.claude/instructions/context-engineering.md

