{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Perplexity Calculation Tutorial\n",
        "\n",
        "**Execution Time:** <3 minutes\n",
        "**Cost:** $0 (uses pre-calculated data)\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "- Calculate perplexity from cross-entropy\n",
        "- Visualize perplexity vs model size\n",
        "- Detect data contamination using perplexity analysis\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- Completed `language_modeling_metrics.md`\n",
        "- Basic Python and matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Setup: Import libraries\n",
        "import json\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"\u2705 Setup complete\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Pre-calculated Perplexity Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Load sample perplexity results\n",
        "with open('data/sample_perplexity_results.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "models = data['models']\n",
        "print(f\"Loaded data for {len(models)} models:\")\n",
        "for model in models:\n",
        "    print(f\"  - {model['model_name']} ({model['parameters']})\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Calculate Perplexity from Cross-Entropy\n",
        "\n",
        "Formula: `Perplexity = 2^(Cross-Entropy in bits)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "def calculate_perplexity(cross_entropy_bits: float) -> float:\n",
        "    \"\"\"Calculate perplexity from cross-entropy in bits.\"\"\"\n",
        "    return 2 ** cross_entropy_bits\n",
        "\n",
        "def calculate_cross_entropy(perplexity: float) -> float:\n",
        "    \"\"\"Calculate cross-entropy from perplexity.\"\"\"\n",
        "    return math.log2(perplexity)\n",
        "\n",
        "# Test with GPT-2 Small on WikiText-2\n",
        "ce = models[0]['results']['wikitext2']['cross_entropy_bits']\n",
        "ppl = models[0]['results']['wikitext2']['perplexity']\n",
        "\n",
        "calculated_ppl = calculate_perplexity(ce)\n",
        "calculated_ce = calculate_cross_entropy(ppl)\n",
        "\n",
        "print(f\"Cross-Entropy: {ce:.2f} bits\")\n",
        "print(f\"Perplexity (from data): {ppl:.2f}\")\n",
        "print(f\"Perplexity (calculated): {calculated_ppl:.2f}\")\n",
        "print(f\"Cross-Entropy (back-calculated): {calculated_ce:.2f} bits\")\n",
        "print(f\"\\n\u2705 Conversion formulas work correctly!\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Visualize Perplexity vs Model Size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Extract data for WikiText-2\n",
        "model_names = [m['model_name'] for m in models]\n",
        "params = [int(m['parameters'].replace('M', '')) for m in models]\n",
        "wikitext2_ppls = [m['results']['wikitext2']['perplexity'] for m in models]\n",
        "ptb_ppls = [m['results']['ptb']['perplexity'] for m in models]\n",
        "\n",
        "# Create bar chart\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "x = np.arange(len(model_names))\n",
        "width = 0.35\n",
        "\n",
        "ax.bar(x - width/2, wikitext2_ppls, width, label='WikiText-2', color='#3498db')\n",
        "ax.bar(x + width/2, ptb_ppls, width, label='Penn Treebank', color='#e74c3c')\n",
        "\n",
        "ax.set_xlabel('Model', fontsize=12)\n",
        "ax.set_ylabel('Perplexity (lower is better)', fontsize=12)\n",
        "ax.set_title('Perplexity vs Model Size (GPT-2 Variants)', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels([f\"{name}\\n({p}M params)\" for name, p in zip(model_names, params)])\n",
        "ax.legend()\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\ud83d\udcca Observation: Perplexity decreases as model size increases\")\n",
        "print(f\"   117M \u2192 1542M: {wikitext2_ppls[0] - wikitext2_ppls[-1]:.2f} reduction ({((wikitext2_ppls[0] - wikitext2_ppls[-1]) / wikitext2_ppls[0] * 100):.1f}%)\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Scaling Trends Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Analyze diminishing returns\n",
        "improvements = []\n",
        "for i in range(1, len(wikitext2_ppls)):\n",
        "    prev_ppl = wikitext2_ppls[i-1]\n",
        "    curr_ppl = wikitext2_ppls[i]\n",
        "    improvement = (prev_ppl - curr_ppl) / prev_ppl * 100\n",
        "    improvements.append(improvement)\n",
        "    param_increase = params[i] / params[i-1]\n",
        "    print(f\"{model_names[i-1]:15} \u2192 {model_names[i]:15}: {improvement:5.1f}% improvement ({param_increase:.1f}\u00d7 parameters)\")\n",
        "\n",
        "print(f\"\\n\ud83d\udcc8 Trend: Diminishing returns as models scale\")\n",
        "print(f\"   First jump:  {improvements[0]:.1f}% (117M \u2192 345M)\")\n",
        "print(f\"   Second jump: {improvements[1]:.1f}% (345M \u2192 762M)\")\n",
        "print(f\"   Third jump:  {improvements[2]:.1f}% (762M \u2192 1542M)\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Data Contamination Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Analyze contamination data\n",
        "contamination = data['contamination_analysis']\n",
        "\n",
        "mmlu_ppl = contamination['mmlu_benchmark']['observed_perplexity']\n",
        "expected_range = contamination['mmlu_benchmark']['expected_perplexity_range']\n",
        "held_out_ppl = contamination['held_out_test']['observed_perplexity']\n",
        "\n",
        "print(\"\ud83d\udd0d Data Contamination Analysis\")\n",
        "print(f\"\\nMMLU Benchmark:\")\n",
        "print(f\"  Expected range: {expected_range[0]}-{expected_range[1]}\")\n",
        "print(f\"  Observed: {mmlu_ppl}\")\n",
        "print(f\"  \u26a0\ufe0f  SUSPICIOUS: {mmlu_ppl} << {expected_range[0]} (much lower than expected)\")\n",
        "print(f\"\\nHeld-out Test Set (post-2019):\")\n",
        "print(f\"  Observed: {held_out_ppl}\")\n",
        "print(f\"  \u2705 NORMAL: Within expected range for unseen data\")\n",
        "print(f\"\\n\ud83d\udca1 Interpretation: MMLU questions likely appeared in GPT-2 training data\")\n",
        "print(f\"   Ratio: {held_out_ppl / mmlu_ppl:.1f}\u00d7 higher perplexity on clean data\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary and Key Takeaways\n",
        "\n",
        "\u2705 **What we learned:**\n",
        "\n",
        "1. **Perplexity = 2^(Cross-Entropy)** \u2192 Simple conversion formula\n",
        "2. **Scaling improves perplexity** but with diminishing returns\n",
        "3. **Contamination detection:** Unusually low perplexity (<10) suggests data leakage\n",
        "4. **Dataset matters:** Same model has different perplexity on different datasets\n",
        "\n",
        "**Next Steps:**\n",
        "- Read `exact_evaluation_methods.md` to learn similarity measurements\n",
        "- Run `similarity_measurements_tutorial.ipynb` for hands-on practice"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}