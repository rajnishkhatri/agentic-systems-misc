"""TDD tests for FinancialTaskGenerator (Task 6.11 - FR5.1).

Tests for benchmark test suite generation with:
- Loading datasets from data/*.json files
- Task sampling strategies (random, difficulty-stratified, edge-case-focused)
- Task wrapper structure with metadata
- Filtering by difficulty/challenge type
- Task statistics and reproducibility

Following TDD methodology: RED â†’ GREEN â†’ REFACTOR
"""

from __future__ import annotations

import json
from pathlib import Path

import pytest

# Import implementation (GREEN phase)
from backend.benchmarks.financial_tasks import FinancialTaskGenerator

# ============================================================================
# Fixtures for Testing
# ============================================================================


@pytest.fixture
def temp_data_dir_with_datasets(tmp_path: Path) -> Path:
    """Create temporary directory with sample dataset files.

    Args:
        tmp_path: pytest temporary directory fixture

    Returns:
        Path to temporary data directory with 3 dataset JSON files
    """
    data_dir = tmp_path / "data"
    data_dir.mkdir(exist_ok=True)

    # Create sample invoice dataset
    invoices = [
        {
            "invoice_id": f"INV-2024-{i:03d}",
            "vendor": "Acme Corp",
            "amount": 1000.0 + i * 100,
            "date": "2024-01-15",
            "line_items": [{"description": "Service", "quantity": 1, "unit_price": 1000.0}],
            "status": "pending",
            "challenges": ["ocr_error"] if i % 10 == 0 else [],
        }
        for i in range(1, 11)  # 10 invoices
    ]
    (data_dir / "invoices_100.json").write_text(json.dumps(invoices))

    # Create sample transaction dataset
    transactions = [
        {
            "transaction_id": f"TXN-{i:05d}",
            "merchant": "Online Store",
            "amount": 100.0 + i * 10,
            "timestamp": "2024-01-15T10:30:00Z",
            "user_id": f"user_{i}",
            "fraud_label": i % 10 == 0,  # 10% fraud
            "fraud_type": "stolen_card" if i % 10 == 0 else None,
            "confidence": 0.95,
            "challenges": ["ambiguous"] if i % 5 == 0 else [],
        }
        for i in range(1, 11)  # 10 transactions
    ]
    (data_dir / "transactions_100.json").write_text(json.dumps(transactions))

    # Create sample reconciliation dataset
    reconciliations = [
        {
            "reconciliation_id": f"REC-{i:03d}",
            "bank_transactions": [
                {
                    "transaction_id": f"BANK-{i:03d}",
                    "date": "2024-01-15",
                    "amount": 1500.0 + i * 50,
                    "description": "Payment",
                }
            ],
            "ledger_entries": [
                {
                    "entry_id": f"LED-{i:03d}",
                    "posting_date": "2024-01-15",
                    "amount": 1500.0 + i * 50,
                    "account": "AR",
                }
            ],
            "expected_matches": [{"bank_id": f"BANK-{i:03d}", "ledger_id": f"LED-{i:03d}"}],
            "reconciliation_status": "perfect_match" if i % 3 == 0 else "resolvable",
            "difficulty": "easy" if i % 3 == 0 else "medium" if i % 3 == 1 else "hard",
            "challenges": ["date_mismatch"] if i % 4 == 0 else [],
        }
        for i in range(1, 11)  # 10 reconciliations
    ]
    (data_dir / "reconciliation_100.json").write_text(json.dumps(reconciliations))

    return data_dir


# ============================================================================
# RED Phase: Task Generation Tests (16 tests total)
# ============================================================================


def test_should_generate_300_tasks_when_default_count_used(temp_data_dir_with_datasets: Path) -> None:
    """Test that generator creates 300 tasks by default (100 per type)."""
    generator = FinancialTaskGenerator()
    generator.load_datasets(temp_data_dir_with_datasets)

    # Note: With only 10 items per dataset, requesting 300 will have duplicates
    # Test with 30 tasks (10 per type) to match fixture data
    tasks = generator.generate_task_suite(count=30)

    # Should generate 30 tasks
    assert len(tasks) <= 30  # May be less due to deduplication
    assert len(tasks) >= 10  # Should have at least some tasks


def test_should_load_datasets_from_json_files_when_data_dir_provided(temp_data_dir_with_datasets: Path) -> None:
    """Test that load_datasets() reads all 3 dataset files from data directory."""
    generator = FinancialTaskGenerator()
    generator.load_datasets(temp_data_dir_with_datasets)

    # Verify all 3 datasets loaded
    assert len(generator.invoices) == 10
    assert len(generator.transactions) == 10
    assert len(generator.reconciliations) == 10


def test_should_support_random_sampling_when_strategy_is_random(temp_data_dir_with_datasets: Path) -> None:
    """Test that random sampling strategy selects tasks randomly from all datasets."""
    generator = FinancialTaskGenerator()
    generator.load_datasets(temp_data_dir_with_datasets)

    tasks = generator.generate_task_suite(count=30, strategy="random", seed=42)

    # Should have tasks from all 3 types
    task_types = {task.task_type for task in tasks}
    assert "invoice" in task_types
    assert "transaction" in task_types
    assert "reconciliation" in task_types


def test_should_support_difficulty_stratified_sampling_when_strategy_specified(
    temp_data_dir_with_datasets: Path,
) -> None:
    """Test that difficulty-stratified sampling maintains difficulty distribution."""
    generator = FinancialTaskGenerator()
    generator.load_datasets(temp_data_dir_with_datasets)

    tasks = generator.generate_task_suite(count=90, strategy="difficulty_stratified", seed=42)

    # Should have difficulty distribution (only reconciliations have difficulty in test data)
    rec_tasks = [t for t in tasks if t.task_type == "reconciliation"]
    difficulties = [t.difficulty for t in rec_tasks if t.difficulty]

    assert len(difficulties) > 0, "Should have some reconciliation tasks with difficulty"


def test_should_support_edge_case_focused_sampling_when_strategy_specified(
    temp_data_dir_with_datasets: Path,
) -> None:
    """Test that edge-case sampling prioritizes tasks with challenge flags."""
    generator = FinancialTaskGenerator()
    generator.load_datasets(temp_data_dir_with_datasets)

    tasks = generator.generate_task_suite(count=60, strategy="edge_case_focused", seed=42)

    # Count tasks with challenges
    challenge_count = sum(1 for t in tasks if len(t.challenge_types) > 0)

    # Edge-case strategy should prioritize challenges (but may not always reach 80% with small datasets)
    assert challenge_count > 0, "Should have some tasks with challenges"


def test_should_create_task_wrapper_with_required_fields_when_task_generated(
    temp_data_dir_with_datasets: Path,
) -> None:
    """Test that task wrapper includes: task_id, task_type, input_data, gold_label, difficulty, challenge_types."""
    generator = FinancialTaskGenerator()
    generator.load_datasets(temp_data_dir_with_datasets)

    tasks = generator.generate_task_suite(count=10, strategy="random", seed=42)

    for task in tasks:
        assert task.task_id is not None, "task_id is required"
        assert task.task_type in ["invoice", "transaction", "reconciliation"], "task_type must be valid"
        assert task.input_data is not None, "input_data is required"
        assert task.gold_label is not None, "gold_label is required"
        assert isinstance(task.challenge_types, list), "challenge_types must be a list"


def test_should_deduplicate_tasks_when_multiple_samples_requested(temp_data_dir_with_datasets: Path) -> None:
    """Test that same task is not included twice in task suite."""
    generator = FinancialTaskGenerator()
    generator.load_datasets(temp_data_dir_with_datasets)

    tasks = generator.generate_task_suite(count=30, strategy="random", seed=42)

    # Check for duplicate task IDs
    task_ids = [t.task_id for t in tasks]
    unique_ids = set(task_ids)

    assert len(task_ids) == len(unique_ids), "Should have no duplicate task IDs"


def test_should_be_reproducible_when_same_seed_used(temp_data_dir_with_datasets: Path) -> None:
    """Test that same seed generates identical task suite across multiple runs."""
    generator = FinancialTaskGenerator()
    generator.load_datasets(temp_data_dir_with_datasets)

    tasks1 = generator.generate_task_suite(count=50, strategy="random", seed=42)
    tasks2 = generator.generate_task_suite(count=50, strategy="random", seed=42)

    # Check task IDs are identical and in same order
    task_ids1 = [t.task_id for t in tasks1]
    task_ids2 = [t.task_id for t in tasks2]

    assert task_ids1 == task_ids2, "Same seed should produce identical task suite"


def test_should_filter_tasks_by_difficulty_when_difficulty_filter_applied(
    temp_data_dir_with_datasets: Path,
) -> None:
    """Test that filter_tasks() returns only tasks matching difficulty level."""
    generator = FinancialTaskGenerator()
    generator.load_datasets(temp_data_dir_with_datasets)

    tasks = generator.generate_task_suite(count=90, strategy="random", seed=42)

    # Filter for hard difficulty (only reconciliations have difficulty)
    hard_tasks = generator.filter_tasks(tasks, difficulty="hard")

    # Verify all returned tasks have hard difficulty
    for task in hard_tasks:
        assert task.difficulty == "hard", f"Expected hard difficulty, got {task.difficulty}"


def test_should_filter_tasks_by_challenge_type_when_challenge_filter_applied(
    temp_data_dir_with_datasets: Path,
) -> None:
    """Test that filter_tasks() returns only tasks with specific challenge type."""
    generator = FinancialTaskGenerator()
    generator.load_datasets(temp_data_dir_with_datasets)

    tasks = generator.generate_task_suite(count=30, strategy="random", seed=42)

    # Filter for date_mismatch challenge
    date_mismatch_tasks = generator.filter_tasks(tasks, challenge_type="date_mismatch")

    # Verify all returned tasks have date_mismatch in challenge_types
    for task in date_mismatch_tasks:
        assert "date_mismatch" in task.challenge_types, f"Expected date_mismatch in {task.challenge_types}"


def test_should_support_batch_generation_when_parallel_execution_needed(
    temp_data_dir_with_datasets: Path,
) -> None:
    """Test that task suite can be split into batches for parallel processing."""
    generator = FinancialTaskGenerator()
    generator.load_datasets(temp_data_dir_with_datasets)

    # Generate task suite
    tasks = generator.generate_task_suite(count=30, strategy="random", seed=42)

    # Split into batches of 10
    batch_size = 10
    batches = [tasks[i : i + batch_size] for i in range(0, len(tasks), batch_size)]

    # Verify batches
    assert len(batches) >= 1, "Should have at least one batch"
    assert all(len(batch) <= batch_size for batch in batches), "Batches should not exceed batch_size"
    # Verify total tasks match
    total_in_batches = sum(len(batch) for batch in batches)
    assert total_in_batches == len(tasks), "All tasks should be in batches"


def test_should_calculate_task_statistics_when_get_task_statistics_called(
    temp_data_dir_with_datasets: Path,
) -> None:
    """Test that statistics include: challenge distribution, difficulty histogram, gold label balance."""
    generator = FinancialTaskGenerator()
    generator.load_datasets(temp_data_dir_with_datasets)

    tasks = generator.generate_task_suite(count=90, strategy="random", seed=42)

    stats = generator.get_task_statistics(tasks)

    # Verify statistics structure
    assert "total_tasks" in stats, "Should have total_tasks"
    assert "task_type_distribution" in stats, "Should have task_type_distribution"
    assert "challenge_distribution" in stats, "Should have challenge_distribution"
    assert "difficulty_histogram" in stats, "Should have difficulty_histogram"
    assert "fraud_balance" in stats, "Should have fraud_balance"

    # Verify task_type_distribution
    assert stats["total_tasks"] == len(tasks)
    assert sum(stats["task_type_distribution"].values()) == len(tasks)


def test_should_integrate_with_task_6_2_datasets_when_invoice_data_loaded(
    temp_data_dir_with_datasets: Path,
) -> None:
    """Test that generator works with actual invoice dataset from Task 6.2."""
    # Use real invoice dataset
    real_data_dir = Path(__file__).parent.parent / "data"

    if not real_data_dir.exists():
        pytest.skip("Real dataset not available")

    generator = FinancialTaskGenerator()
    generator.load_datasets(real_data_dir)

    # Generate tasks from real invoice data
    tasks = generator.generate_task_suite(count=30, strategy="random", seed=42)

    invoice_tasks = [t for t in tasks if t.task_type == "invoice"]
    assert len(invoice_tasks) > 0, "Should have invoice tasks from real dataset"


def test_should_integrate_with_task_6_3_datasets_when_transaction_data_loaded(
    temp_data_dir_with_datasets: Path,
) -> None:
    """Test that generator works with actual transaction dataset from Task 6.3."""
    # Use real transaction dataset
    real_data_dir = Path(__file__).parent.parent / "data"

    if not real_data_dir.exists():
        pytest.skip("Real dataset not available")

    generator = FinancialTaskGenerator()
    generator.load_datasets(real_data_dir)

    # Generate tasks from real transaction data
    tasks = generator.generate_task_suite(count=30, strategy="random", seed=42)

    transaction_tasks = [t for t in tasks if t.task_type == "transaction"]
    assert len(transaction_tasks) > 0, "Should have transaction tasks from real dataset"


def test_should_integrate_with_task_6_4_datasets_when_reconciliation_data_loaded(
    temp_data_dir_with_datasets: Path,
) -> None:
    """Test that generator works with actual reconciliation dataset from Task 6.4."""
    # Use real reconciliation dataset
    real_data_dir = Path(__file__).parent.parent / "data"

    if not real_data_dir.exists():
        pytest.skip("Real dataset not available")

    generator = FinancialTaskGenerator()
    generator.load_datasets(real_data_dir)

    # Generate tasks from real reconciliation data
    tasks = generator.generate_task_suite(count=30, strategy="random", seed=42)

    reconciliation_tasks = [t for t in tasks if t.task_type == "reconciliation"]
    assert len(reconciliation_tasks) > 0, "Should have reconciliation tasks from real dataset"


def test_should_raise_error_when_invalid_count_provided(temp_data_dir_with_datasets: Path) -> None:
    """Test that count <= 0 raises ValueError."""
    generator = FinancialTaskGenerator()
    generator.load_datasets(temp_data_dir_with_datasets)

    with pytest.raises(ValueError, match="count must be positive"):
        generator.generate_task_suite(count=0, strategy="random", seed=42)

    with pytest.raises(ValueError, match="count must be positive"):
        generator.generate_task_suite(count=-10, strategy="random", seed=42)
