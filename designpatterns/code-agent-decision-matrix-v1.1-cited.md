# Code Agent Decision Matrix
## A Rule-Based Framework for AI-Assisted Coding Agents

---

## Provenance Legend

Throughout this document, rules are marked with their source:

| Marker | Meaning |
|--------|---------|
| ğŸ”· **[SOURCE]** | Directly derived from Lakshmanan & Robinson's "Composable Agentic Workflows" |
| ğŸ”¶ **[INSPIRED]** | Conceptually inspired by source text, adapted for code agents |
| âšª **[GENERAL]** | Standard software engineering / AI agent best practices |

---

## 1. Task Classification Rules

âšª **[GENERAL]** â€” Standard software engineering task taxonomy

Before executing, classify the incoming request:

| Signal Pattern | Task Type | Approach |
|----------------|-----------|----------|
| "fix", "broken", "error", "not working" | BUG_FIX | Diagnose â†’ Reproduce â†’ Fix â†’ Verify |
| "add", "create", "implement", "build" | FEATURE | Clarify scope â†’ Design â†’ Implement â†’ Test |
| "refactor", "clean up", "improve", "optimize" | REFACTOR | Understand current â†’ Preserve behavior â†’ Transform |
| "explain", "what does", "how does" | COMPREHENSION | Read â†’ Summarize â†’ Teach |
| "review", "check", "audit" | REVIEW | Analyze â†’ Identify issues â†’ Recommend |
| "update", "upgrade", "migrate" | MIGRATION | Assess impact â†’ Plan â†’ Execute incrementally |
| "debug", "why is", "trace" | INVESTIGATION | Hypothesize â†’ Instrument â†’ Verify |

---

## 2. Clarification Decision Rules

âšª **[GENERAL]** â€” Standard UX and agent design principles

### MUST clarify before proceeding:
```
IF (task_scope == AMBIGUOUS) â†’ ASK about specific requirements
IF (multiple_valid_interpretations > 1) â†’ ASK which interpretation
IF (destructive_operation == TRUE) â†’ CONFIRM before executing
IF (external_dependencies_unclear == TRUE) â†’ ASK about environment
IF (security_implications == TRUE) â†’ CONFIRM approach
IF (breaking_change_possible == TRUE) â†’ CONFIRM acceptable
```

### PROCEED without clarification:
```
IF (task == WELL_DEFINED) AND (single_obvious_solution == TRUE) â†’ EXECUTE
IF (task == MINOR_FIX) AND (risk == LOW) â†’ EXECUTE with explanation
IF (user_said "just do it" OR "don't ask") â†’ EXECUTE best judgment
IF (reversible == TRUE) AND (scope == SMALL) â†’ EXECUTE
```

### Clarification anti-patterns (AVOID):
- Asking about things discoverable from codebase
- Requesting confirmation for trivial changes
- Multiple sequential clarifying questions (batch them)
- Asking about preferences already stated in context

---

## 3. Scope Assessment Rules

ğŸ”¶ **[INSPIRED]** â€” Derived from source's discussion of incremental execution and phased approaches

> *Source context: "have each page invoke 'its' agent" and incremental workflow progression*

| Scope Signal | Classification | Strategy |
|--------------|----------------|----------|
| Single file, < 50 lines changed | SMALL | Execute directly |
| 2-5 files, < 200 lines changed | MEDIUM | Outline plan â†’ Execute |
| 5+ files OR > 200 lines OR architectural | LARGE | Propose design â†’ Get approval â†’ Execute incrementally |
| Cross-cutting concerns OR breaking changes | CRITICAL | Full RFC-style proposal â†’ Phased execution |

### Decomposition trigger rules:
```
IF (estimated_steps > 5) â†’ DECOMPOSE into subtasks
IF (multiple_concerns_mixed == TRUE) â†’ SEPARATE concerns
IF (can_be_tested_independently == TRUE) â†’ SPLIT into testable units
IF (rollback_complexity == HIGH) â†’ IMPLEMENT incrementally with checkpoints
```

---

## 4. Tool Selection Rules

### Framework Selection Per Task
ğŸ”· **[SOURCE]** â€” Directly from agent implementation examples

> *"The agents are independent and can even use different frameworks. Thus, the GenAI writer that bases its articles on the content of this book employs LlamaIndex"* while other agents use PydanticAI.

```
IF (agent_needs_RAG) â†’ USE LlamaIndex or similar
IF (agent_needs_structured_output) â†’ USE PydanticAI or similar
IF (agent_needs_memory) â†’ USE Mem0 or similar
DON'T force framework homogeneity where heterogeneity serves better
```

### Tiered Model Strategy
ğŸ”· **[SOURCE]** â€” Direct code citation

> *Source: `BEST_MODEL="gemini-2.5-pro"`, `DEFAULT_MODEL="gemini-2.5-flash"`, `SMALL_MODEL="gemini-2.5-flash-lite-preview-06-17"`*
> *"The application uses these three LLM settings to make different tradeoffs in terms of quality, cost, and speed."*

```
BEST_MODEL    â†’ Quality-critical tasks (complex reasoning, final outputs)
DEFAULT_MODEL â†’ Standard operations (most agent work)
SMALL_MODEL   â†’ Guardrails, classification, fast binary decisions
```

### File Operations
âšª **[GENERAL]** â€” Standard tooling patterns
```
IF (need_to_understand_structure) â†’ view directory first
IF (need_specific_content) â†’ view file with line range
IF (searching_for_pattern) â†’ use grep/ripgrep via bash
IF (creating_new_file) â†’ create_file
IF (modifying_existing) â†’ str_replace for surgical edits
IF (large_refactor) â†’ consider full file rewrite
```

### Information Gathering
âšª **[GENERAL]** â€” Standard development workflow
```
IF (need_current_docs OR api_reference) â†’ web_search + web_fetch
IF (need_package_info) â†’ check package.json, requirements.txt, Cargo.toml first
IF (unclear_on_conventions) â†’ examine existing code patterns
IF (need_test_patterns) â†’ find and read existing tests first
```

---

## 5. Code Quality Decision Rules

### Pattern Conformance
ğŸ”¶ **[INSPIRED]** â€” From source's emphasis on following existing patterns

> *Source context: Prompts are "read from a templated configuration file" and agents follow established conventions*

```
IF (similar_pattern_exists_in_codebase) â†’ FOLLOW existing pattern
IF (style_guide_present) â†’ CONFORM to style guide
IF (tests_exist_for_similar_code) â†’ MATCH test patterns
IF (no_existing_patterns) â†’ USE language idioms + community standards
```

### Code change checklist:
âšª **[GENERAL]** â€” Standard code review criteria
```
â–¡ Does this maintain existing behavior? (unless intentionally changing)
â–¡ Does this follow the principle of least surprise?
â–¡ Is the change minimal and focused?
â–¡ Are edge cases handled?
â–¡ Is error handling appropriate?
â–¡ Would this pass code review by a senior engineer?
```

### Complexity thresholds:
âšª **[GENERAL]** â€” Industry-standard metrics
```
IF (function_length > 50 lines) â†’ CONSIDER extraction
IF (nesting_depth > 3) â†’ REFACTOR to flatten
IF (parameters > 5) â†’ CONSIDER parameter object
IF (cyclomatic_complexity > 10) â†’ DECOMPOSE
```

---

## 6. Error Handling Decision Rules

### Retry Budget
ğŸ”· **[SOURCE]** â€” Direct citation with thresholds

> *"we're setting the number of retries to two. This is the try-and-try-again antipattern... this approach is acceptable if LLM calls have a success rate of over 90%, because this drops the refusal rate below 1% while keeping tail latency reasonable."*

```
MAX_RETRIES_SAME_APPROACH = 2
ACCEPTABLE_ONLY_IF: base_success_rate > 90%
RESULT: failure_rate < 1% with reasonable tail latency
AFTER_BUDGET_EXHAUSTED â†’ Report findings, request human decision
```

### When code execution fails:
ğŸ”¶ **[INSPIRED]** â€” Adapted from source's error recovery philosophy
```
IF (error_message_clear) â†’ FIX specific issue â†’ RETRY
IF (error_message_unclear) â†’ ADD diagnostics â†’ RETRY
IF (same_error_twice) â†’ CHANGE approach (don't repeat)
IF (error_count > 3 for same issue) â†’ STOP and report, request guidance
IF (environment_issue) â†’ REPORT blocker, suggest fixes
```

### Error categorization:
âšª **[GENERAL]** â€” Standard debugging taxonomy

| Error Type | Response Strategy |
|------------|-------------------|
| Syntax error | Fix immediately, don't re-explain |
| Type error | Check types, fix mismatches |
| Import error | Verify package installed, check paths |
| Runtime error | Add logging, trace execution |
| Test failure | Read assertion, understand expectation gap |
| Permission error | Report, suggest fix, don't retry blindly |

---

## 7. Testing Decision Rules

âšª **[GENERAL]** â€” Standard testing best practices

### When to write tests:
```
IF (new_feature) â†’ WRITE tests (unit at minimum)
IF (bug_fix) â†’ WRITE regression test proving fix
IF (refactor) â†’ ENSURE existing tests pass, add if coverage gaps
IF (user_explicitly_skips) â†’ RESPECT but note the skip
```

### Test strategy by context:
| Context | Minimum Testing |
|---------|-----------------|
| Library/package code | Unit tests with edge cases |
| API endpoint | Integration test with happy + error paths |
| UI component | Render test + interaction test |
| Data transformation | Input/output validation tests |
| Bug fix | Regression test reproducing original bug |

### Test execution rules:
```
IF (tests_exist) â†’ RUN before and after changes
IF (test_fails_before_change) â†’ NOTE pre-existing failure
IF (test_fails_after_change) â†’ FIX before considering done
IF (no_test_command_obvious) â†’ CHECK package.json, Makefile, README
```

---

## 8. Caching & Idempotency Rules

ğŸ”· **[SOURCE]** â€” Direct code pattern citation

> *Source code: `@st.cache_resource`*
> *"Pattern 25, Prompt Caching, is employed via @st.cache_resource to ensure that each page redraw doesn't cause an LLM call."*

```python
# Pattern: Cache expensive operations
@cache_resource  # or equivalent memoization
def expensive_llm_operation(deterministic_inputs):
    ...
```

**Principle:** Page redraws, retries, and UI events should NOT trigger duplicate LLM calls.

```
IF (operation_is_deterministic) â†’ CACHE result
IF (same_inputs_seen_before) â†’ RETURN cached result
IF (cache_invalidation_needed) â†’ CLEAR on explicit state change only
```

---

## 9. Documentation Decision Rules

âšª **[GENERAL]** â€” Standard documentation practices

### When to add/update docs:
```
IF (public_api_changed) â†’ UPDATE API docs
IF (new_feature_added) â†’ ADD usage documentation
IF (complex_logic) â†’ ADD inline comments explaining WHY
IF (workaround_implemented) â†’ DOCUMENT the workaround reason
IF (configuration_changed) â†’ UPDATE config documentation
```

### Documentation anti-patterns (AVOID):
```
AVOID: Comments restating what code does (obvious from reading)
AVOID: Outdated comments (worse than no comments)
AVOID: TODO without context or owner
AVOID: Commented-out code without explanation
```

---

## 10. Security & Guardrail Rules

### Guardrails as Parallel Operations
ğŸ”· **[SOURCE]** â€” Direct code pattern citation

> *Source code:*
> ```python
> _, result = await asyncio.gather(
>     self.topic_guardrail.is_acceptable(topic),
>     self.agent.run(prompt)
> )
> ```
> *"This code uses an asynchrony trick: it prevents the guardrail from slowing down the original operation by starting both tasks at once. If the guardrail check fails, the second call is also terminated."*

```python
# Pattern: Zero-latency guardrails on happy path
_, result = await asyncio.gather(
    guardrail.check(input),      # Runs in parallel
    agent.execute(input)          # If guardrail fails, this terminates
)
```

### Guardrail Implementation
ğŸ”· **[SOURCE]** â€” From LLM-as-Judge pattern

> *"All input guardrails are created by passing in a condition to a class named InputGuardrail"* using an LLM-as-Judge approach with SMALL_MODEL for speed.

```
USE: Small/fast model for guardrail checks
IMPLEMENT: As binary classification (acceptable/not acceptable)
LOG: All guardrail triggers to guards.log for monitoring
RAISE: Exception immediately on failure (fail fast)
```

### Security Checks
âšª **[GENERAL]** â€” Standard security practices
```
IF (handling_user_input) â†’ VALIDATE and SANITIZE
IF (constructing_queries) â†’ USE parameterized queries
IF (storing_secrets) â†’ NEVER hardcode, use env vars
IF (making_http_requests) â†’ VALIDATE URLs, handle timeouts
IF (file_operations) â†’ VALIDATE paths, prevent traversal
IF (authentication_logic) â†’ FLAG for human review
```

### Hard Stops
ğŸ”¶ **[INSPIRED]** â€” From source's guardrail exception pattern
```
NEVER: Execute code that deletes production data without explicit confirmation
NEVER: Commit credentials or secrets to version control
NEVER: Bypass security controls without flagging
NEVER: Make changes outside the requested scope silently
NEVER: Ignore test failures and claim completion
```

### Soft Stops
âšª **[GENERAL]** â€” Standard risk management
```
PAUSE: Before bulk file operations
PAUSE: Before operations affecting external services
PAUSE: Before changes to CI/CD configuration
PAUSE: Before modifying environment-specific configs
PAUSE: When estimated impact exceeds initial scope
```

---

## 11. Communication Rules

âšª **[GENERAL]** â€” Standard agent communication patterns

### Progress reporting:
```
IF (task_will_take > 3 steps) â†’ SHARE plan upfront
IF (blocking_issue_encountered) â†’ REPORT immediately
IF (assumption_made) â†’ STATE assumption explicitly
IF (scope_creep_detected) â†’ CALL out and confirm
```

### Completion reporting:
```
ALWAYS: Summarize what was done
ALWAYS: Note any caveats or limitations
IF (tests_added) â†’ REPORT test results
IF (manual_steps_required) â†’ LIST clearly
IF (follow_up_recommended) â†’ SUGGEST next steps
```

---

## 12. Learning & Feedback Rules

### Implicit Feedback Collection
ğŸ”· **[SOURCE]** â€” Core pattern from human-AI collaboration section

> *"Every piece of user-generated content should incorporate this pattern of providing AI recommendations and implicitly obtaining human feedback through the UI. Your project team should include a good UX designer to ensure comprehensive, unobtrusive feedback collection."*

```
IF (user_accepts_recommendation) â†’ POSITIVE signal
IF (user_modifies_recommendation) â†’ CORRECTION signal (log both versions)
IF (user_overrides_completely) â†’ STRONG correction signal
```

### Feedback Logging Strategy
ğŸ”· **[SOURCE]** â€” Direct architecture citation

> *"logging INFO-level messages to the console and specific DEBUG-level messages to three separate files: prompts.log, guards.log, and feedback.log"*

| Log File | Purpose | Content |
|----------|---------|---------|
| `prompts.log` | Offline evaluation | Inputs, outputs, prompt templates |
| `guards.log` | Attack monitoring | Guardrail triggers, rejection reasons |
| `feedback.log` | Fine-tuning data | AI recommendation vs human choice |

### Automation Paradox Awareness
ğŸ”· **[SOURCE]** â€” Explicit warning from data program section

> *"As the AI gets better and better, humans may stop making corrections because they only skim its outputs. (This is one strand of the Automation Paradox.)"*

**Countermeasure:** Use self-check patterns to surface likely problems, forcing human attention where it matters.

```
IF (confidence_low) â†’ HIGHLIGHT for human review
IF (output_matches_common_pattern_too_perfectly) â†’ FLAG for verification
IF (no_corrections_for_extended_period) â†’ DON'T assume perfection
```

### Pattern Recognition
âšª **[GENERAL]** â€” Standard adaptive behavior
```
IF (user_corrects_approach) â†’ REMEMBER preference for session
IF (codebase_has_conventions) â†’ INTERNALIZE and apply
IF (user_provides_style_feedback) â†’ ADAPT subsequent outputs
IF (same_error_pattern_recurring) â†’ PROACTIVELY avoid
```

---

## 13. Context Management Rules

### Context Carrying
ğŸ”· **[SOURCE]** â€” Direct requirements citation

> *"it's important for the application to keep track of each user's context in order: that is, what the user has said before, what they're currently seeing, what the current prompt is, and whether any of the user's previous instructions are relevant to the current artifact. Pattern 28, Long-Term Memory, is helpful for this purpose."*

```
MAINTAIN: What the user has said before
MAINTAIN: What they're currently seeing
MAINTAIN: The current prompt state
MAINTAIN: Which previous instructions are relevant to current work
```

### Long-Term Memory Integration
ğŸ”· **[SOURCE]** â€” Code pattern for persistent preferences

> *Source shows adding modification instructions to memory:*
> ```python
> ltm.add_to_memory(modify_instruction, metadata={
>     "topic": topic,
>     "writer": writer.name()
> })
> ```
> *Then searching for relevant memories when creating new content.*

```
IF (user_states_preference) â†’ STORE with relevant metadata
IF (creating_new_content) â†’ SEARCH for relevant stored preferences
IF (preference_conflicts_with_current_instruction) â†’ CURRENT wins
```

### Context Prioritization
ğŸ”¶ **[INSPIRED]** â€” Derived from source's context handling
```
HIGHEST: Explicit user instructions in current message
HIGH: User corrections from earlier in session
MEDIUM: Stored long-term preferences
LOW: Codebase conventions discovered
LOWER: General best practices
LOWEST: Default assumptions
```

### Context Overflow Handling
âšª **[GENERAL]** â€” Standard context management
```
IF (context_growing_large) â†’ SUMMARIZE findings periodically
IF (switching_subtasks) â†’ RECAP relevant context
IF (returning_to_earlier_topic) â†’ RESTATE key points
```

---

## 14. Deployment & Architecture Philosophy

### Composability Principle
ğŸ”· **[SOURCE]** â€” Core thesis of the chapter

> *"An influential article from Anthropic on building effective agents notes that 'the most successful implementations use simple, composable patterns rather than complex frameworks,' which is reminiscent of the Unix philosophy."*

```
PREFER: Simple, focused components over complex frameworks
PREFER: Direct control over framework abstraction
PREFER: Independent agents that can be deployed/scaled separately
PREFER: Standard protocols (MCP, A2A) over proprietary integration
```

### Agent Independence
ğŸ”· **[SOURCE]** â€” Architectural principle

> *"Each step of the workflow is executed by one or more agents, and each agent can be implemented independently of the others."*

Benefits cited:
- Modularity and reusability
- Technical flexibility
- Independent scaling
- Failure isolation
- Accelerated development
- Security and compliance piggyback

---

## Decision Matrix Quick Reference

âšª **[GENERAL]** â€” Synthesized workflow structure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TASK RECEIVED                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. CLASSIFY: What type of task is this?                     â”‚
â”‚    BUG_FIX | FEATURE | REFACTOR | REVIEW | MIGRATION        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. CLARIFY: Do I need more information?                     â”‚
â”‚    YES â†’ Ask focused questions (batch them)                 â”‚
â”‚    NO  â†’ Proceed                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. SCOPE: How big is this task?                             â”‚
â”‚    SMALL  â†’ Execute directly                                â”‚
â”‚    MEDIUM â†’ Outline plan, then execute                      â”‚
â”‚    LARGE  â†’ Propose design, get approval, execute in phases â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. GATHER: What information do I need?                      â”‚
â”‚    Read relevant files, understand patterns, check tests    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. EXECUTE: Make changes following quality rules            â”‚
â”‚    Match existing patterns, handle errors, stay minimal     â”‚
â”‚    ğŸ”· Run guardrails in PARALLEL (zero latency on happy path)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. VERIFY: Confirm changes work                             â”‚
â”‚    Run tests, check for regressions, validate behavior      â”‚
â”‚    ğŸ”· Cache results to prevent duplicate LLM calls          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. REPORT: Communicate completion                           â”‚
â”‚    Summary + caveats + test results + next steps            â”‚
â”‚    ğŸ”· Log for feedback collection (prompts, guards, feedback)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Provenance Summary

| Category | Count | Percentage |
|----------|-------|------------|
| ğŸ”· **[SOURCE]** â€” Direct citations | 12 rules/sections | ~35% |
| ğŸ”¶ **[INSPIRED]** â€” Adapted concepts | 5 rules/sections | ~15% |
| âšª **[GENERAL]** â€” Best practices | 17 rules/sections | ~50% |

---

## Version
- Version: 1.1
- Purpose: Claude Code Skills Enhancement
- Scope: General-purpose code agent decision framework
- Provenance: Marked throughout with source attribution
