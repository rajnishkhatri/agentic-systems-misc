{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Search Comparison: BM25 vs Semantic vs Hybrid\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Compare BM25 (lexical), semantic (embedding-based), and hybrid search\n",
    "- Understand when each retrieval method excels\n",
    "- Implement Reciprocal Rank Fusion (RRF) for hybrid search\n",
    "- Measure retrieval quality using precision metrics\n",
    "\n",
    "**Execution Time:** <8 minutes (DEMO mode), ~20 minutes (FULL mode)  \n",
    "**Cost Estimate:** $0.30 (DEMO), $1.50 (FULL)\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from rank_bm25 import BM25Okapi\n",
    "from backend.semantic_retrieval import (\n",
    "    generate_embeddings,\n",
    "    build_vector_index,\n",
    "    semantic_search,\n",
    "    hybrid_search,\n",
    "    reciprocal_rank_fusion\n",
    ")\n",
    "from backend.context_judges import ContextPrecisionJudge\n",
    "import os\n",
    "\n",
    "# Set execution mode: DEMO (cheap, fast) or FULL (comprehensive)\n",
    "MODE = os.getenv(\"EXECUTION_MODE\", \"DEMO\")  # Change to \"FULL\" for comprehensive evaluation\n",
    "print(f\"üîß Execution Mode: {MODE}\")\n",
    "\n",
    "# Load recipe data\n",
    "with open('../homeworks/hw4/data/processed_recipes.json', 'r') as f:\n",
    "    recipes = json.load(f)\n",
    "\n",
    "# Sample size based on mode\n",
    "SAMPLE_SIZE = 50 if MODE == \"DEMO\" else 200\n",
    "recipes = recipes[:SAMPLE_SIZE]\n",
    "\n",
    "print(f\"üìö Loaded {len(recipes)} recipes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract recipe documents (name + description + ingredients)\n",
    "documents = []\n",
    "for recipe in recipes:\n",
    "    doc = f\"{recipe['name']}. {recipe['description']}. Ingredients: {', '.join(recipe['ingredients'][:10])}\"\n",
    "    documents.append(doc)\n",
    "\n",
    "print(f\"üìù Created {len(documents)} recipe documents\")\n",
    "print(f\"\\nüìÑ Sample document:\\n{documents[0][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Search Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Build BM25 index (lexical)\n",
    "tokenized_corpus = [doc.lower().split() for doc in documents]\n",
    "bm25_index = BM25Okapi(tokenized_corpus)\n",
    "print(\"‚úÖ BM25 index built\")\n",
    "\n",
    "# 2. Build vector index (semantic)\n",
    "print(\"\\nüîÑ Generating embeddings (this may take 2-5 minutes)...\")\n",
    "embeddings = generate_embeddings(documents)\n",
    "vector_index = build_vector_index(embeddings)\n",
    "print(f\"‚úÖ Vector index built: {embeddings.shape[0]} documents, {embeddings.shape[1]} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Queries\n",
    "\n",
    "We'll test three query types:\n",
    "1. **Exact match queries** (BM25 should excel)\n",
    "2. **Semantic queries** (Embeddings should excel)\n",
    "3. **Mixed queries** (Hybrid should excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    # Exact match queries (favor BM25)\n",
    "    {\"query\": \"lasagna with cheese\", \"type\": \"exact\", \"expected_terms\": [\"lasagna\", \"cheese\"]},\n",
    "    {\"query\": \"chicken recipe\", \"type\": \"exact\", \"expected_terms\": [\"chicken\"]},\n",
    "    \n",
    "    # Semantic queries (favor embeddings)\n",
    "    {\"query\": \"healthy breakfast ideas\", \"type\": \"semantic\", \"expected_concepts\": [\"nutritious\", \"morning\"]},\n",
    "    {\"query\": \"comfort food for cold weather\", \"type\": \"semantic\", \"expected_concepts\": [\"warm\", \"hearty\"]},\n",
    "    \n",
    "    # Mixed queries (favor hybrid)\n",
    "    {\"query\": \"quick vegetarian pasta\", \"type\": \"mixed\", \"expected_terms\": [\"pasta\"], \"expected_concepts\": [\"fast\", \"meatless\"]},\n",
    "    {\"query\": \"chocolate dessert easy to make\", \"type\": \"mixed\", \"expected_terms\": [\"chocolate\"], \"expected_concepts\": [\"simple\", \"sweet\"]},\n",
    "]\n",
    "\n",
    "if MODE == \"DEMO\":\n",
    "    test_queries = test_queries[:3]\n",
    "\n",
    "print(f\"üîç Testing {len(test_queries)} queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize context precision judge\n",
    "judge = ContextPrecisionJudge()\n",
    "\n",
    "results = []\n",
    "k = 5  # Top-5 retrieval\n",
    "\n",
    "for i, test in enumerate(test_queries):\n",
    "    query = test[\"query\"]\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query {i+1}/{len(test_queries)}: '{query}' (Type: {test['type']})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 1. BM25 search\n",
    "    tokenized_query = query.lower().split()\n",
    "    bm25_scores = bm25_index.get_scores(tokenized_query)\n",
    "    bm25_top_k = np.argsort(bm25_scores)[::-1][:k]\n",
    "    bm25_results = [documents[idx] for idx in bm25_top_k]\n",
    "    \n",
    "    # 2. Semantic search\n",
    "    query_embedding = generate_embeddings([query])[0]\n",
    "    semantic_results_raw = semantic_search(query_embedding, vector_index, k=k)\n",
    "    semantic_top_k = [idx for idx, score in semantic_results_raw]\n",
    "    semantic_results = [documents[idx] for idx in semantic_top_k]\n",
    "    \n",
    "    # 3. Hybrid search (alpha=0.5: equal weight to BM25 and semantic)\n",
    "    hybrid_top_k = hybrid_search(query, bm25_index, vector_index, alpha=0.5, k=k)\n",
    "    hybrid_results = [documents[idx] for idx in hybrid_top_k]\n",
    "    \n",
    "    # Evaluate precision using AI judge\n",
    "    print(\"\\nü§ñ Evaluating with AI judge...\")\n",
    "    bm25_eval = judge.evaluate(query, bm25_results)\n",
    "    semantic_eval = judge.evaluate(query, semantic_results)\n",
    "    hybrid_eval = judge.evaluate(query, hybrid_results)\n",
    "    \n",
    "    print(f\"\\nüìä Precision@{k}:\")\n",
    "    print(f\"  BM25:     {bm25_eval['precision']:.2f}\")\n",
    "    print(f\"  Semantic: {semantic_eval['precision']:.2f}\")\n",
    "    print(f\"  Hybrid:   {hybrid_eval['precision']:.2f}\")\n",
    "    \n",
    "    # Show top-1 result from each method\n",
    "    print(f\"\\nü•á Top-1 Results:\")\n",
    "    print(f\"\\n  BM25: {bm25_results[0][:150]}...\")\n",
    "    print(f\"\\n  Semantic: {semantic_results[0][:150]}...\")\n",
    "    print(f\"\\n  Hybrid: {hybrid_results[0][:150]}...\")\n",
    "    \n",
    "    results.append({\n",
    "        \"query\": query,\n",
    "        \"query_type\": test[\"type\"],\n",
    "        \"bm25_precision\": bm25_eval['precision'],\n",
    "        \"semantic_precision\": semantic_eval['precision'],\n",
    "        \"hybrid_precision\": hybrid_eval['precision'],\n",
    "        \"bm25_top_k\": bm25_top_k.tolist(),\n",
    "        \"semantic_top_k\": semantic_top_k,\n",
    "        \"hybrid_top_k\": hybrid_top_k\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis & Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create summary dataframe\n",
    "summary = pd.DataFrame([\n",
    "    {\n",
    "        \"Query\": r[\"query\"],\n",
    "        \"Type\": r[\"query_type\"],\n",
    "        \"BM25\": r[\"bm25_precision\"],\n",
    "        \"Semantic\": r[\"semantic_precision\"],\n",
    "        \"Hybrid\": r[\"hybrid_precision\"]\n",
    "    }\n",
    "    for r in results\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìà SUMMARY: Precision@5 by Query Type\")\n",
    "print(\"=\"*80)\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "# Aggregate by query type\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä AVERAGE PRECISION BY QUERY TYPE\")\n",
    "print(\"=\"*80)\n",
    "for qtype in [\"exact\", \"semantic\", \"mixed\"]:\n",
    "    subset = summary[summary[\"Type\"] == qtype]\n",
    "    if len(subset) > 0:\n",
    "        print(f\"\\n{qtype.upper()} queries:\")\n",
    "        print(f\"  BM25:     {subset['BM25'].mean():.3f}\")\n",
    "        print(f\"  Semantic: {subset['Semantic'].mean():.3f}\")\n",
    "        print(f\"  Hybrid:   {subset['Hybrid'].mean():.3f}\")\n",
    "\n",
    "# Overall average\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üèÜ OVERALL AVERAGE PRECISION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"  BM25:     {summary['BM25'].mean():.3f}\")\n",
    "print(f\"  Semantic: {summary['Semantic'].mean():.3f}\")\n",
    "print(f\"  Hybrid:   {summary['Hybrid'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "**Expected Patterns:**\n",
    "\n",
    "1. **BM25 (Lexical Search)**\n",
    "   - ‚úÖ Excels at exact term matching (e.g., \"lasagna with cheese\")\n",
    "   - ‚ùå Struggles with semantic similarity (e.g., \"comfort food\")\n",
    "   - ‚ö° Fast: No embedding computation needed\n",
    "\n",
    "2. **Semantic Search (Embeddings)**\n",
    "   - ‚úÖ Excels at conceptual matching (e.g., \"healthy breakfast\" ‚Üí nutritious recipes)\n",
    "   - ‚ùå May miss exact term matches if semantically distant\n",
    "   - üê¢ Slower: Requires embedding generation\n",
    "\n",
    "3. **Hybrid Search (RRF)**\n",
    "   - ‚úÖ Best of both worlds: Combines lexical + semantic signals\n",
    "   - ‚úÖ Most robust across diverse query types\n",
    "   - ‚öñÔ∏è Tunable with alpha parameter (0=pure semantic, 1=pure BM25)\n",
    "\n",
    "**Recommendation:** Use hybrid search with `alpha=0.5` as default for production RAG systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for dashboard\n",
    "output = {\n",
    "    \"mode\": MODE,\n",
    "    \"sample_size\": SAMPLE_SIZE,\n",
    "    \"k\": k,\n",
    "    \"queries\": results,\n",
    "    \"summary\": {\n",
    "        \"avg_bm25_precision\": float(summary['BM25'].mean()),\n",
    "        \"avg_semantic_precision\": float(summary['Semantic'].mean()),\n",
    "        \"avg_hybrid_precision\": float(summary['Hybrid'].mean()),\n",
    "        \"improvement_over_bm25\": float((summary['Hybrid'].mean() - summary['BM25'].mean()) / summary['BM25'].mean() * 100),\n",
    "        \"improvement_over_semantic\": float((summary['Hybrid'].mean() - summary['Semantic'].mean()) / summary['Semantic'].mean() * 100)\n",
    "    }\n",
    "}\n",
    "\n",
    "os.makedirs('results', exist_ok=True)\n",
    "with open('results/hybrid_search_results.json', 'w') as f:\n",
    "    json.dump(output, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úÖ Results saved to: lesson-12/results/hybrid_search_results.json\")\n",
    "print(f\"\\nüéØ Hybrid search improved precision by:\")\n",
    "print(f\"  vs BM25:     {output['summary']['improvement_over_bm25']:+.1f}%\")\n",
    "print(f\"  vs Semantic: {output['summary']['improvement_over_semantic']:+.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Tune Alpha:** Experiment with different `alpha` values (0.3, 0.5, 0.7) in `hybrid_search()`\n",
    "2. **Try RRF:** Use `reciprocal_rank_fusion()` for more sophisticated merging\n",
    "3. **Context Quality:** Complete `chunking_optimization.ipynb` to optimize chunk size\n",
    "4. **Advanced Retrieval:** Study `lesson-12/hybrid_search_strategies.md` for query expansion techniques\n",
    "\n",
    "**Related Tutorials:**\n",
    "- [Concept: Hybrid Search Strategies](hybrid_search_strategies.md)\n",
    "- [Concept: Context Quality Evaluation](context_quality_evaluation.md)\n",
    "- [Homework 4: RAG Evaluation](../homeworks/hw4/TUTORIAL_INDEX.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
