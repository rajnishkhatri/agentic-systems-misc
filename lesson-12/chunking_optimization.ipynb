{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking Optimization: Finding the Sweet Spot\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Compare fixed-size, semantic, and contextual chunking strategies\n",
    "- Measure impact of chunk size on retrieval quality\n",
    "- Understand trade-offs between chunk granularity and context\n",
    "- Implement Anthropic's contextual retrieval augmentation\n",
    "\n",
    "**Execution Time:** <5 minutes (DEMO mode), ~12 minutes (FULL mode)  \n",
    "**Cost Estimate:** $0.20 (DEMO), $1.00 (FULL)\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "from backend.semantic_retrieval import generate_embeddings, build_vector_index, semantic_search\n",
    "from backend.context_judges import ContextPrecisionJudge, ContextRecallJudge\n",
    "import os\n",
    "\n",
    "# Set execution mode\n",
    "MODE = os.getenv(\"EXECUTION_MODE\", \"DEMO\")\n",
    "print(f\"üîß Execution Mode: {MODE}\")\n",
    "\n",
    "# Load recipe data\n",
    "with open('../homeworks/hw4/data/processed_recipes.json', 'r') as f:\n",
    "    recipes = json.load(f)\n",
    "\n",
    "SAMPLE_SIZE = 30 if MODE == \"DEMO\" else 100\n",
    "recipes = recipes[:SAMPLE_SIZE]\n",
    "\n",
    "print(f\"üìö Loaded {len(recipes)} recipes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking Strategies Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_size_chunking(text: str, chunk_size: int = 200, overlap: int = 50) -> List[str]:\n",
    "    \"\"\"Split text into fixed-size chunks with overlap.\"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = ' '.join(words[i:i + chunk_size])\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "def semantic_chunking(text: str, max_chunk_size: int = 300) -> List[str]:\n",
    "    \"\"\"Split text at natural boundaries (periods, newlines).\"\"\"\n",
    "    # Split by periods and newlines\n",
    "    sentences = [s.strip() for s in text.replace('\\n', '. ').split('. ') if s.strip()]\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_size = 0\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        sentence_size = len(sentence.split())\n",
    "        \n",
    "        if current_size + sentence_size > max_chunk_size and current_chunk:\n",
    "            chunks.append('. '.join(current_chunk) + '.')\n",
    "            current_chunk = [sentence]\n",
    "            current_size = sentence_size\n",
    "        else:\n",
    "            current_chunk.append(sentence)\n",
    "            current_size += sentence_size\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append('. '.join(current_chunk) + '.')\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "def contextual_chunking(text: str, document_context: str, chunk_size: int = 200) -> List[str]:\n",
    "    \"\"\"Add document context to each chunk (Anthropic's method).\"\"\"\n",
    "    base_chunks = fixed_size_chunking(text, chunk_size=chunk_size, overlap=50)\n",
    "    \n",
    "    # Prepend context to each chunk\n",
    "    contextual_chunks = [\n",
    "        f\"[Document: {document_context}] {chunk}\"\n",
    "        for chunk in base_chunks\n",
    "    ]\n",
    "    \n",
    "    return contextual_chunks\n",
    "\n",
    "\n",
    "print(\"‚úÖ Chunking strategies defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Chunked Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare document texts\n",
    "documents = []\n",
    "for recipe in recipes:\n",
    "    doc = f\"{recipe['name']}. {recipe['description']}\"\n",
    "    documents.append({\n",
    "        \"text\": doc,\n",
    "        \"name\": recipe['name'],\n",
    "        \"ingredients\": recipe['ingredients'][:10]\n",
    "    })\n",
    "\n",
    "# Test different chunking strategies\n",
    "chunking_configs = [\n",
    "    {\"name\": \"Fixed-100\", \"strategy\": \"fixed\", \"chunk_size\": 100, \"overlap\": 25},\n",
    "    {\"name\": \"Fixed-200\", \"strategy\": \"fixed\", \"chunk_size\": 200, \"overlap\": 50},\n",
    "    {\"name\": \"Fixed-400\", \"strategy\": \"fixed\", \"chunk_size\": 400, \"overlap\": 100},\n",
    "    {\"name\": \"Semantic-300\", \"strategy\": \"semantic\", \"max_chunk_size\": 300},\n",
    "    {\"name\": \"Contextual-200\", \"strategy\": \"contextual\", \"chunk_size\": 200},\n",
    "]\n",
    "\n",
    "if MODE == \"DEMO\":\n",
    "    chunking_configs = chunking_configs[:3]  # Test only fixed-size variants\n",
    "\n",
    "print(f\"üîç Testing {len(chunking_configs)} chunking strategies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chunked versions\n",
    "chunked_corpora = {}\n",
    "\n",
    "for config in chunking_configs:\n",
    "    all_chunks = []\n",
    "    chunk_metadata = []  # Track which document each chunk belongs to\n",
    "    \n",
    "    for doc_idx, doc in enumerate(documents):\n",
    "        if config[\"strategy\"] == \"fixed\":\n",
    "            chunks = fixed_size_chunking(\n",
    "                doc[\"text\"],\n",
    "                chunk_size=config[\"chunk_size\"],\n",
    "                overlap=config[\"overlap\"]\n",
    "            )\n",
    "        elif config[\"strategy\"] == \"semantic\":\n",
    "            chunks = semantic_chunking(\n",
    "                doc[\"text\"],\n",
    "                max_chunk_size=config[\"max_chunk_size\"]\n",
    "            )\n",
    "        elif config[\"strategy\"] == \"contextual\":\n",
    "            context = f\"Recipe: {doc['name']}\"\n",
    "            chunks = contextual_chunking(\n",
    "                doc[\"text\"],\n",
    "                document_context=context,\n",
    "                chunk_size=config[\"chunk_size\"]\n",
    "            )\n",
    "        \n",
    "        for chunk in chunks:\n",
    "            all_chunks.append(chunk)\n",
    "            chunk_metadata.append(doc_idx)\n",
    "    \n",
    "    chunked_corpora[config[\"name\"]] = {\n",
    "        \"chunks\": all_chunks,\n",
    "        \"metadata\": chunk_metadata,\n",
    "        \"config\": config\n",
    "    }\n",
    "    \n",
    "    print(f\"  {config['name']}: {len(all_chunks)} chunks (avg: {len(all_chunks)/len(documents):.1f} chunks/doc)\")\n",
    "\n",
    "print(\"\\n‚úÖ All chunked corpora created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Vector Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ Building vector indices (this may take 2-5 minutes)...\\n\")\n",
    "\n",
    "indices = {}\n",
    "\n",
    "for name, corpus in chunked_corpora.items():\n",
    "    print(f\"  Building index for {name}...\")\n",
    "    embeddings = generate_embeddings(corpus[\"chunks\"])\n",
    "    index = build_vector_index(embeddings)\n",
    "    indices[name] = {\n",
    "        \"index\": index,\n",
    "        \"embeddings\": embeddings,\n",
    "        \"chunks\": corpus[\"chunks\"],\n",
    "        \"metadata\": corpus[\"metadata\"]\n",
    "    }\n",
    "\n",
    "print(\"\\n‚úÖ All indices built\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation: Retrieval Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test queries\n",
    "test_queries = [\n",
    "    \"creamy pasta with cheese\",\n",
    "    \"healthy vegetarian dinner\",\n",
    "    \"quick chocolate dessert\",\n",
    "    \"comfort food for winter\",\n",
    "]\n",
    "\n",
    "if MODE == \"DEMO\":\n",
    "    test_queries = test_queries[:2]\n",
    "\n",
    "print(f\"üîç Testing {len(test_queries)} queries across {len(chunking_configs)} chunking strategies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize judges\n",
    "precision_judge = ContextPrecisionJudge()\n",
    "\n",
    "results = []\n",
    "k = 5  # Top-5 retrieval\n",
    "\n",
    "for query_idx, query in enumerate(test_queries):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query {query_idx+1}/{len(test_queries)}: '{query}'\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    query_embedding = generate_embeddings([query])[0]\n",
    "    \n",
    "    for strategy_name, index_data in indices.items():\n",
    "        # Retrieve top-k chunks\n",
    "        search_results = semantic_search(query_embedding, index_data[\"index\"], k=k)\n",
    "        retrieved_chunks = [index_data[\"chunks\"][idx] for idx, score in search_results]\n",
    "        \n",
    "        # Evaluate precision\n",
    "        precision_eval = precision_judge.evaluate(query, retrieved_chunks)\n",
    "        \n",
    "        # Calculate diversity (how many unique documents retrieved)\n",
    "        retrieved_doc_ids = [index_data[\"metadata\"][idx] for idx, score in search_results]\n",
    "        diversity = len(set(retrieved_doc_ids)) / k\n",
    "        \n",
    "        print(f\"  {strategy_name:20s} Precision: {precision_eval['precision']:.2f}, Diversity: {diversity:.2f}\")\n",
    "        \n",
    "        results.append({\n",
    "            \"query\": query,\n",
    "            \"strategy\": strategy_name,\n",
    "            \"precision\": precision_eval['precision'],\n",
    "            \"diversity\": diversity,\n",
    "            \"top_chunk\": retrieved_chunks[0][:100] + \"...\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: Find Optimal Chunk Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create summary dataframe\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Aggregate by strategy\n",
    "summary = df.groupby('strategy').agg({\n",
    "    'precision': 'mean',\n",
    "    'diversity': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "summary.columns = ['Strategy', 'Avg Precision', 'Avg Diversity']\n",
    "summary = summary.sort_values('Avg Precision', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä CHUNKING STRATEGY COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "# Find best strategy\n",
    "best_strategy = summary.iloc[0]\n",
    "print(f\"\\nüèÜ Best Strategy: {best_strategy['Strategy']}\")\n",
    "print(f\"   Precision: {best_strategy['Avg Precision']:.3f}\")\n",
    "print(f\"   Diversity: {best_strategy['Avg Diversity']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "**Trade-offs:**\n",
    "\n",
    "1. **Small Chunks (100-150 words)**\n",
    "   - ‚úÖ High precision: Retrieves focused content\n",
    "   - ‚ùå Low diversity: Multiple chunks from same document\n",
    "   - ‚ö†Ô∏è Risk: May lose important context\n",
    "\n",
    "2. **Medium Chunks (200-300 words)**\n",
    "   - ‚úÖ Balanced precision and context\n",
    "   - ‚úÖ Good diversity across documents\n",
    "   - üéØ **Recommended for most RAG applications**\n",
    "\n",
    "3. **Large Chunks (400+ words)**\n",
    "   - ‚úÖ Maximum context preservation\n",
    "   - ‚ùå Lower precision: Includes irrelevant content\n",
    "   - ‚ö†Ô∏è May exceed LLM context windows\n",
    "\n",
    "4. **Semantic Chunking**\n",
    "   - ‚úÖ Respects natural boundaries\n",
    "   - ‚úÖ Better readability\n",
    "   - ‚ö° Variable chunk sizes\n",
    "\n",
    "5. **Contextual Retrieval (Anthropic)**\n",
    "   - ‚úÖ Adds document metadata to chunks\n",
    "   - ‚úÖ Improves cross-document retrieval\n",
    "   - üí∞ Higher embedding costs (longer chunks)\n",
    "\n",
    "**Recommendation:** Use **200-word semantic chunks** with **50-word overlap** for production systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for dashboard\n",
    "output = {\n",
    "    \"mode\": MODE,\n",
    "    \"sample_size\": SAMPLE_SIZE,\n",
    "    \"strategies_tested\": len(chunking_configs),\n",
    "    \"queries_tested\": len(test_queries),\n",
    "    \"results\": results,\n",
    "    \"summary\": summary.to_dict(orient='records'),\n",
    "    \"best_strategy\": {\n",
    "        \"name\": best_strategy['Strategy'],\n",
    "        \"precision\": float(best_strategy['Avg Precision']),\n",
    "        \"diversity\": float(best_strategy['Avg Diversity'])\n",
    "    }\n",
    "}\n",
    "\n",
    "os.makedirs('results', exist_ok=True)\n",
    "with open('results/chunking_comparison.json', 'w') as f:\n",
    "    json.dump(output, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úÖ Results saved to: lesson-12/results/chunking_comparison.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Advanced Chunking:** Implement recursive text splitting (LangChain `RecursiveCharacterTextSplitter`)\n",
    "2. **Context Window Aware:** Test chunk sizes against your LLM's context window\n",
    "3. **Domain-Specific:** Tune chunk size for your specific document types\n",
    "4. **Evaluation at Scale:** Run FULL mode with 200+ documents\n",
    "\n",
    "**Related Tutorials:**\n",
    "- [Concept: Context Quality Evaluation](context_quality_evaluation.md)\n",
    "- [Hybrid Search Comparison](hybrid_search_comparison.ipynb)\n",
    "- [Lesson 13: RAG Generation & Attribution](../lesson-13/TUTORIAL_INDEX.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
