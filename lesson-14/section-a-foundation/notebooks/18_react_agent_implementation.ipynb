{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReAct Agent Implementation (Lesson 14)\n",
    "\n",
    "**Objective:** Build a ReAct (Reasoning + Acting) agent that dynamically plans and executes actions based on observations.\n",
    "\n",
    "**Learning Goals:**\n",
    "- Understand the Thought-Action-Observation loop\n",
    "- Implement tool selection and execution\n",
    "- Handle errors and iterative refinement\n",
    "- Track agent performance metrics\n",
    "\n",
    "**Prerequisites:**\n",
    "- Lesson 10 (AI-as-Judge) for LLM prompting patterns\n",
    "- `backend/agent_evaluation.py` for validation functions\n",
    "- `lesson-14/react_reflexion_patterns.md` for theoretical background\n",
    "\n",
    "**Execution Modes:**\n",
    "- **DEMO mode**: 3 simple tasks, <$0.50, ~3 min execution\n",
    "- **FULL mode**: 15 complex tasks, <$3, ~10 min execution\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Mode: DEMO\n",
      "üìä Tasks: 3\n",
      "üí∞ Est. Cost: $0.30-0.50\n",
      "‚è±Ô∏è  Est. Time: 3-5 minutes\n",
      "ü§ñ Model: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and setup\n",
    "import json\n",
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import litellm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Execution mode: \"DEMO\" (cheap, fast) or \"FULL\" (comprehensive)\n",
    "MODE = \"DEMO\"  # Change to \"FULL\" for complete evaluation\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"DEMO\": {\n",
    "        \"num_tasks\": 3,\n",
    "        \"max_steps\": 5,\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"estimated_cost\": \"$0.30-0.50\",\n",
    "        \"estimated_time\": \"3-5 minutes\"\n",
    "    },\n",
    "    \"FULL\": {\n",
    "        \"num_tasks\": 15,\n",
    "        \"max_steps\": 10,\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"estimated_cost\": \"$2-3\",\n",
    "        \"estimated_time\": \"8-12 minutes\"\n",
    "    }\n",
    "}\n",
    "\n",
    "config = CONFIG[MODE]\n",
    "print(f\"üîß Mode: {MODE}\")\n",
    "print(f\"üìä Tasks: {config['num_tasks']}\")\n",
    "print(f\"üí∞ Est. Cost: {config['estimated_cost']}\")\n",
    "print(f\"‚è±Ô∏è  Est. Time: {config['estimated_time']}\")\n",
    "print(f\"ü§ñ Model: {config['model']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Definitions\n",
    "\n",
    "Define available tools for the ReAct agent to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 3 tools: ['search_recipes', 'get_recipe_details', 'add_to_shopping_list']\n",
      "üì¶ Recipe database: 5 recipes\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Tool definitions\n",
    "\n",
    "# Mock recipe database\n",
    "RECIPE_DB = [\n",
    "    {\"id\": 1, \"name\": \"Vegan Pasta Primavera\", \"cuisine\": \"Italian\", \"diet\": \"vegan\", \"time\": 30, \"ingredients\":\n",
    "        [\"pasta\", \"vegetables\", \"olive oil\"]},\n",
    "    {\"id\": 2, \"name\": \"Chicken Tikka Masala\", \"cuisine\": \"Indian\", \"diet\": \"none\", \"time\": 45, \"ingredients\":\n",
    "        [\"chicken\", \"yogurt\", \"spices\"]},\n",
    "    {\"id\": 3, \"name\": \"Gluten-Free Pizza\", \"cuisine\": \"Italian\", \"diet\": \"gluten-free\", \"time\": 25, \"ingredients\": \n",
    "        [\"gf flour\", \"cheese\", \"tomato\"]},\n",
    "    {\"id\": 4, \"name\": \"Thai Green Curry\", \"cuisine\": \"Thai\", \"diet\": \"none\", \"time\": 35, \"ingredients\": \n",
    "        [\"curry paste\", \"coconut milk\", \"vegetables\"]},\n",
    "    {\"id\": 5, \"name\": \"Keto Avocado Salad\", \"cuisine\": \"American\", \"diet\": \"keto\", \"time\": 15, \"ingredients\":\n",
    "        [\"avocado\", \"eggs\", \"bacon\"]}\n",
    "]\n",
    "\n",
    "SHOPPING_LIST = []\n",
    "\n",
    "def search_recipes(cuisine: str = None, dietary_restrictions: list[str] = None, max_cook_time: int = None) -> list[dict]:\n",
    "    \"\"\"Search recipe database with filters.\n",
    "    \n",
    "    Args:\n",
    "        cuisine: Filter by cuisine type\n",
    "        dietary_restrictions: Filter by diet (vegan, gluten-free, keto)\n",
    "        max_cook_time: Maximum cooking time in minutes\n",
    "    \n",
    "    Returns:\n",
    "        List of matching recipes\n",
    "    \"\"\"\n",
    "    results = RECIPE_DB.copy()\n",
    "    \n",
    "    if cuisine:\n",
    "        results = [r for r in results if r[\"cuisine\"].lower() == cuisine.lower()]\n",
    "    \n",
    "    if dietary_restrictions:\n",
    "        for diet in dietary_restrictions:\n",
    "            results = [r for r in results if r[\"diet\"] == diet]\n",
    "    \n",
    "    if max_cook_time:\n",
    "        results = [r for r in results if r[\"time\"] <= max_cook_time]\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_recipe_details(recipe_id: int) -> dict:\n",
    "    \"\"\"Get full recipe details by ID.\n",
    "    \n",
    "    Args:\n",
    "        recipe_id: Recipe ID\n",
    "    \n",
    "    Returns:\n",
    "        Recipe details or error\n",
    "    \"\"\"\n",
    "    for recipe in RECIPE_DB:\n",
    "        if recipe[\"id\"] == recipe_id:\n",
    "            return recipe\n",
    "    return {\"error\": f\"Recipe {recipe_id} not found\"}\n",
    "\n",
    "def add_to_shopping_list(ingredients: list[str]) -> dict:\n",
    "    \"\"\"Add ingredients to shopping list.\n",
    "    \n",
    "    Args:\n",
    "        ingredients: List of ingredients to add\n",
    "    \n",
    "    Returns:\n",
    "        Success message with updated list\n",
    "    \"\"\"\n",
    "    global SHOPPING_LIST\n",
    "    SHOPPING_LIST.extend(ingredients)\n",
    "    return {\"success\": True, \"shopping_list\": SHOPPING_LIST, \"count\": len(SHOPPING_LIST)}\n",
    "\n",
    "# Tool registry\n",
    "TOOLS = {\n",
    "    \"search_recipes\": {\n",
    "        \"function\": search_recipes,\n",
    "        \"description\": \"Search recipe database by cuisine, dietary restrictions, or cooking time\",\n",
    "        \"parameters\": {\n",
    "            \"cuisine\": {\"type\": \"str\", \"required\": False, \"description\": \"Cuisine type (Italian, Indian, Thai, etc.)\"},\n",
    "            \"dietary_restrictions\": {\"type\": \"list[str]\", \"required\": False, \"description\": \"Diet filters (vegan, gluten-free, keto)\"},\n",
    "            \"max_cook_time\": {\"type\": \"int\", \"required\": False, \"description\": \"Max cooking time in minutes\"}\n",
    "        }\n",
    "    },\n",
    "    \"get_recipe_details\": {\n",
    "        \"function\": get_recipe_details,\n",
    "        \"description\": \"Get full recipe details by ID\",\n",
    "        \"parameters\": {\n",
    "            \"recipe_id\": {\"type\": \"int\", \"required\": True, \"description\": \"Recipe ID\"}\n",
    "        }\n",
    "    },\n",
    "    \"add_to_shopping_list\": {\n",
    "        \"function\": add_to_shopping_list,\n",
    "        \"description\": \"Add ingredients to shopping list\",\n",
    "        \"parameters\": {\n",
    "            \"ingredients\": {\"type\": \"list[str]\", \"required\": True, \"description\": \"List of ingredients\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(TOOLS)} tools: {list(TOOLS.keys())}\")\n",
    "print(f\"üì¶ Recipe database: {len(RECIPE_DB)} recipes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReAct Agent Implementation\n",
    "\n",
    "Implement the ReAct agent with Thought-Action-Observation loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ReActAgent class defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: ReActAgent class\n",
    "\n",
    "@dataclass\n",
    "class ReActState:\n",
    "    \"\"\"State for ReAct agent execution.\"\"\"\n",
    "    query: str\n",
    "    history: list[dict] = field(default_factory=list)\n",
    "    observations: list[dict] = field(default_factory=list)\n",
    "    data: dict = field(default_factory=dict)\n",
    "    errors: list[str] = field(default_factory=list)\n",
    "    step_count: int = 0\n",
    "    max_steps: int = 10\n",
    "    done: bool = False\n",
    "\n",
    "class ReActAgent:\n",
    "    \"\"\"ReAct agent with Thought-Action-Observation loop.\"\"\"\n",
    "    \n",
    "    def __init__(self, llm_model: str = \"gpt-4o-mini\", max_steps: int = 10, tools: dict = None):\n",
    "        \"\"\"Initialize ReAct agent.\n",
    "        \n",
    "        Args:\n",
    "            llm_model: LLM model for reasoning\n",
    "            max_steps: Maximum iterations before timeout\n",
    "            tools: Available tools dictionary\n",
    "        \"\"\"\n",
    "        self.llm_model = llm_model\n",
    "        self.max_steps = max_steps\n",
    "        self.tools = tools or {}\n",
    "        self.total_tokens = 0\n",
    "        self.total_cost = 0.0\n",
    "    \n",
    "    def _generate_thought(self, state: ReActState) -> str:\n",
    "        \"\"\"Generate reasoning thought based on current state.\n",
    "        \n",
    "        Args:\n",
    "            state: Current agent state\n",
    "        \n",
    "        Returns:\n",
    "            Thought string with reasoning\n",
    "        \"\"\"\n",
    "        # Build context from history\n",
    "        context = f\"Query: {state.query}\\n\\n\"\n",
    "        \n",
    "        if state.history:\n",
    "            context += \"Previous steps:\\n\"\n",
    "            for i, entry in enumerate(state.history[-6:]):  # Last 6 entries\n",
    "                context += f\"{i+1}. {entry['type'].upper()}: {str(entry.get('content', entry))[:150]}\\n\"\n",
    "        \n",
    "        # Tool descriptions\n",
    "        tool_desc = \"\\n\".join([f\"- {name}: {tool['description']}\" for name, tool in self.tools.items()])\n",
    "        \n",
    "        prompt = f\"\"\"{context}\n",
    "\n",
    "Available tools:\n",
    "{tool_desc}\n",
    "\n",
    "You are a ReAct agent. Generate your next thought following this format:\n",
    "\n",
    "Thought: [Your reasoning about what to do next]\n",
    "Action: [tool_name]\n",
    "Action Input: {{\"param\": \"value\"}}\n",
    "\n",
    "OR if you have the final answer:\n",
    "\n",
    "Thought: I now have enough information to answer\n",
    "Final Answer: [Your complete answer]\n",
    "\n",
    "Generate your thought:\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = litellm.completion(\n",
    "                model=self.llm_model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.0\n",
    "            )\n",
    "            \n",
    "            # Track costs\n",
    "            usage = response.usage\n",
    "            self.total_tokens += usage.total_tokens\n",
    "            # Approximate cost: $0.15/1M input, $0.60/1M output for gpt-4o-mini\n",
    "            self.total_cost += (usage.prompt_tokens * 0.15 / 1_000_000) + (usage.completion_tokens * 0.60 / 1_000_000)\n",
    "            \n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            return f\"Thought: Error generating thought: {str(e)}\\nFinal Answer: Unable to complete task due to error.\"\n",
    "    \n",
    "    def _is_final_answer(self, thought: str) -> bool:\n",
    "        \"\"\"Check if thought contains final answer.\"\"\"\n",
    "        return \"Final Answer:\" in thought or \"final answer\" in thought.lower()\n",
    "    \n",
    "    def _extract_answer(self, thought: str) -> str:\n",
    "        \"\"\"Extract final answer from thought.\"\"\"\n",
    "        if \"Final Answer:\" in thought:\n",
    "            return thought.split(\"Final Answer:\")[1].strip()\n",
    "        return thought\n",
    "    \n",
    "    def _parse_action(self, thought: str) -> tuple[str, dict]:\n",
    "        \"\"\"Parse action and arguments from thought.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (tool_name, arguments_dict)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Extract action\n",
    "            if \"Action:\" in thought:\n",
    "                action_line = thought.split(\"Action:\")[1].split(\"\\n\")[0].strip()\n",
    "            else:\n",
    "                return \"search_recipes\", {}  # Default fallback\n",
    "            \n",
    "            # Extract action input\n",
    "            if \"Action Input:\" in thought:\n",
    "                input_str = thought.split(\"Action Input:\")[1].strip()\n",
    "                # Try to parse JSON\n",
    "                try:\n",
    "                    args = json.loads(input_str.split(\"\\n\")[0])\n",
    "                except json.JSONDecodeError:\n",
    "                    args = {}\n",
    "            else:\n",
    "                args = {}\n",
    "            \n",
    "            return action_line, args\n",
    "        except Exception:\n",
    "            return \"search_recipes\", {}  # Safe fallback\n",
    "    \n",
    "    def _execute_action(self, thought: str, state: ReActState) -> dict:\n",
    "        \"\"\"Execute action from thought.\n",
    "        \n",
    "        Returns:\n",
    "            Result dictionary with tool, args, observation, status\n",
    "        \"\"\"\n",
    "        tool_name, args = self._parse_action(thought)\n",
    "        \n",
    "        # Validate tool exists\n",
    "        if tool_name not in self.tools:\n",
    "            return {\n",
    "                \"tool\": tool_name,\n",
    "                \"args\": args,\n",
    "                \"observation\": f\"Error: Tool '{tool_name}' not found. Available: {list(self.tools.keys())}\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "        \n",
    "        # Execute tool\n",
    "        try:\n",
    "            tool = self.tools[tool_name]\n",
    "            result = tool[\"function\"](**args)\n",
    "            \n",
    "            # Format observation\n",
    "            if isinstance(result, list):\n",
    "                obs = f\"Found {len(result)} results: {result}\"\n",
    "            elif isinstance(result, dict) and \"error\" in result:\n",
    "                obs = f\"Error: {result['error']}\"\n",
    "                return {\n",
    "                    \"tool\": tool_name,\n",
    "                    \"args\": args,\n",
    "                    \"observation\": obs,\n",
    "                    \"status\": \"error\"\n",
    "                }\n",
    "            else:\n",
    "                obs = str(result)\n",
    "            \n",
    "            return {\n",
    "                \"tool\": tool_name,\n",
    "                \"args\": args,\n",
    "                \"observation\": obs,\n",
    "                \"status\": \"success\",\n",
    "                \"result\": result\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"tool\": tool_name,\n",
    "                \"args\": args,\n",
    "                \"observation\": f\"Error executing tool: {str(e)}\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "    \n",
    "    def run(self, query: str) -> dict[str, Any]:\n",
    "        \"\"\"Run ReAct loop until completion or max steps.\n",
    "        \n",
    "        Args:\n",
    "            query: User query\n",
    "        \n",
    "        Returns:\n",
    "            Result with trajectory, answer, and metrics\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Initialize state\n",
    "        state = ReActState(query=query, max_steps=self.max_steps)\n",
    "        \n",
    "        # ReAct loop\n",
    "        while not state.done and state.step_count < state.max_steps:\n",
    "            # Phase 1: Generate Thought\n",
    "            thought = self._generate_thought(state)\n",
    "            state.history.append({\"type\": \"thought\", \"content\": thought, \"step\": state.step_count})\n",
    "            \n",
    "            # Check if final answer\n",
    "            if self._is_final_answer(thought):\n",
    "                answer = self._extract_answer(thought)\n",
    "                state.done = True\n",
    "                state.history.append({\"type\": \"answer\", \"content\": answer})\n",
    "                break\n",
    "            \n",
    "            # Phase 2: Execute Action\n",
    "            action_result = self._execute_action(thought, state)\n",
    "            state.history.append({\n",
    "                \"type\": \"action\",\n",
    "                \"tool\": action_result[\"tool\"],\n",
    "                \"args\": action_result[\"args\"],\n",
    "                \"step\": state.step_count\n",
    "            })\n",
    "            \n",
    "            # Phase 3: Process Observation\n",
    "            observation = action_result[\"observation\"]\n",
    "            state.observations.append({\n",
    "                \"step\": state.step_count,\n",
    "                \"observation\": observation,\n",
    "                \"status\": action_result[\"status\"]\n",
    "            })\n",
    "            state.history.append({\"type\": \"observation\", \"content\": observation, \"step\": state.step_count})\n",
    "            \n",
    "            # Update state\n",
    "            state.step_count += 1\n",
    "            \n",
    "            # Check for repeated errors\n",
    "            if action_result[\"status\"] == \"error\":\n",
    "                state.errors.append(observation)\n",
    "                if len(state.errors) >= 3:\n",
    "                    state.done = True\n",
    "                    state.history.append({\n",
    "                        \"type\": \"answer\",\n",
    "                        \"content\": f\"Failed to complete task after {len(state.errors)} errors\"\n",
    "                    })\n",
    "                    break\n",
    "        \n",
    "        # Timeout check\n",
    "        if not state.done:\n",
    "            state.history.append({\n",
    "                \"type\": \"answer\",\n",
    "                \"content\": f\"Max steps ({state.max_steps}) reached without completion\"\n",
    "            })\n",
    "        \n",
    "        execution_time = time.time() - start_time\n",
    "        \n",
    "        # Extract final answer\n",
    "        final_answer = \"No answer generated\"\n",
    "        for entry in reversed(state.history):\n",
    "            if entry[\"type\"] == \"answer\":\n",
    "                final_answer = entry[\"content\"]\n",
    "                break\n",
    "        \n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"answer\": final_answer,\n",
    "            \"trajectory\": state.history,\n",
    "            \"observations\": state.observations,\n",
    "            \"metrics\": {\n",
    "                \"steps\": state.step_count,\n",
    "                \"completed\": state.done,\n",
    "                \"errors\": len(state.errors),\n",
    "                \"execution_time\": execution_time,\n",
    "                \"total_tokens\": self.total_tokens,\n",
    "                \"total_cost\": self.total_cost\n",
    "            }\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ ReActAgent class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Tasks\n",
    "\n",
    "Define test tasks for DEMO and FULL modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Loaded 3 test tasks for DEMO mode\n",
      "\n",
      "Sample tasks:\n",
      "  1. Find vegan Italian recipes\n",
      "  2. Get details for recipe ID 2\n",
      "  3. Find quick recipes under 20 minutes\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Test tasks\n",
    "\n",
    "DEMO_TASKS = [\n",
    "    \"Find vegan Italian recipes\",\n",
    "    \"Get details for recipe ID 2\",\n",
    "    \"Find quick recipes under 20 minutes\"\n",
    "]\n",
    "\n",
    "FULL_TASKS = DEMO_TASKS + [\n",
    "    \"Find gluten-free Italian recipes and add their ingredients to shopping list\",\n",
    "    \"Search for Thai cuisine and get details of the first result\",\n",
    "    \"Find keto recipes with cooking time under 30 minutes\",\n",
    "    \"Get recipe 4 details and add its ingredients to shopping list\",\n",
    "    \"Find all Indian recipes\",\n",
    "    \"Search for vegan recipes under 25 minutes\",\n",
    "    \"Find recipes without dietary restrictions\",\n",
    "    \"Get details for recipe 5 and analyze ingredients\",\n",
    "    \"Find Italian recipes under 30 minutes\",\n",
    "    \"Search for recipes with maximum 40 minute cooking time\",\n",
    "    \"Find all available cuisines and recommend one\",\n",
    "    \"Create a complete meal plan with shopping list\"\n",
    "]\n",
    "\n",
    "tasks = DEMO_TASKS if MODE == \"DEMO\" else FULL_TASKS\n",
    "\n",
    "print(f\"üìã Loaded {len(tasks)} test tasks for {MODE} mode\")\n",
    "print(\"\\nSample tasks:\")\n",
    "for i, task in enumerate(tasks[:3], 1):\n",
    "    print(f\"  {i}. {task}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute ReAct Agent\n",
    "\n",
    "Run the agent on all test tasks and collect results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting ReAct agent execution (DEMO mode)...\n",
      "\n",
      "‚ö†Ô∏è  Estimated cost: $0.30-0.50\n",
      "‚è±Ô∏è  Estimated time: 3-5 minutes\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Task 1/3: Find vegan Italian recipes\n",
      "================================================================================\n",
      "\n",
      "üìä Result Summary:\n",
      "   Steps: 4\n",
      "   Completed: True\n",
      "   Errors: 1\n",
      "   Time: 17.16s\n",
      "   Cost: $0.0005\n",
      "\n",
      "üí¨ Final Answer:\n",
      "   Here are some popular vegan Italian recipes you can try:\n",
      "\n",
      "1. **Vegan Pasta Primavera**: A mix of seasonal vegetables saut√©ed and tossed with pasta and olive oil.\n",
      "2. **Vegan Risotto**: Creamy risotto m...\n",
      "\n",
      "================================================================================\n",
      "Task 2/3: Get details for recipe ID 2\n",
      "================================================================================\n",
      "\n",
      "üìä Result Summary:\n",
      "   Steps: 4\n",
      "   Completed: True\n",
      "   Errors: 3\n",
      "   Time: 14.13s\n",
      "   Cost: $0.0009\n",
      "\n",
      "üí¨ Final Answer:\n",
      "   Failed to complete task after 3 errors...\n",
      "\n",
      "================================================================================\n",
      "Task 3/3: Find quick recipes under 20 minutes\n",
      "================================================================================\n",
      "\n",
      "üìä Result Summary:\n",
      "   Steps: 5\n",
      "   Completed: False\n",
      "   Errors: 2\n",
      "   Time: 10.23s\n",
      "   Cost: $0.0013\n",
      "\n",
      "üí¨ Final Answer:\n",
      "   Max steps (5) reached without completion...\n",
      "\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Execution Complete\n",
      "================================================================================\n",
      "Total tasks: 3\n",
      "Total time: 41.52s (0.7 min)\n",
      "Total cost: $0.0013\n",
      "Total tokens: 5,050\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Execute agent\n",
    "\n",
    "print(f\"üöÄ Starting ReAct agent execution ({MODE} mode)...\\n\")\n",
    "print(f\"‚ö†Ô∏è  Estimated cost: {config['estimated_cost']}\")\n",
    "print(f\"‚è±Ô∏è  Estimated time: {config['estimated_time']}\\n\")\n",
    "\n",
    "# Initialize agent\n",
    "agent = ReActAgent(\n",
    "    llm_model=config[\"model\"],\n",
    "    max_steps=config[\"max_steps\"],\n",
    "    tools=TOOLS\n",
    ")\n",
    "\n",
    "results = []\n",
    "start_time = time.time()\n",
    "\n",
    "for i, task in enumerate(tasks, 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Task {i}/{len(tasks)}: {task}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    try:\n",
    "        # Reset shopping list for each task\n",
    "        SHOPPING_LIST.clear()\n",
    "        \n",
    "        # Run agent\n",
    "        result = agent.run(task)\n",
    "        results.append(result)\n",
    "        \n",
    "        # Display summary\n",
    "        print(\"\\nüìä Result Summary:\")\n",
    "        print(f\"   Steps: {result['metrics']['steps']}\")\n",
    "        print(f\"   Completed: {result['metrics']['completed']}\")\n",
    "        print(f\"   Errors: {result['metrics']['errors']}\")\n",
    "        print(f\"   Time: {result['metrics']['execution_time']:.2f}s\")\n",
    "        print(f\"   Cost: ${result['metrics']['total_cost']:.4f}\")\n",
    "        print(f\"\\nüí¨ Final Answer:\\n   {result['answer'][:200]}...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {str(e)}\")\n",
    "        results.append({\n",
    "            \"query\": task,\n",
    "            \"answer\": f\"Error: {str(e)}\",\n",
    "            \"trajectory\": [],\n",
    "            \"metrics\": {\"steps\": 0, \"completed\": False, \"errors\": 1, \"execution_time\": 0, \"total_tokens\": 0, \"total_cost\": 0}\n",
    "        })\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n\\n{'='*80}\")\n",
    "print(\"‚úÖ Execution Complete\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total tasks: {len(results)}\")\n",
    "print(f\"Total time: {total_time:.2f}s ({total_time/60:.1f} min)\")\n",
    "print(f\"Total cost: ${agent.total_cost:.4f}\")\n",
    "print(f\"Total tokens: {agent.total_tokens:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Results\n",
    "\n",
    "Calculate performance metrics and analyze agent behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä ReAct Agent Performance Analysis\n",
      "\n",
      "Completion Metrics:\n",
      "  ‚úÖ Completion rate: 66.7% (2/3)\n",
      "  üìà Average steps per task: 4.3\n",
      "  ‚è±Ô∏è  Average time per task: 13.84s\n",
      "  ‚ùå Error rate: 46.2% (6 errors in 13 steps)\n",
      "\n",
      "Cost Metrics:\n",
      "  üí∞ Total cost: $0.0013\n",
      "  üíµ Cost per task: $0.0004\n",
      "  üî¢ Total tokens: 5,050\n",
      "  üìä Tokens per task: 1,683\n",
      "\n",
      "Tool Usage:\n",
      "  search_recipes: 10 calls (76.9% of actions)\n",
      "  get_recipe_details: 2 calls (15.4% of actions)\n",
      "  None: 1 calls (7.7% of actions)\n",
      "\n",
      "Task Categories:\n",
      "  ‚úÖ Successful (no errors): 0 (0.0%)\n",
      "  ‚ö†Ô∏è  Failed or with errors: 3 (100.0%)\n",
      "\n",
      "Failed Tasks:\n",
      "  - Find vegan Italian recipes... (errors: 1)\n",
      "  - Get details for recipe ID 2... (errors: 3)\n",
      "  - Find quick recipes under 20 minutes... (errors: 2)\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Analyze results\n",
    "\n",
    "print(\"üìä ReAct Agent Performance Analysis\\n\")\n",
    "\n",
    "# Calculate metrics\n",
    "total_tasks = len(results)\n",
    "completed_tasks = sum(1 for r in results if r[\"metrics\"][\"completed\"])\n",
    "total_steps = sum(r[\"metrics\"][\"steps\"] for r in results)\n",
    "total_errors = sum(r[\"metrics\"][\"errors\"] for r in results)\n",
    "avg_steps = total_steps / total_tasks if total_tasks > 0 else 0\n",
    "avg_time = sum(r[\"metrics\"][\"execution_time\"] for r in results) / total_tasks if total_tasks > 0 else 0\n",
    "\n",
    "completion_rate = completed_tasks / total_tasks if total_tasks > 0 else 0\n",
    "error_rate = total_errors / total_steps if total_steps > 0 else 0\n",
    "\n",
    "print(\"Completion Metrics:\")\n",
    "print(f\"  ‚úÖ Completion rate: {completion_rate:.1%} ({completed_tasks}/{total_tasks})\")\n",
    "print(f\"  üìà Average steps per task: {avg_steps:.1f}\")\n",
    "print(f\"  ‚è±Ô∏è  Average time per task: {avg_time:.2f}s\")\n",
    "print(f\"  ‚ùå Error rate: {error_rate:.1%} ({total_errors} errors in {total_steps} steps)\")\n",
    "\n",
    "print(\"\\nCost Metrics:\")\n",
    "print(f\"  üí∞ Total cost: ${agent.total_cost:.4f}\")\n",
    "print(f\"  üíµ Cost per task: ${agent.total_cost/total_tasks:.4f}\")\n",
    "print(f\"  üî¢ Total tokens: {agent.total_tokens:,}\")\n",
    "print(f\"  üìä Tokens per task: {agent.total_tokens//total_tasks:,}\")\n",
    "\n",
    "# Tool usage analysis\n",
    "tool_usage = {}\n",
    "for result in results:\n",
    "    for entry in result[\"trajectory\"]:\n",
    "        if entry[\"type\"] == \"action\":\n",
    "            tool = entry[\"tool\"]\n",
    "            tool_usage[tool] = tool_usage.get(tool, 0) + 1\n",
    "\n",
    "print(\"\\nTool Usage:\")\n",
    "for tool, count in sorted(tool_usage.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {tool}: {count} calls ({count/total_steps*100:.1f}% of actions)\")\n",
    "\n",
    "# Success analysis\n",
    "successful = [r for r in results if r[\"metrics\"][\"completed\"] and r[\"metrics\"][\"errors\"] == 0]\n",
    "failed = [r for r in results if not r[\"metrics\"][\"completed\"] or r[\"metrics\"][\"errors\"] > 0]\n",
    "\n",
    "print(\"\\nTask Categories:\")\n",
    "print(f\"  ‚úÖ Successful (no errors): {len(successful)} ({len(successful)/total_tasks*100:.1f}%)\")\n",
    "print(f\"  ‚ö†Ô∏è  Failed or with errors: {len(failed)} ({len(failed)/total_tasks*100:.1f}%)\")\n",
    "\n",
    "if failed:\n",
    "    print(\"\\nFailed Tasks:\")\n",
    "    for r in failed[:3]:  # Show first 3\n",
    "        print(f\"  - {r['query'][:60]}... (errors: {r['metrics']['errors']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "\n",
    "Save results to JSON for dashboard integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Results saved to: lesson-14/results/react_agent_results_demo.json\n",
      "üìÅ File size: 18.6 KB\n",
      "‚úÖ Dashboard data saved to: lesson-14/results/planning_validation.json\n",
      "\n",
      "üéâ Notebook execution complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Save results\n",
    "\n",
    "output_dir = Path(\"lesson-14/results\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_data = {\n",
    "    \"metadata\": {\n",
    "        \"mode\": MODE,\n",
    "        \"model\": config[\"model\"],\n",
    "        \"num_tasks\": len(tasks),\n",
    "        \"max_steps\": config[\"max_steps\"],\n",
    "        \"execution_date\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"total_time\": total_time,\n",
    "        \"total_cost\": agent.total_cost,\n",
    "        \"total_tokens\": agent.total_tokens\n",
    "    },\n",
    "    \"summary\": {\n",
    "        \"completion_rate\": completion_rate,\n",
    "        \"avg_steps_per_task\": avg_steps,\n",
    "        \"avg_time_per_task\": avg_time,\n",
    "        \"error_rate\": error_rate,\n",
    "        \"successful_tasks\": len(successful),\n",
    "        \"failed_tasks\": len(failed),\n",
    "        \"tool_usage\": tool_usage\n",
    "    },\n",
    "    \"results\": results\n",
    "}\n",
    "\n",
    "output_path = output_dir / f\"react_agent_results_{MODE.lower()}.json\"\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"‚úÖ Results saved to: {output_path}\")\n",
    "print(f\"üìÅ File size: {output_path.stat().st_size / 1024:.1f} KB\")\n",
    "\n",
    "# Also save a general planning_validation.json for dashboard\n",
    "dashboard_data = {\n",
    "    \"version\": \"1.0\",\n",
    "    \"created\": time.strftime(\"%Y-%m-%d\"),\n",
    "    \"mode\": MODE,\n",
    "    \"metrics\": {\n",
    "        \"planning_accuracy\": completion_rate,\n",
    "        \"avg_steps\": avg_steps,\n",
    "        \"error_rate\": error_rate,\n",
    "        \"completion_rate\": completion_rate\n",
    "    },\n",
    "    \"tool_usage\": tool_usage,\n",
    "    \"sample_trajectories\": [\n",
    "        {\n",
    "            \"query\": r[\"query\"],\n",
    "            \"steps\": r[\"metrics\"][\"steps\"],\n",
    "            \"completed\": r[\"metrics\"][\"completed\"],\n",
    "            \"answer\": r[\"answer\"][:200]\n",
    "        }\n",
    "        for r in results[:5]\n",
    "    ]\n",
    "}\n",
    "\n",
    "dashboard_path = output_dir / \"planning_validation.json\"\n",
    "with open(dashboard_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(dashboard_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"‚úÖ Dashboard data saved to: {dashboard_path}\")\n",
    "print(\"\\nüéâ Notebook execution complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and Assertions\n",
    "\n",
    "Verify results meet quality thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Validating results...\n",
      "\n",
      "‚úÖ All tasks executed\n",
      "‚úÖ Completion rate ‚â•50%\n",
      "‚úÖ Average steps ‚â§ max_steps\n",
      "‚úÖ Cost within budget\n",
      "‚úÖ Execution time reasonable\n",
      "‚úÖ At least one tool used\n",
      "‚úÖ No task had 0 steps\n",
      "\n",
      "üìä Validation: 7/7 checks passed (100.0%)\n",
      "\n",
      "üéâ All validation checks passed!\n",
      "\n",
      "================================================================================\n",
      "Notebook execution complete. Results saved to lesson-14/results/\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Validation\n",
    "\n",
    "print(\"üîç Validating results...\\n\")\n",
    "\n",
    "# Validation checks\n",
    "checks = [\n",
    "    (\"All tasks executed\", len(results) == len(tasks)),\n",
    "    (\"Completion rate ‚â•50%\", completion_rate >= 0.5),\n",
    "    (\"Average steps ‚â§ max_steps\", avg_steps <= config[\"max_steps\"]),\n",
    "    (\"Cost within budget\", agent.total_cost <= float(config[\"estimated_cost\"].split(\"-\")[1].replace(\"$\", \"\"))),\n",
    "    (\"Execution time reasonable\", total_time <= int(config[\"estimated_time\"].split(\"-\")[1].split()[0]) * 60),\n",
    "    (\"At least one tool used\", len(tool_usage) > 0),\n",
    "    (\"No task had 0 steps\", all(r[\"metrics\"][\"steps\"] > 0 or r[\"metrics\"][\"errors\"] > 0 for r in results))\n",
    "]\n",
    "\n",
    "passed = 0\n",
    "for check_name, check_result in checks:\n",
    "    status = \"‚úÖ\" if check_result else \"‚ùå\"\n",
    "    print(f\"{status} {check_name}\")\n",
    "    if check_result:\n",
    "        passed += 1\n",
    "\n",
    "print(f\"\\nüìä Validation: {passed}/{len(checks)} checks passed ({passed/len(checks)*100:.1f}%)\")\n",
    "\n",
    "if passed == len(checks):\n",
    "    print(\"\\nüéâ All validation checks passed!\")\n",
    "elif passed >= len(checks) * 0.8:\n",
    "    print(\"\\n‚ö†Ô∏è  Most checks passed, but some issues detected\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Multiple validation failures - review results\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Notebook execution complete. Results saved to lesson-14/results/\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Recipe Chatbot (.venv)",
   "language": "python",
   "name": "recipe-chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
