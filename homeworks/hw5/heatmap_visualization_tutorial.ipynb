{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Heatmap Visualization Tutorial: Failure Transition Matrices\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By completing this tutorial, you will be able to:\n",
        "- âœ… Load and explore labeled failure trace data\n",
        "- âœ… Extract failure transitions from trace records\n",
        "- âœ… Build transition count matrices programmatically\n",
        "- âœ… Configure seaborn heatmaps for effective visualization\n",
        "- âœ… Interpret heatmap patterns to identify bottlenecks\n",
        "- âœ… Export publication-quality heatmap visualizations\n",
        "- âœ… Perform basic bottleneck analysis from matrices\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- Completed [Transition Analysis Concepts](transition_analysis_concepts.md)\n",
        "- Understanding of Python dictionaries and lists\n",
        "- Familiarity with pandas and matplotlib\n",
        "\n",
        "## Estimated Time\n",
        "\n",
        "**Execution Time:** 15-20 minutes  \n",
        "**Hands-on Exercises:** 10-15 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard library\n",
        "import json\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "# Data manipulation and visualization\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configure visualization defaults\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "plt.rcParams['figure.figsize'] = (10, 8)\n",
        "\n",
        "print(\"\\u2713 Imports successful\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Labeled Trace Data\n",
        "\n",
        "We'll load the pre-labeled failure traces from `data/labeled_traces.json`. Each trace contains:\n",
        "- `trace_id`: Unique identifier\n",
        "- `last_success_state`: Final state that succeeded\n",
        "- `first_failure_state`: First state that failed\n",
        "- `messages`: Full conversation history\n",
        "- Additional metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define file paths\n",
        "DATA_FILE = Path(\"data/labeled_traces.json\")\n",
        "\n",
        "# Load traces\n",
        "if not DATA_FILE.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Data file not found: {DATA_FILE}\\n\"\n",
        "        \"Make sure you're running this notebook from the homeworks/hw5/ directory.\"\n",
        "    )\n",
        "\n",
        "with open(DATA_FILE, 'r') as f:\n",
        "    traces = json.load(f)\n",
        "\n",
        "print(f\"âœ“ Loaded {len(traces)} labeled failure traces\")\n",
        "print(f\"âœ“ File: {DATA_FILE.resolve()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Explore a Sample Trace\n",
        "\n",
        "Let's examine the structure of a single trace to understand what data we're working with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display first trace (pretty-printed)\n",
        "sample_trace = traces[0]\n",
        "\n",
        "print(\"Sample Trace Structure:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Trace ID: {sample_trace['trace_id']}\")\n",
        "print(f\"Customer Persona: {sample_trace.get('customer_persona', 'N/A')}\")\n",
        "print(f\"Last Success State: {sample_trace['last_success_state']}\")\n",
        "print(f\"First Failure State: {sample_trace['first_failure_state']}\")\n",
        "print(f\"Number of Messages: {len(sample_trace.get('messages', []))}\")\n",
        "print(\"\\nFailure Transition:\")\n",
        "print(f\"  {sample_trace['last_success_state']} â†’ {sample_trace['first_failure_state']}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Pipeline States\n",
        "\n",
        "The recipe bot follows a 10-state pipeline. We'll define these states in order to structure our matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 10-state pipeline (in execution order)\n",
        "PIPELINE_STATES = [\n",
        "    \"ParseRequest\",        # LLM: Parse user query\n",
        "    \"PlanToolCalls\",       # LLM: Decide which tools to use\n",
        "    \"GenCustomerArgs\",     # LLM: Generate customer DB arguments\n",
        "    \"GetCustomerProfile\",  # TOOL: Fetch customer profile\n",
        "    \"GenRecipeArgs\",       # LLM: Generate recipe search arguments\n",
        "    \"GetRecipes\",          # TOOL: Search recipe database\n",
        "    \"GenWebArgs\",          # LLM: Generate web search arguments\n",
        "    \"GetWebInfo\",          # TOOL: Perform web search\n",
        "    \"ComposeResponse\",     # LLM: Draft final response\n",
        "    \"DeliverResponse\",     # SYSTEM: Send response to user\n",
        "]\n",
        "\n",
        "# Create state â†’ index mapping\n",
        "STATE_INDEX = {state: idx for idx, state in enumerate(PIPELINE_STATES)}\n",
        "\n",
        "print(f\"âœ“ Pipeline has {len(PIPELINE_STATES)} states\")\n",
        "print(\"\\nState Types:\")\n",
        "print(\"  LLM States:   ParseRequest, PlanToolCalls, GenCustomerArgs, GenRecipeArgs, GenWebArgs, ComposeResponse\")\n",
        "print(\"  Tool States:  GetCustomerProfile, GetRecipes, GetWebInfo\")\n",
        "print(\"  System State: DeliverResponse\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Extract Failure Transitions\n",
        "\n",
        "A **failure transition** is the pair `(last_success_state, first_failure_state)` for each trace.\n",
        "\n",
        "Let's extract all transitions and count their frequencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_failure_transitions(traces: List[Dict]) -> List[Tuple[str, str]]:\n",
        "    \"\"\"Extract all (last_success, first_failure) pairs from traces.\n",
        "    \n",
        "    Args:\n",
        "        traces: List of labeled trace dictionaries\n",
        "        \n",
        "    Returns:\n",
        "        List of (from_state, to_state) tuples\n",
        "    \"\"\"\n",
        "    transitions = []\n",
        "    \n",
        "    for trace in traces:\n",
        "        from_state = trace.get('last_success_state')\n",
        "        to_state = trace.get('first_failure_state')\n",
        "        \n",
        "        # Validate both states exist and are in our pipeline\n",
        "        if from_state in STATE_INDEX and to_state in STATE_INDEX:\n",
        "            transitions.append((from_state, to_state))\n",
        "        else:\n",
        "            print(f\"âš  Skipped invalid transition in {trace.get('trace_id')}: {from_state} â†’ {to_state}\")\n",
        "    \n",
        "    return transitions\n",
        "\n",
        "# Extract transitions\n",
        "failure_transitions = extract_failure_transitions(traces)\n",
        "\n",
        "print(f\"âœ“ Extracted {len(failure_transitions)} failure transitions\")\n",
        "print(f\"âœ“ Coverage: {len(failure_transitions)}/{len(traces)} traces ({len(failure_transitions)/len(traces)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Count Transition Frequencies\n",
        "\n",
        "Use `Counter` to tally how many times each transition occurs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count transition frequencies\n",
        "transition_counts = Counter(failure_transitions)\n",
        "\n",
        "print(f\"Total unique transitions: {len(transition_counts)}\")\n",
        "print(f\"\\nTop 5 Most Common Failure Transitions:\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for (from_state, to_state), count in transition_counts.most_common(5):\n",
        "    percentage = count / len(failure_transitions) * 100\n",
        "    print(f\"{from_state:20} â†’ {to_state:20} | Count: {count:3} ({percentage:5.1f}%)\")\n",
        "\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Build Transition Matrix\n",
        "\n",
        "Convert the transition counts into a 10Ã—10 matrix where:\n",
        "- **Rows** = Last successful state\n",
        "- **Columns** = First failing state\n",
        "- **Cell value** = Number of times that transition occurred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_transition_matrix(traces: List[Dict], states: List[str]) -> np.ndarray:\n",
        "    \"\"\"Build transition count matrix from labeled traces.\n",
        "    \n",
        "    Args:\n",
        "        traces: List of labeled trace dictionaries\n",
        "        states: Ordered list of pipeline states\n",
        "        \n",
        "    Returns:\n",
        "        nÃ—n numpy array where n = len(states)\n",
        "    \"\"\"\n",
        "    n = len(states)\n",
        "    matrix = np.zeros((n, n), dtype=int)\n",
        "    state_to_idx = {s: i for i, s in enumerate(states)}\n",
        "    \n",
        "    for trace in traces:\n",
        "        from_state = trace.get('last_success_state')\n",
        "        to_state = trace.get('first_failure_state')\n",
        "        \n",
        "        # Only count valid transitions\n",
        "        if from_state in state_to_idx and to_state in state_to_idx:\n",
        "            i = state_to_idx[from_state]\n",
        "            j = state_to_idx[to_state]\n",
        "            matrix[i, j] += 1\n",
        "    \n",
        "    return matrix\n",
        "\n",
        "# Build matrix\n",
        "transition_matrix = build_transition_matrix(traces, PIPELINE_STATES)\n",
        "\n",
        "print(f\"âœ“ Built {transition_matrix.shape[0]}Ã—{transition_matrix.shape[1]} transition matrix\")\n",
        "print(f\"âœ“ Total failures recorded: {transition_matrix.sum():.0f}\")\n",
        "print(f\"âœ“ Non-zero cells: {np.count_nonzero(transition_matrix)}/{transition_matrix.size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### View Matrix as DataFrame\n",
        "\n",
        "Convert to pandas DataFrame for easier inspection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create labeled DataFrame\n",
        "matrix_df = pd.DataFrame(\n",
        "    transition_matrix,\n",
        "    index=PIPELINE_STATES,\n",
        "    columns=PIPELINE_STATES\n",
        ")\n",
        "\n",
        "print(\"Transition Matrix (rows=last success, columns=first failure):\")\n",
        "print(\"=\" * 100)\n",
        "display(matrix_df)\n",
        "print(\"=\" * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualize with Seaborn Heatmap\n",
        "\n",
        "Create an annotated heatmap to visualize failure patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_transition_heatmap(\n",
        "    matrix: np.ndarray,\n",
        "    states: List[str],\n",
        "    title: str = \"Failure Transition Heatmap\",\n",
        "    cmap: str = \"YlOrRd\",\n",
        "    figsize: Tuple[int, int] = (12, 10)\n",
        ") -> None:\n",
        "    \"\"\"Plot annotated heatmap of transition matrix.\n",
        "    \n",
        "    Args:\n",
        "        matrix: Transition count matrix\n",
        "        states: State labels for axes\n",
        "        title: Plot title\n",
        "        cmap: Seaborn color palette\n",
        "        figsize: Figure dimensions (width, height)\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=figsize)\n",
        "    \n",
        "    # Create heatmap\n",
        "    sns.heatmap(\n",
        "        matrix,\n",
        "        annot=True,           # Show count values in cells\n",
        "        fmt=\"d\",              # Integer format\n",
        "        cmap=cmap,            # Color scheme (yellow â†’ red)\n",
        "        xticklabels=states,\n",
        "        yticklabels=states,\n",
        "        cbar_kws={\"label\": \"Failure Count\"},\n",
        "        square=True,          # Square cells\n",
        "        linewidths=0.5,       # Grid lines\n",
        "        linecolor='gray'\n",
        "    )\n",
        "    \n",
        "    # Formatting\n",
        "    plt.title(title, fontsize=16, fontweight='bold', pad=20)\n",
        "    plt.xlabel(\"First Failure State â†’\", fontsize=12, fontweight='bold')\n",
        "    plt.ylabel(\"Last Success State â†“\", fontsize=12, fontweight='bold')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Generate heatmap\n",
        "plot_transition_heatmap(transition_matrix, PIPELINE_STATES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpret the Heatmap\n",
        "\n",
        "**Reading the Heatmap:**\n",
        "- **Darker cells** = Higher failure counts\n",
        "- **Row** = Where the system last succeeded\n",
        "- **Column** = Where the system first failed\n",
        "- **Diagonal** = State succeeded, then immediately failed on retry (rare)\n",
        "- **Off-diagonal** = Failure in next sequential state (common)\n",
        "\n",
        "**Common Patterns:**\n",
        "1. **Single dark cell** = Clustered bottleneck (most failures at one transition)\n",
        "2. **Dark column** = Specific state fails from multiple predecessors\n",
        "3. **Dark row** = After one state, failures scatter across next states\n",
        "4. **Distributed darkness** = No clear bottleneck (diverse failures)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Bottleneck Analysis\n",
        "\n",
        "Perform quantitative analysis to identify system bottlenecks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Which States Fail Most Often? (Column Sums)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sum failures by column (how often each state fails)\n",
        "column_sums = transition_matrix.sum(axis=0)\n",
        "\n",
        "# Create summary DataFrame\n",
        "failure_by_state = pd.DataFrame({\n",
        "    'State': PIPELINE_STATES,\n",
        "    'Total Failures': column_sums,\n",
        "    'Percentage': column_sums / column_sums.sum() * 100\n",
        "}).sort_values('Total Failures', ascending=False)\n",
        "\n",
        "print(\"States Ranked by Failure Frequency (Column Sums):\")\n",
        "print(\"=\" * 60)\n",
        "display(failure_by_state)\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Identify primary bottleneck\n",
        "primary_bottleneck = failure_by_state.iloc[0]\n",
        "print(f\"\\nðŸ”´ PRIMARY BOTTLENECK: {primary_bottleneck['State']}\")\n",
        "print(f\"   Fails {primary_bottleneck['Total Failures']:.0f} times ({primary_bottleneck['Percentage']:.1f}% of all failures)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### After Which States Do Failures Occur? (Row Sums)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sum failures by row (after which state do failures happen)\n",
        "row_sums = transition_matrix.sum(axis=1)\n",
        "\n",
        "# Create summary DataFrame\n",
        "failures_after_state = pd.DataFrame({\n",
        "    'State': PIPELINE_STATES,\n",
        "    'Failures After This State': row_sums,\n",
        "    'Percentage': row_sums / row_sums.sum() * 100\n",
        "}).sort_values('Failures After This State', ascending=False)\n",
        "\n",
        "print(\"States with Most Downstream Failures (Row Sums):\")\n",
        "print(\"=\" * 70)\n",
        "display(failures_after_state)\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Identify upstream cause\n",
        "upstream_issue = failures_after_state.iloc[0]\n",
        "print(f\"\\nâš ï¸  UPSTREAM RISK: {upstream_issue['State']}\")\n",
        "print(f\"   Followed by {upstream_issue['Failures After This State']:.0f} failures ({upstream_issue['Percentage']:.1f}% of total)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Most Common Single Transition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find cell with maximum value\n",
        "max_value = transition_matrix.max()\n",
        "max_indices = np.argwhere(transition_matrix == max_value)\n",
        "\n",
        "print(f\"Most Frequent Failure Transition(s):\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for i, j in max_indices:\n",
        "    from_state = PIPELINE_STATES[i]\n",
        "    to_state = PIPELINE_STATES[j]\n",
        "    percentage = max_value / transition_matrix.sum() * 100\n",
        "    \n",
        "    print(f\"  {from_state} â†’ {to_state}\")\n",
        "    print(f\"  Count: {max_value} occurrences ({percentage:.1f}% of all failures)\")\n",
        "    print()\n",
        "\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Export Heatmap\n",
        "\n",
        "Save publication-quality PNG for reports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_heatmap(\n",
        "    matrix: np.ndarray,\n",
        "    states: List[str],\n",
        "    output_path: Path,\n",
        "    dpi: int = 300\n",
        ") -> None:\n",
        "    \"\"\"Save heatmap to PNG file.\n",
        "    \n",
        "    Args:\n",
        "        matrix: Transition count matrix\n",
        "        states: State labels\n",
        "        output_path: Output file path\n",
        "        dpi: Resolution (300 for publication quality)\n",
        "    \"\"\"\n",
        "    # Ensure output directory exists\n",
        "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Create figure\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(\n",
        "        matrix,\n",
        "        annot=True,\n",
        "        fmt=\"d\",\n",
        "        cmap=\"YlOrRd\",\n",
        "        xticklabels=states,\n",
        "        yticklabels=states,\n",
        "        cbar_kws={\"label\": \"Failure Count\"},\n",
        "        square=True,\n",
        "        linewidths=0.5,\n",
        "        linecolor='gray'\n",
        "    )\n",
        "    \n",
        "    plt.title(\"Failure Transition Heatmap\", fontsize=16, fontweight='bold', pad=20)\n",
        "    plt.xlabel(\"First Failure State â†’\", fontsize=12, fontweight='bold')\n",
        "    plt.ylabel(\"Last Success State â†“\", fontsize=12, fontweight='bold')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    \n",
        "    # Save\n",
        "    plt.savefig(output_path, dpi=dpi, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    \n",
        "    print(f\"âœ“ Heatmap saved to: {output_path.resolve()}\")\n",
        "    print(f\"  Resolution: {dpi} DPI\")\n",
        "    print(f\"  File size: {output_path.stat().st_size / 1024:.1f} KB\")\n",
        "\n",
        "# Save to results/\n",
        "OUTPUT_PATH = Path(\"results/failure_transition_heatmap.png\")\n",
        "save_heatmap(transition_matrix, PIPELINE_STATES, OUTPUT_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Exercises and Next Steps\n",
        "\n",
        "### Exercise 1: Filter by Customer Persona\n",
        "\n",
        "Build separate transition matrices for different customer personas (e.g., `vegan_family`, `gluten_free_athlete`) to see if failure patterns differ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Group traces by customer_persona and build separate matrices\n",
        "# Hint: Use a dictionary comprehension to group traces\n",
        "\n",
        "# Example starter code:\n",
        "# personas = set(t.get('customer_persona') for t in traces if t.get('customer_persona'))\n",
        "# for persona in personas:\n",
        "#     persona_traces = [t for t in traces if t.get('customer_persona') == persona]\n",
        "#     persona_matrix = build_transition_matrix(persona_traces, PIPELINE_STATES)\n",
        "#     plot_transition_heatmap(persona_matrix, PIPELINE_STATES, title=f\"Failures: {persona}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 2: Investigate High-Frequency Transition\n",
        "\n",
        "Read all traces with the most common failure transition to identify patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Filter traces by (last_success_state, first_failure_state) pair\n",
        "# Examine their user queries, customer personas, or other metadata\n",
        "\n",
        "# Example starter code:\n",
        "# target_from = \"GenRecipeArgs\"\n",
        "# target_to = \"GetRecipes\"\n",
        "# matching_traces = [\n",
        "#     t for t in traces \n",
        "#     if t['last_success_state'] == target_from and t['first_failure_state'] == target_to\n",
        "# ]\n",
        "# print(f\"Found {len(matching_traces)} traces with {target_from} â†’ {target_to}\")\n",
        "# # Inspect first few\n",
        "# for trace in matching_traces[:3]:\n",
        "#     print(trace['trace_id'], trace.get('customer_persona'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 3: Normalized Heatmap (Percentages)\n",
        "\n",
        "Create a heatmap showing percentages instead of raw counts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Normalize matrix to percentages\n",
        "# Hint: normalized_matrix = (transition_matrix / transition_matrix.sum()) * 100\n",
        "\n",
        "# Then plot with fmt=\".1f\" to show 1 decimal place"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary and Key Takeaways\n",
        "\n",
        "In this tutorial, you learned to:\n",
        "\n",
        "1. **Load and explore labeled failure traces** from JSON\n",
        "2. **Extract failure transitions** as `(last_success, first_failure)` pairs\n",
        "3. **Build transition count matrices** programmatically\n",
        "4. **Visualize patterns with seaborn heatmaps** using effective color schemes\n",
        "5. **Identify bottlenecks** through column/row sum analysis\n",
        "6. **Export publication-quality visualizations** at 300 DPI\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- **Read traces** with high-frequency transitions to understand root causes\n",
        "- **Propose fixes** for identified bottlenecks (better prompts, tool improvements)\n",
        "- **Re-run analysis** after implementing fixes to verify improvement\n",
        "- **Explore** [Transition Analysis Concepts](transition_analysis_concepts.md) for deeper methodology\n",
        "\n",
        "### Related Tutorials\n",
        "\n",
        "- [Transition Analysis Concepts](transition_analysis_concepts.md) - Theory and methodology\n",
        "- [Transition Matrix Diagram](diagrams/transition_matrix_concept.mmd) - Visual pipeline reference\n",
        "- [HW5 Tutorial Index](TUTORIAL_INDEX.md) - Complete learning path\n",
        "\n",
        "---\n",
        "\n",
        "**Tutorial Status:** âœ… Complete  \n",
        "**Last Updated:** 2025-10-30  \n",
        "**Maintainer:** AI Evaluation Course Team"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
