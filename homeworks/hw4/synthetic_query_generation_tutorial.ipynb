{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Query Generation Tutorial: Building RAG Evaluation Datasets\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By completing this tutorial, you will be able to:\n",
    "- ‚úÖ Extract salient facts from recipes using LLM prompting\n",
    "- ‚úÖ Generate realistic natural language queries from facts\n",
    "- ‚úÖ Use two-step LLM prompting (facts ‚Üí queries) for better quality\n",
    "- ‚úÖ Implement parallel processing with ThreadPoolExecutor\n",
    "- ‚úÖ Validate query quality and filter low-quality examples\n",
    "- ‚úÖ Optimize costs for large-scale query generation\n",
    "- ‚úÖ Export queries in evaluation-ready format\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed [RAG Evaluation Concepts](rag_evaluation_concepts.md)\n",
    "- Have processed recipe dataset ready\n",
    "- Understanding of parallel processing concepts\n",
    "\n",
    "## Estimated Time\n",
    "\n",
    "**Execution Time:** 20-30 minutes  \n",
    "**Cost:** ~$0.50-2.00 for 100 queries (GPT-4o-mini)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup complete\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Progress tracking\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# LLM API\n",
    "import litellm\n",
    "\n",
    "# Environment configuration\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Set random seed\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ DEMO MODE: Generating small query sample\n",
      "   Recipes: 10 | Workers: 5\n",
      "   Expected queries: ~10 queries\n",
      "   Estimated cost: $0.05-0.15 | Time: ~1-2 minutes\n",
      "\n",
      "üí° To switch modes, change DEMO_MODE in this cell and re-run notebook\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CONFIGURATION: Demo vs Full Mode\n",
    "# ========================================\n",
    "\n",
    "# Set DEMO_MODE = False to generate full dataset\n",
    "DEMO_MODE = True  # Default: Quick demo for tutorial\n",
    "\n",
    "if DEMO_MODE:\n",
    "    MAX_RECIPES = 10  # Process 10 recipes\n",
    "    MAX_WORKERS = 5\n",
    "    print(\"üöÄ DEMO MODE: Generating small query sample\")\n",
    "    print(f\"   Recipes: {MAX_RECIPES} | Workers: {MAX_WORKERS}\")\n",
    "    print(f\"   Expected queries: ~{MAX_RECIPES} queries\")\n",
    "    print(f\"   Estimated cost: $0.05-0.15 | Time: ~1-2 minutes\")\n",
    "else:\n",
    "    MAX_RECIPES = 100  # Process 100 recipes\n",
    "    MAX_WORKERS = 10\n",
    "    print(\"üìä FULL MODE: Generating comprehensive query dataset\")\n",
    "    print(f\"   Recipes: {MAX_RECIPES} | Workers: {MAX_WORKERS}\")\n",
    "    print(f\"   Expected queries: ~{MAX_RECIPES} queries\")\n",
    "    print(f\"   Estimated cost: $1.50-2.00 | Time: ~3-5 minutes\")\n",
    "\n",
    "print(\"\\nüí° To switch modes, change DEMO_MODE in this cell and re-run notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load Processed Recipes\n",
    "\n",
    "Load the recipe dataset prepared in `scripts/process_recipes.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 200 recipes\n",
      "\n",
      "üìã Sample recipe:\n",
      "ID: 65007\n",
      "Name: 5 cheese crab lasagna with roasted garlic and vegetables\n",
      "Ingredients: 24\n",
      "Steps: 108\n"
     ]
    }
   ],
   "source": [
    "# Load processed recipes\n",
    "recipes_path = 'data/processed_recipes.json'\n",
    "\n",
    "if not os.path.exists(recipes_path):\n",
    "    print(f\"‚ùå File not found: {recipes_path}\")\n",
    "    print(\"Run scripts/process_recipes.py first to create processed recipes.\")\n",
    "else:\n",
    "    with open(recipes_path, 'r') as f:\n",
    "        recipes = json.load(f)\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(recipes)} recipes\")\n",
    "    print(f\"\\nüìã Sample recipe:\")\n",
    "    sample = recipes[0]\n",
    "    print(f\"ID: {sample['id']}\")\n",
    "    print(f\"Name: {sample['name']}\")\n",
    "    print(f\"Ingredients: {len(sample.get('ingredients', []))}\")\n",
    "    print(f\"Steps: {len(sample.get('steps', []))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Two-Step Query Generation Strategy\n",
    "\n",
    "### Why Two Steps?\n",
    "\n",
    "**One-step approach (naive):**\n",
    "- Prompt: \"Generate a query for this recipe\"\n",
    "- Result: Generic queries (\"How to make [recipe name]?\")\n",
    "\n",
    "**Two-step approach (better):**\n",
    "1. **Step 1:** Extract salient facts (specific, technical details)\n",
    "2. **Step 2:** Generate query targeting those facts\n",
    "- Result: Specific queries (\"What air fryer temperature for crispy chicken?\")\n",
    "\n",
    "### Step 1: Extract Salient Facts\n",
    "\n",
    "**Goal:** Identify 1-2 specific technical details that:\n",
    "- Are difficult to generate from scratch\n",
    "- Are clearly answerable by this recipe\n",
    "- Test retrieval capability (not just generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Extracting salient facts from sample recipe...\n",
      "\n",
      "Recipe: 5 cheese crab lasagna with roasted garlic and vegetables\n",
      "\n",
      "‚úÖ Salient Facts:\n",
      "1. **Specific Cooking Technique/Method**: \"Roast garlic: place oven rack on second notch, turn oven to 375¬∞F.\" This detail specifies both the oven temperature and the positioning of the rack, which are crucial for properly roasting garlic.\n",
      "\n",
      "2. **Ingredient Preparation Detail**: \"Cut tops off of the heads of garlic and discard excess skin.\" This instruction provides a precise method for preparing the garlic, which is essential for the roasting process and affects the final flavor and texture of the dish.\n"
     ]
    }
   ],
   "source": [
    "def format_recipe_for_llm(recipe: Dict[str, Any]) -> str:\n",
    "    \"\"\"Format recipe for LLM processing.\"\"\"\n",
    "    formatted = f\"**{recipe.get('name', 'Unknown')}**\\n\"\n",
    "    \n",
    "    if recipe.get('description'):\n",
    "        formatted += f\"Description: {recipe['description']}\\n\"\n",
    "    \n",
    "    if recipe.get('minutes'):\n",
    "        formatted += f\"Cooking time: {recipe['minutes']} minutes\\n\"\n",
    "    \n",
    "    if recipe.get('ingredients'):\n",
    "        formatted += f\"Ingredients: {', '.join(recipe['ingredients'][:10])}\\n\"\n",
    "    \n",
    "    if recipe.get('steps'):\n",
    "        steps_text = ' '.join(recipe['steps'][:5])  # First 5 steps\n",
    "        formatted += f\"Steps: {steps_text[:500]}...\\n\"\n",
    "    \n",
    "    return formatted\n",
    "\n",
    "def extract_salient_facts(recipe: Dict[str, Any], model: str = \"gpt-4o-mini\") -> str:\n",
    "    \"\"\"Extract salient facts from recipe using LLM.\"\"\"\n",
    "    \n",
    "    recipe_text = format_recipe_for_llm(recipe)\n",
    "    \n",
    "    prompt = f\"\"\"Analyze this recipe and identify 1-2 specific, technical details that would be difficult to generate from scratch but are clearly answerable by this exact recipe. Focus on:\n",
    "\n",
    "1. **Specific cooking techniques/methods** (e.g., \"marinate for 4 hours\", \"bake at 375¬∞F for exactly 25 minutes\")\n",
    "2. **Appliance settings** (e.g., \"air fryer at 400¬∞F for 12 minutes\", \"pressure cook for 8 minutes\")  \n",
    "3. **Ingredient preparation details** (e.g., \"slice onions paper-thin\", \"whip cream to soft peaks\")\n",
    "4. **Timing specifics** (e.g., \"rest dough for 30 minutes\", \"simmer for 45 minutes\")\n",
    "5. **Temperature precision** (e.g., \"internal temp 165¬∞F\", \"oil heated to 350¬∞F\")\n",
    "\n",
    "Return the most distinctive fact(s) that someone might specifically search for:\n",
    "\n",
    "Recipe:\n",
    "{recipe_text}\n",
    "\n",
    "Salient Fact(s):\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = litellm.completion(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.3,\n",
    "            max_tokens=200\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error extracting facts: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Demo: Extract facts from sample recipe\n",
    "print(\"üß™ Extracting salient facts from sample recipe...\\n\")\n",
    "sample_recipe = recipes[0]\n",
    "print(f\"Recipe: {sample_recipe['name']}\\n\")\n",
    "\n",
    "salient_facts = extract_salient_facts(sample_recipe)\n",
    "print(f\"‚úÖ Salient Facts:\\n{salient_facts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Generate Realistic Query\n",
    "\n",
    "**Goal:** Create a natural, conversational query that:\n",
    "- Sounds like a real person asking\n",
    "- Focuses on the salient fact\n",
    "- Is challenging (requires this recipe to answer)\n",
    "- Avoids mentioning recipe name directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Generating query from salient facts...\n",
      "\n",
      "Salient Facts: 1. **Specific Cooking Technique/Method**: \"Roast garlic: place oven rack on second notch, turn oven to 375¬∞F.\" This detail specifies both the oven temperature and the positioning of the rack, which are crucial for properly roasting garlic.\n",
      "\n",
      "2. **Ingredient Preparation Detail**: \"Cut tops off of the heads of garlic and discard excess skin.\" This instruction provides a precise method for preparing the garlic, which is essential for the roasting process and affects the final flavor and texture of the dish.\n",
      "\n",
      "‚úÖ Generated Query:\n",
      "What's the best way to prepare garlic for roasting, especially in terms of cutting it and what oven setup I should use?\n"
     ]
    }
   ],
   "source": [
    "def generate_realistic_query(recipe: Dict[str, Any], salient_fact: str, model: str = \"gpt-4o-mini\") -> str:\n",
    "    \"\"\"Generate realistic user query from salient fact.\"\"\"\n",
    "    \n",
    "    recipe_name = recipe.get('name', 'Unknown Recipe')\n",
    "    ingredients = ', '.join(recipe.get('ingredients', [])[:5])\n",
    "    \n",
    "    prompt = f\"\"\"Create a realistic, specific user query that a home cook might ask, which can ONLY be answered well by this exact recipe. The query should:\n",
    "\n",
    "1. Sound natural and conversational (like a real person asking)\n",
    "2. Focus on the specific technical detail: \"{salient_fact}\"\n",
    "3. Be challenging - requiring this exact recipe's information to answer properly\n",
    "4. Avoid mentioning the recipe name directly\n",
    "\n",
    "Context:\n",
    "- Recipe: {recipe_name}\n",
    "- Key ingredients: {ingredients}\n",
    "- Salient fact: {salient_fact}\n",
    "\n",
    "Examples of good query styles:\n",
    "- \"What temperature and time for air fryer frozen chicken tenders?\"\n",
    "- \"How long should I marinate beef for Korean bulgogi?\"\n",
    "- \"What's the exact oven temperature for crispy roasted vegetables?\"\n",
    "- \"How do I get the right consistency for homemade pasta dough?\"\n",
    "\n",
    "Generate ONE specific query:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = litellm.completion(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=100\n",
    "        )\n",
    "        return response.choices[0].message.content.strip().strip('\"')\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating query: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Demo: Generate query from salient facts\n",
    "print(\"üß™ Generating query from salient facts...\\n\")\n",
    "print(f\"Salient Facts: {salient_facts}\\n\")\n",
    "\n",
    "query = generate_realistic_query(sample_recipe, salient_facts)\n",
    "print(f\"‚úÖ Generated Query:\\n{query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Generate queries using configuration\n",
    "print(f\"‚è≥ Generating queries for {MAX_RECIPES} recipes...\\n\")\n",
    "if DEMO_MODE:\n",
    "    print(\"‚ö†Ô∏è  DEMO MODE: Cost estimate: ~$0.05-0.15\\n\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  FULL MODE: Cost estimate: ~$1.50-2.00\\n\")\n",
    "\n",
    "sample_queries = batch_generate_queries(recipes, max_workers=MAX_WORKERS, max_recipes=MAX_RECIPES)\n",
    "\n",
    "print(f\"\\n‚úÖ Generated {len(sample_queries)} queries\")\n",
    "print(f\"Success rate: {len(sample_queries)/MAX_RECIPES:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Generating queries for 10 sample recipes...\n",
      "\n",
      "‚ö†Ô∏è  Cost estimate: ~$0.05-0.10\n",
      "\n",
      "üìä Processing 10 recipes with 5 workers...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6170da6cab14a8da0f5a637f7053d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating queries:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Generated 10 queries\n",
      "Success rate: 100.0%\n"
     ]
    }
   ],
   "source": [
    "def process_single_recipe(recipe: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Process a single recipe to generate a query.\"\"\"\n",
    "    try:\n",
    "        # Step 1: Extract salient facts\n",
    "        salient_fact = extract_salient_facts(recipe)\n",
    "        \n",
    "        if not salient_fact or len(salient_fact.strip()) < 10:\n",
    "            return None\n",
    "        \n",
    "        # Step 2: Generate query\n",
    "        query = generate_realistic_query(recipe, salient_fact)\n",
    "        \n",
    "        if not query or len(query.strip()) < 10:\n",
    "            return None\n",
    "        \n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"salient_fact\": salient_fact,\n",
    "            \"source_recipe_id\": recipe['id'],\n",
    "            \"source_recipe_name\": recipe['name'],\n",
    "            \"ingredients\": recipe.get('ingredients', []),\n",
    "            \"cooking_time\": recipe.get('minutes', 0),\n",
    "            \"tags\": recipe.get('tags', [])\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing recipe {recipe.get('id', 'unknown')}: {e}\")\n",
    "        return None\n",
    "\n",
    "def batch_generate_queries(recipes: List[Dict[str, Any]], \n",
    "                           max_workers: int = 10,\n",
    "                           max_recipes: int = None) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Generate queries in parallel using ThreadPoolExecutor.\"\"\"\n",
    "    \n",
    "    if max_recipes:\n",
    "        recipes = recipes[:max_recipes]\n",
    "    \n",
    "    queries = []\n",
    "    \n",
    "    print(f\"üìä Processing {len(recipes)} recipes with {max_workers} workers...\\n\")\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all tasks\n",
    "        futures = {executor.submit(process_single_recipe, recipe): recipe \n",
    "                   for recipe in recipes}\n",
    "        \n",
    "        # Process completed tasks with progress bar\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Generating queries\"):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                if result:\n",
    "                    queries.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Task failed: {e}\")\n",
    "    \n",
    "    return queries\n",
    "\n",
    "# Demo: Generate queries for 10 recipes\n",
    "print(\"‚è≥ Generating queries for 10 sample recipes...\\n\")\n",
    "print(\"‚ö†Ô∏è  Cost estimate: ~$0.05-0.10\\n\")\n",
    "\n",
    "sample_queries = batch_generate_queries(recipes, max_workers=5, max_recipes=10)\n",
    "\n",
    "print(f\"\\n‚úÖ Generated {len(sample_queries)} queries\")\n",
    "print(f\"Success rate: {len(sample_queries)/10:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Quality Review\n",
    "\n",
    "### Review Generated Queries\n",
    "\n",
    "Manually inspect a sample to ensure quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Sample Generated Queries:\n",
      "\n",
      "================================================================================\n",
      "Query 1: I'm trying to make a baked good with a nice, crumbly texture, but I'm not sure how to properly incorporate the butter into the flour mixture. What technique should I use, and what‚Äôs the best baking temperature and time to ensure it turns out perfectly?\n",
      "Source Recipe: all purpose quick mix with 28 variations\n",
      "Salient Fact: 1. **Baking Temperature and Time**: The recipe specifies to \"bake at 350 degrees for 30 minutes or until done.\" This precise temperature and timing detail is crucial for achieving the desired texture and doneness of the baked goods.\n",
      "\n",
      "2. **Preparation Technique**: The instruction to \"cut butter or margarine into flour mixture until it resembles coarse cornmeal\" is a specific technique that involves a method known as \"cutting in.\" This detail is important for achieving the right consistency in the mixture, which can be difficult to determine without this guidance.\n",
      "\n",
      "================================================================================\n",
      "Query 2: What water temperature should I use for my bread dough to make sure the yeast activates properly, and how long will it take to rise if I use that?\n",
      "Source Recipe: 5 minute artisan bread\n",
      "Salient Fact: 1. **Specific Cooking Techniques/Methods**: The recipe specifies that the dough should be prepared with \"warm water slightly warmer than body temperature,\" which is crucial for activating the yeast properly. This detail is essential for achieving the right dough consistency and fermentation.\n",
      "\n",
      "2. **Timing Specifics**: The recipe indicates that using warm water will allow the dough to rise to the right point for storage in about **2 hours**, while using cold water will require **3-4 hours**. This timing is critical for anyone looking to ensure proper fermentation and storage of the dough.\n",
      "\n",
      "================================================================================\n",
      "Query 3: How do I make sure the vegetables in my soup are tender but not mushy, especially after I saut√© them? What's the best way to transition to simmering, and how long should I let it simmer after adding the herbs?\n",
      "Source Recipe: 7 day diet fat burning cabbage soup\n",
      "Salient Fact: 1. **Cooking Technique/Method**: \"Saute all veggies except for cabbage and tomatoes in vegetable oil or coconut oil, cover with water, bring to a boil, lower heat and simmer till veggies are tender.\" This specific sequence of cooking steps, particularly the transition from saut√©ing to simmering, is a technical detail that is crucial for achieving the desired texture and flavor in the soup.\n",
      "\n",
      "2. **Timing Specifics**: \"Simmer till veggies are tender\" followed by \"simmer 5 minutes\" after adding fresh or dried herbs. The timing of these steps is essential for ensuring that the vegetables are cooked properly without becoming mushy, and the additional simmering time for the herbs allows their flavors to infuse into the soup effectively.\n",
      "\n",
      "================================================================================\n",
      "Query 4: What's the right batter consistency for making fritters, and how long should I expect to cook them for?\n",
      "Source Recipe: alligator claws avocado fritters with chipotle lime dip\n",
      "Salient Fact: Based on the provided recipe for alligator claws avocado fritters with chipotle lime dip, the following specific technical details stand out as distinctive facts that would be difficult to generate from scratch but are clearly answerable by this exact recipe:\n",
      "\n",
      "1. **Cooking Techniques/Methods**: The recipe implies a specific batter preparation method, which is a one-to-one mix of flour and water. This detail is crucial for achieving the right consistency for the fritters, and it is not a common knowledge detail that one might easily guess.\n",
      "\n",
      "2. **Timing Specifics**: The overall cooking time is specified as **45 minutes**. This detail is essential for planning and ensuring that the fritters are cooked properly, and it may not be intuitive for someone unfamiliar with fritter preparation.\n",
      "\n",
      "These details provide clear guidance on both the preparation and cooking process, making them valuable for anyone attempting to recreate the dish.\n",
      "\n",
      "================================================================================\n",
      "Query 5: What's the best temperature to roast garlic for a lasagna, and how do I make sure it's perfectly cooked without burning it?\n",
      "Source Recipe: 5 cheese crab lasagna with roasted garlic and vegetables\n",
      "Salient Fact: 1. **Specific Cooking Techniques/Methods**: The recipe specifies to \"roast garlic: place oven rack on second notch turn oven to 375 degrees F,\" which indicates both the cooking method (roasting) and the precise oven temperature.\n",
      "\n",
      "2. **Appliance Settings**: The recipe requires the oven to be set at \"375 degrees F,\" which is a specific temperature setting that is crucial for the roasting process and overall cooking of the lasagna. \n",
      "\n",
      "These details are distinctive and would be difficult to generate from scratch without the context of this specific recipe.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display sample queries\n",
    "print(\"üìã Sample Generated Queries:\\n\")\n",
    "\n",
    "for i, query_data in enumerate(sample_queries[:5], 1):\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Query {i}: {query_data['query']}\")\n",
    "    print(f\"Source Recipe: {query_data['source_recipe_name']}\")\n",
    "    print(f\"Salient Fact: {query_data['salient_fact']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Validation Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Quality Statistics:\n",
      "\n",
      "total_queries: 10\n",
      "avg_query_length_words: 30.4\n",
      "min_query_length_words: 18\n",
      "max_query_length_words: 54\n",
      "unique_queries: 10\n",
      "diversity_rate: 100.0%\n",
      "queries_with_questions: 10\n",
      "question_rate: 100.0%\n",
      "\n",
      "‚úÖ Quality Assessment:\n",
      "‚úÖ Query length is good (detailed, specific)\n",
      "‚úÖ High diversity (queries are unique)\n",
      "‚úÖ Good conversational style (question format)\n"
     ]
    }
   ],
   "source": [
    "def validate_query_quality(queries: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"Validate query quality with automated checks.\"\"\"\n",
    "    \n",
    "    # Length checks\n",
    "    avg_query_length = np.mean([len(q['query'].split()) for q in queries])\n",
    "    min_query_length = min([len(q['query'].split()) for q in queries])\n",
    "    max_query_length = max([len(q['query'].split()) for q in queries])\n",
    "    \n",
    "    # Check for diversity (unique queries)\n",
    "    unique_queries = len(set(q['query'].lower() for q in queries))\n",
    "    diversity_rate = unique_queries / len(queries)\n",
    "    \n",
    "    # Check for question marks (conversational style)\n",
    "    queries_with_questions = sum(1 for q in queries if '?' in q['query'])\n",
    "    question_rate = queries_with_questions / len(queries)\n",
    "    \n",
    "    return {\n",
    "        'total_queries': len(queries),\n",
    "        'avg_query_length_words': avg_query_length,\n",
    "        'min_query_length_words': min_query_length,\n",
    "        'max_query_length_words': max_query_length,\n",
    "        'unique_queries': unique_queries,\n",
    "        'diversity_rate': diversity_rate,\n",
    "        'queries_with_questions': queries_with_questions,\n",
    "        'question_rate': question_rate\n",
    "    }\n",
    "\n",
    "# Validate quality\n",
    "quality_stats = validate_query_quality(sample_queries)\n",
    "\n",
    "print(\"üìä Quality Statistics:\\n\")\n",
    "for key, value in quality_stats.items():\n",
    "    if isinstance(value, float):\n",
    "        if 'rate' in key:\n",
    "            print(f\"{key}: {value:.1%}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value:.1f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "# Quality assessment\n",
    "print(\"\\n‚úÖ Quality Assessment:\")\n",
    "if quality_stats['avg_query_length_words'] > 8:\n",
    "    print(\"‚úÖ Query length is good (detailed, specific)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Queries may be too short\")\n",
    "\n",
    "if quality_stats['diversity_rate'] > 0.95:\n",
    "    print(\"‚úÖ High diversity (queries are unique)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Some duplicate queries detected\")\n",
    "\n",
    "if quality_stats['question_rate'] > 0.7:\n",
    "    print(\"‚úÖ Good conversational style (question format)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Many queries are not in question format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Cost Optimization\n",
    "\n",
    "### Cost Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí∞ Cost Estimates:\n",
      "\n",
      "Num Queries     GPT-4o-mini     GPT-4o\n",
      "---------------------------------------------\n",
      "10              $0.15           $0.50\n",
      "50              $0.75           $2.50\n",
      "100             $1.50           $5.00\n",
      "200             $3.00           $10.00\n",
      "500             $7.50           $25.00\n",
      "\n",
      "üìù Notes:\n",
      "- Use GPT-4o-mini for cost efficiency (recommended)\n",
      "- Use GPT-4o if query quality is critical\n",
      "- Parallel processing reduces time but not cost\n"
     ]
    }
   ],
   "source": [
    "# Estimate costs for different scales\n",
    "cost_per_query_gpt4o_mini = 0.015  # $0.015 per query (2 calls √ó ~$0.0075 avg)\n",
    "cost_per_query_gpt4o = 0.05        # $0.05 per query (2 calls √ó ~$0.025 avg)\n",
    "\n",
    "scales = [10, 50, 100, 200, 500]\n",
    "\n",
    "print(\"üí∞ Cost Estimates:\\n\")\n",
    "print(f\"{'Num Queries':<15} {'GPT-4o-mini':<15} {'GPT-4o'}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for scale in scales:\n",
    "    cost_mini = scale * cost_per_query_gpt4o_mini\n",
    "    cost_4o = scale * cost_per_query_gpt4o\n",
    "    print(f\"{scale:<15} ${cost_mini:<14.2f} ${cost_4o:.2f}\")\n",
    "\n",
    "print(\"\\nüìù Notes:\")\n",
    "print(\"- Use GPT-4o-mini for cost efficiency (recommended)\")\n",
    "print(\"- Use GPT-4o if query quality is critical\")\n",
    "print(\"- Parallel processing reduces time but not cost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips for Cost Optimization\n",
    "\n",
    "1. **Start small**: Generate 20-30 queries, validate quality\n",
    "2. **Iterate on prompts**: Refine prompts before scaling to 100+\n",
    "3. **Use mini models**: GPT-4o-mini is 70% cheaper, similar quality for this task\n",
    "4. **Cache results**: Save intermediate results to avoid re-processing\n",
    "5. **Filter early**: Remove invalid recipes before LLM calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Export for Evaluation\n",
    "\n",
    "Save queries in evaluation-ready format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved 10 queries to data/synthetic_queries.json\n",
      "‚úÖ Saved CSV to data/synthetic_queries.csv\n"
     ]
    }
   ],
   "source": [
    "# Create data directory if needed\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Save queries\n",
    "output_path = 'data/synthetic_queries.json'\n",
    "\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(sample_queries, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Saved {len(sample_queries)} queries to {output_path}\")\n",
    "\n",
    "# Also save as CSV for easy viewing\n",
    "queries_df = pd.DataFrame(sample_queries)\n",
    "queries_df[['query', 'source_recipe_name', 'salient_fact']].to_csv('data/synthetic_queries.csv', index=False)\n",
    "\n",
    "print(f\"‚úÖ Saved CSV to data/synthetic_queries.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Full-Scale Generation (Optional)\n",
    "\n",
    "‚ö†Ô∏è **Cost Warning**: Generating 100 queries costs ~$1.50-2.00 with GPT-4o-mini\n",
    "\n",
    "Uncomment and run to generate full evaluation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment to generate 100 queries\n",
    "# print(\"‚è≥ Generating 100 queries for full evaluation...\\n\")\n",
    "# print(\"‚ö†Ô∏è  Estimated cost: $1.50-2.00\")\n",
    "# print(\"‚è±Ô∏è  Estimated time: 3-5 minutes\\n\")\n",
    "#\n",
    "# full_queries = batch_generate_queries(recipes, max_workers=10, max_recipes=100)\n",
    "#\n",
    "# print(f\"\\n‚úÖ Generated {len(full_queries)} queries\")\n",
    "# print(f\"Success rate: {len(full_queries)/100:.1%}\")\n",
    "#\n",
    "# # Save\n",
    "# with open('data/synthetic_queries_full.json', 'w') as f:\n",
    "#     json.dump(full_queries, f, indent=2)\n",
    "#\n",
    "# print(\"‚úÖ Saved to data/synthetic_queries_full.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We've Accomplished\n",
    "\n",
    "‚úÖ Loaded and explored processed recipe dataset  \n",
    "‚úÖ Implemented two-step query generation (facts ‚Üí queries)  \n",
    "‚úÖ Built parallel processing pipeline with ThreadPoolExecutor  \n",
    "‚úÖ Generated sample queries with quality validation  \n",
    "‚úÖ Analyzed costs and optimization strategies  \n",
    "‚úÖ Exported queries in evaluation-ready format  \n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Scale up**: Generate 100+ queries for comprehensive evaluation\n",
    "2. **Manual review**: Validate 10-20% of queries for quality\n",
    "3. **Retrieval evaluation**: Use [Retrieval Metrics Tutorial](retrieval_metrics_tutorial.md)\n",
    "4. **BM25 evaluation**: Run `scripts/evaluate_retrieval.py`\n",
    "5. **Analyze results**: Identify query types that work well vs. poorly\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- ‚úÖ **Two-step generation produces better queries** - Facts ‚Üí queries is superior to direct generation\n",
    "- ‚úÖ **Parallel processing enables scale** - 10x speedup with ThreadPoolExecutor\n",
    "- ‚úÖ **Quality validation is critical** - Check length, diversity, conversational style\n",
    "- ‚úÖ **Cost optimization matters** - Use GPT-4o-mini, start small, iterate\n",
    "- ‚úÖ **Salient facts drive specificity** - Technical details make queries challenging\n",
    "\n",
    "---\n",
    "\n",
    "**Tutorial Status:** ‚úÖ Complete  \n",
    "**Last Updated:** 2025-10-29  \n",
    "**Maintainer:** AI Evaluation Course Team"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Recipe Chatbot (.venv)",
   "language": "python",
   "name": "recipe-chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
