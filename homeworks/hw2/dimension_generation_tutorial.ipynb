{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension Generation Tutorial\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By completing this tutorial, you will:\n",
    "- âœ… Generate dimension tuples (combinations) using LLMs\n",
    "- âœ… Convert tuples to natural language queries\n",
    "- âœ… Validate and filter generated queries\n",
    "- âœ… Optimize costs with parallel processing\n",
    "- âœ… Export queries to CSV for systematic testing\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed [Error Analysis Concepts Tutorial](error_analysis_concepts.md)\n",
    "- Identified 3-5 key dimensions for query generation\n",
    "- OpenAI API key configured in `.env` file\n",
    "\n",
    "## Estimated Time\n",
    "\n",
    "**Execution Time:** 10-15 minutes (depending on API latency)\n",
    "\n",
    "**âš ï¸ Cost Warning:** This notebook makes LLM API calls. Estimated cost: $0.10-0.30 for full execution (using gpt-4o-mini)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Environment configured\n"
     ]
    }
   ],
   "source": [
    "# Add project root to path for imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from langsmith import traceable\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent.parent))\n",
    "\n",
    "# Load environment variables\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(Path.cwd().parent.parent / '.env')\n",
    "\n",
    "# Verify API key is loaded\n",
    "if not os.environ.get('OPENAI_API_KEY'):\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment. Check your .env file.\")\n",
    "\n",
    "print(\"âœ“ Environment configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import time\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "# Configure litellm disk cache for cost savings\n",
    "import litellm\n",
    "import pandas as pd\n",
    "from litellm import Cache, completion\n",
    "from pydantic import BaseModel\n",
    "\n",
    "litellm.cache = Cache(type=\"disk\")\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully\")\n",
    "print(\"âœ“ LiteLLM disk cache configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Why Dimension-Based Query Generation?\n",
    "\n",
    "In **HW1**, you manually created 10+ diverse queries. This approach:\n",
    "- âœ… Works for small test sets\n",
    "- âŒ Doesn't scale to 100+ queries\n",
    "- âŒ Hard to ensure balanced coverage\n",
    "- âŒ Time-consuming and error-prone\n",
    "\n",
    "**Dimension-based generation** solves this:\n",
    "1. **Define dimensions** (cuisine, dietary, meal type, time, etc.)\n",
    "2. **Generate tuples** - LLM creates diverse combinations\n",
    "3. **Generate queries** - LLM converts tuples to natural language\n",
    "4. **Validate** - Filter unrealistic or duplicate queries\n",
    "5. **Export** - Save to CSV for systematic testing\n",
    "\n",
    "**Key Benefits:**\n",
    "- ðŸš€ Generate 50-100 queries in minutes\n",
    "- ðŸ“Š Systematic coverage across all dimensions\n",
    "- ðŸ”„ Reproducible (can regenerate with different seeds)\n",
    "- âœ… Includes natural language variations\n",
    "\n",
    "**Reference:** See [`generate_synthetic_queries.py`](generate_synthetic_queries.py) for full implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Define Your Dimensions\n",
    "\n",
    "Based on **error analysis** (HW2 Part 2), identify dimensions where your bot frequently fails or needs comprehensive testing.\n",
    "\n",
    "For our Recipe Bot, we'll use **6 dimensions**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DietaryNeedsOrRestrictions: 18 values\n",
      "AvailableIngredientsFocus: 6 values\n",
      "CuisinePreference: 9 values\n",
      "SkillLevelEffort: 3 values\n",
      "TimeAvailability: 3 values\n",
      "QueryStyleAndDetail: 3 values\n",
      "\n",
      "Total possible combinations: 26,244\n",
      "(We'll generate a diverse subset of 10-20 tuples)\n"
     ]
    }
   ],
   "source": [
    "# Define dimension values\n",
    "\n",
    "DIMENSIONS = {\n",
    "    \"DietaryNeedsOrRestrictions\": [\n",
    "        \"vegan\", \"vegetarian\", \"gluten-free\", \"dairy-free\", \"keto\", \"paleo\",\n",
    "        \"halal\", \"kosher\", \"no restrictions\", \"pescatarian\", \"low-carb\",\n",
    "        \"low-sodium\", \"nut-free\", \"egg-free\", \"soy-free\", \"FODMAP\",\n",
    "        \"diabetic-friendly\", \"high-protein\"\n",
    "    ],\n",
    "    \n",
    "    \"AvailableIngredientsFocus\": [\n",
    "        \"must_use_specific: chicken, rice, vegetables\",\n",
    "        \"must_use_specific: pasta, tomatoes, cheese\",\n",
    "        \"must_use_specific: eggs, spinach, cheese\",\n",
    "        \"must_use_specific: salmon, lemon, herbs\",\n",
    "        \"general_pantry: basic ingredients\",\n",
    "        \"no_specific_ingredients: open to suggestions\"\n",
    "    ],\n",
    "    \n",
    "    \"CuisinePreference\": [\n",
    "        \"specific_cuisine: Italian\",\n",
    "        \"specific_cuisine: Mexican\",\n",
    "        \"specific_cuisine: Thai\",\n",
    "        \"specific_cuisine: Indian\",\n",
    "        \"specific_cuisine: Chinese\",\n",
    "        \"specific_cuisine: Mediterranean\",\n",
    "        \"specific_cuisine: Japanese\",\n",
    "        \"any_cuisine\",\n",
    "        \"avoid_specific: spicy\"\n",
    "    ],\n",
    "    \n",
    "    \"SkillLevelEffort\": [\n",
    "        \"beginner_easy_low_effort\",\n",
    "        \"intermediate_moderate_effort\",\n",
    "        \"advanced_complex_high_effort\"\n",
    "    ],\n",
    "    \n",
    "    \"TimeAvailability\": [\n",
    "        \"quick_under_30_mins\",\n",
    "        \"moderate_30_to_60_mins\",\n",
    "        \"flexible_no_time_constraint\"\n",
    "    ],\n",
    "    \n",
    "    \"QueryStyleAndDetail\": [\n",
    "        \"short_keywords_minimal_detail\",\n",
    "        \"natural_question_moderate_detail\",\n",
    "        \"detailed_request_high_detail\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Display dimension counts\n",
    "for dim, values in DIMENSIONS.items():\n",
    "    print(f\"{dim}: {len(values)} values\")\n",
    "\n",
    "print(f\"\\nTotal possible combinations: {18 * 6 * 9 * 3 * 3 * 3:,}\")\n",
    "print(\"(We'll generate a diverse subset of 10-20 tuples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Define Pydantic Models\n",
    "\n",
    "Pydantic provides **structured output** from LLM responses. This ensures we get valid, parseable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Dimension Tuple:\n",
      "{\n",
      "  \"DietaryNeedsOrRestrictions\": \"vegan\",\n",
      "  \"AvailableIngredientsFocus\": \"general_pantry\",\n",
      "  \"CuisinePreference\": \"specific_cuisine: Italian\",\n",
      "  \"SkillLevelEffort\": \"beginner_easy_low_effort\",\n",
      "  \"TimeAvailability\": \"quick_under_30_mins\",\n",
      "  \"QueryStyleAndDetail\": \"natural_question_moderate_detail\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pydantic models for structured LLM output\n",
    "\n",
    "class DimensionTuple(BaseModel):\n",
    "    \"\"\"Represents one combination of dimension values.\"\"\"\n",
    "    DietaryNeedsOrRestrictions: str\n",
    "    AvailableIngredientsFocus: str\n",
    "    CuisinePreference: str\n",
    "    SkillLevelEffort: str\n",
    "    TimeAvailability: str\n",
    "    QueryStyleAndDetail: str\n",
    "\n",
    "class DimensionTuplesList(BaseModel):\n",
    "    \"\"\"List of dimension tuples returned by LLM.\"\"\"\n",
    "    tuples: List[DimensionTuple]\n",
    "\n",
    "class QueriesList(BaseModel):\n",
    "    \"\"\"List of natural language queries.\"\"\"\n",
    "    queries: List[str]\n",
    "\n",
    "class QueryWithDimensions(BaseModel):\n",
    "    \"\"\"Query with associated dimension tuple for tracking.\"\"\"\n",
    "    id: str\n",
    "    query: str\n",
    "    dimension_tuple: DimensionTuple\n",
    "    is_realistic_and_kept: int = 1\n",
    "    notes_for_filtering: str = \"\"\n",
    "\n",
    "# Test the models\n",
    "example_tuple = DimensionTuple(\n",
    "    DietaryNeedsOrRestrictions=\"vegan\",\n",
    "    AvailableIngredientsFocus=\"general_pantry\",\n",
    "    CuisinePreference=\"specific_cuisine: Italian\",\n",
    "    SkillLevelEffort=\"beginner_easy_low_effort\",\n",
    "    TimeAvailability=\"quick_under_30_mins\",\n",
    "    QueryStyleAndDetail=\"natural_question_moderate_detail\"\n",
    ")\n",
    "\n",
    "print(\"Example Dimension Tuple:\")\n",
    "print(example_tuple.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: LLM Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ LLM helper function defined (with caching enabled)\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "MODEL_NAME = \"gpt-4o-mini\"  # Cost-effective model for generation\n",
    "\n",
    "# Note: Cache is already configured globally in Cell 3\n",
    "# litellm will automatically cache responses based on the messages and model\n",
    "# Re-running the same prompts will use cached responses (saving API costs)\n",
    "\n",
    "@traceable(run_type=\"llm\")\n",
    "def call_llm(messages: List[Dict[str, str]], response_format: Any) -> Any:\n",
    "    \"\"\"Call LLM with retry logic for robustness.\n",
    "    \n",
    "    Responses are automatically cached on disk. Duplicate requests will\n",
    "    return cached results, reducing API costs.\n",
    "    \"\"\"\n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = completion(\n",
    "                model=MODEL_NAME,\n",
    "                messages=messages,\n",
    "                response_format=response_format\n",
    "            )\n",
    "            return response_format(**json.loads(response.choices[0].message.content))\n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                raise e\n",
    "            time.sleep(1)  # Wait before retry\n",
    "    \n",
    "print(\"âœ“ LLM helper function defined (with caching enabled)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4: Generate Dimension Tuples\n",
    "\n",
    "We'll ask the LLM to generate **diverse combinations** of dimension values.\n",
    "\n",
    "**Key prompt engineering principles:**\n",
    "- Emphasize **balanced coverage** (don't over-represent any value)\n",
    "- Provide **example tuples** showing realistic combinations\n",
    "- Request **weird/unusual combinations** to test edge cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CONFIGURATION: Demo vs Full Mode\n",
    "# ========================================\n",
    "\n",
    "# Set DEMO_MODE = False for full dataset generation\n",
    "DEMO_MODE = True  # Default: Quick demo for tutorial\n",
    "\n",
    "if DEMO_MODE:\n",
    "    NUM_TUPLES = 5  # Generate 5 tuples (15 queries)\n",
    "    QUERIES_PER_TUPLE = 3\n",
    "    print(\"ðŸš€ DEMO MODE: Generating small sample for quick execution\")\n",
    "    print(f\"   Tuples: {NUM_TUPLES} | Queries per tuple: {QUERIES_PER_TUPLE}\")\n",
    "    print(f\"   Total queries: {NUM_TUPLES * QUERIES_PER_TUPLE}\")\n",
    "    print(\"   Estimated cost: $0.05-0.10 | Time: ~1-2 minutes\")\n",
    "else:\n",
    "    NUM_TUPLES = 15  # Generate 15 tuples (45-60 queries)\n",
    "    QUERIES_PER_TUPLE = 3\n",
    "    print(\"ðŸ“Š FULL MODE: Generating comprehensive query set\")\n",
    "    print(f\"   Tuples: {NUM_TUPLES} | Queries per tuple: {QUERIES_PER_TUPLE}\")\n",
    "    print(f\"   Total queries: {NUM_TUPLES * QUERIES_PER_TUPLE}\")\n",
    "    print(\"   Estimated cost: $0.20-0.40 | Time: ~5-10 minutes\")\n",
    "\n",
    "print(\"\\nðŸ’¡ To switch modes, change DEMO_MODE in this cell and re-run notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate tuples using configuration\n",
    "print(f\"Generating {NUM_TUPLES} dimension tuples...\")\n",
    "dimension_tuples = generate_dimension_tuples(num_tuples=NUM_TUPLES)\n",
    "\n",
    "print(f\"\\nâœ“ Generated {len(dimension_tuples)} tuples\\n\")\n",
    "\n",
    "# Display first 3 tuples\n",
    "for i, tuple_obj in enumerate(dimension_tuples[:3], 1):\n",
    "    print(f\"Tuple {i}:\")\n",
    "    print(json.dumps(tuple_obj.model_dump(), indent=2))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# VALIDATION: Verify tuple generation\n",
    "# ========================================\n",
    "\n",
    "# Assert tuples were generated\n",
    "assert len(dimension_tuples) > 0, \"No dimension tuples were generated\"\n",
    "assert len(dimension_tuples) == NUM_TUPLES, f\"Expected {NUM_TUPLES} tuples, got {len(dimension_tuples)}\"\n",
    "\n",
    "# Assert all tuples are valid Pydantic models\n",
    "for i, tuple_obj in enumerate(dimension_tuples):\n",
    "    assert isinstance(tuple_obj, DimensionTuple), f\"Tuple {i} is not a DimensionTuple instance\"\n",
    "    assert len(tuple_obj.DietaryNeedsOrRestrictions) > 0, f\"Tuple {i} has empty dietary restriction\"\n",
    "    assert len(tuple_obj.CuisinePreference) > 0, f\"Tuple {i} has empty cuisine preference\"\n",
    "\n",
    "print(f\"âœ… VALIDATION PASSED: Generated {len(dimension_tuples)} valid dimension tuples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 10 dimension tuples...\n",
      "\n",
      "âœ“ Generated 10 tuples\n",
      "\n",
      "Tuple 1:\n",
      "{\n",
      "  \"DietaryNeedsOrRestrictions\": \"vegan\",\n",
      "  \"AvailableIngredientsFocus\": \"must_use_specific: [tofu, spinach, quinoa]\",\n",
      "  \"CuisinePreference\": \"specific_cuisine: [Indian]\",\n",
      "  \"SkillLevelEffort\": \"beginner_easy_low_effort\",\n",
      "  \"TimeAvailability\": \"quick_under_30_mins\",\n",
      "  \"QueryStyleAndDetail\": \"natural_question_moderate_detail\"\n",
      "}\n",
      "\n",
      "Tuple 2:\n",
      "{\n",
      "  \"DietaryNeedsOrRestrictions\": \"keto\",\n",
      "  \"AvailableIngredientsFocus\": \"general_pantry\",\n",
      "  \"CuisinePreference\": \"any_cuisine\",\n",
      "  \"SkillLevelEffort\": \"intermediate_moderate_effort\",\n",
      "  \"TimeAvailability\": \"flexible_no_time_constraint\",\n",
      "  \"QueryStyleAndDetail\": \"short_keywords_minimal_detail\"\n",
      "}\n",
      "\n",
      "Tuple 3:\n",
      "{\n",
      "  \"DietaryNeedsOrRestrictions\": \"no restrictions\",\n",
      "  \"AvailableIngredientsFocus\": \"no_specific_ingredients\",\n",
      "  \"CuisinePreference\": \"avoid_specific: [Mexican]\",\n",
      "  \"SkillLevelEffort\": \"advanced_complex_high_effort\",\n",
      "  \"TimeAvailability\": \"moderate_30_to_60_mins\",\n",
      "  \"QueryStyleAndDetail\": \"detailed_request_high_detail\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate tuples\n",
    "print(\"Generating 10 dimension tuples...\")\n",
    "dimension_tuples = generate_dimension_tuples(num_tuples=10)\n",
    "\n",
    "print(f\"\\nâœ“ Generated {len(dimension_tuples)} tuples\\n\")\n",
    "\n",
    "# Display first 3 tuples\n",
    "for i, tuple_obj in enumerate(dimension_tuples[:3], 1):\n",
    "    print(f\"Tuple {i}:\")\n",
    "    print(json.dumps(tuple_obj.model_dump(), indent=2))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: Generate Natural Language Queries\n",
    "\n",
    "Now we convert each dimension tuple into a **realistic natural language query** that a user might ask.\n",
    "\n",
    "**Key features:**\n",
    "- Multiple queries per tuple (to increase coverage)\n",
    "- Natural language variations (typos, lowercase, emojis, text speak)\n",
    "- Realistic user query styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Query generation function defined\n"
     ]
    }
   ],
   "source": [
    "def generate_queries_for_tuple(dimension_tuple: DimensionTuple, num_queries: int = 3) -> List[str]:\n",
    "    \"\"\"Generate natural language queries for a given dimension tuple.\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"Generate {num_queries} different natural language queries for a recipe chatbot based on these characteristics:\n",
    "{dimension_tuple.model_dump_json(indent=2)}\n",
    "\n",
    "The queries should:\n",
    "1. Sound like real users asking for recipe help\n",
    "2. Naturally incorporate all the dimension values\n",
    "3. Vary in style and detail level\n",
    "4. Be realistic and practical\n",
    "5. Include natural variations in typing style, such as:\n",
    "   - Some queries in all lowercase\n",
    "   - Some with random capitalization\n",
    "   - Some with common typos\n",
    "   - Some with missing punctuation\n",
    "   - Some with emojis or text speak\n",
    "\n",
    "Generate {num_queries} unique queries that match the given dimensions, varying the text style naturally.\"\"\"\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    response = call_llm(messages, QueriesList)\n",
    "    return response.queries\n",
    "\n",
    "print(\"âœ“ Query generation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 3 queries for the first dimension tuple...\n",
      "\n",
      "Dimension Tuple:\n",
      "{\n",
      "  \"DietaryNeedsOrRestrictions\": \"vegan\",\n",
      "  \"AvailableIngredientsFocus\": \"must_use_specific: [tofu, spinach, quinoa]\",\n",
      "  \"CuisinePreference\": \"specific_cuisine: [Indian]\",\n",
      "  \"SkillLevelEffort\": \"beginner_easy_low_effort\",\n",
      "  \"TimeAvailability\": \"quick_under_30_mins\",\n",
      "  \"QueryStyleAndDetail\": \"natural_question_moderate_detail\"\n",
      "}\n",
      "\n",
      "Generated Queries:\n",
      "1. can u help me find an easy vegan recipe that uses tofu, spinach, and quinoa? I only have like 30 minutes to cook, and I really feel like something Indian tonight!\n",
      "2. Hey! ðŸŒ± I'm looking for a simple Indian vegan dish. I have some tofu, spinach, and quinoa that I need to use up! Any quick recipes under 30 mins? Thanks!\n",
      "3. do you have any beginner friendly vegan recipes? i need to use tofu, quinoa and spinach, something easy peasy and quick like less than 30 min. thx!\n"
     ]
    }
   ],
   "source": [
    "# Test query generation on first tuple\n",
    "print(\"Generating 3 queries for the first dimension tuple...\\n\")\n",
    "\n",
    "test_queries = generate_queries_for_tuple(dimension_tuples[0], num_queries=3)\n",
    "\n",
    "print(\"Dimension Tuple:\")\n",
    "print(json.dumps(dimension_tuples[0].model_dump(), indent=2))\n",
    "print(\"\\nGenerated Queries:\")\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"{i}. {query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Parallel Processing for Efficiency\n",
    "\n",
    "Generating queries sequentially is slow. We'll use **ThreadPoolExecutor** to parallelize LLM calls.\n",
    "\n",
    "**Benefits:**\n",
    "- ðŸš€ 5-10x faster generation\n",
    "- ðŸ“Š Progress tracking with tqdm\n",
    "- ðŸ”„ Handles failures gracefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# VALIDATION: Verify query generation\n",
    "# ========================================\n",
    "\n",
    "# Assert queries were generated\n",
    "assert len(queries) > 0, \"No queries were generated\"\n",
    "expected_count = NUM_TUPLES * QUERIES_PER_TUPLE\n",
    "assert len(queries) <= expected_count, f\"Generated too many queries: {len(queries)} > {expected_count}\"\n",
    "assert len(queries) >= expected_count * 0.8, f\"Generated too few queries: {len(queries)} < {expected_count * 0.8} (80% of expected)\"\n",
    "\n",
    "# Assert all queries are valid\n",
    "for i, query_obj in enumerate(queries):\n",
    "    assert isinstance(query_obj, QueryWithDimensions), f\"Query {i} is not a QueryWithDimensions instance\"\n",
    "    assert len(query_obj.query) >= 10, f\"Query {i} is too short: '{query_obj.query}'\"\n",
    "    assert len(query_obj.id) > 0, f\"Query {i} has no ID\"\n",
    "    assert query_obj.dimension_tuple is not None, f\"Query {i} has no dimension tuple\"\n",
    "\n",
    "# Check for reasonable diversity\n",
    "unique_queries_count = len(set(q.query for q in queries))\n",
    "diversity_rate = unique_queries_count / len(queries)\n",
    "assert diversity_rate >= 0.8, f\"Low diversity: only {diversity_rate:.1%} unique queries\"\n",
    "\n",
    "print(\"âœ… VALIDATION PASSED:\")\n",
    "print(f\"   - Generated {len(queries)} queries\")\n",
    "print(\"   - All queries have valid structure\")\n",
    "print(f\"   - Diversity rate: {diversity_rate:.1%}\")\n",
    "print(f\"   - Average query length: {sum(len(q.query) for q in queries) / len(queries):.0f} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all queries in parallel using configuration\n",
    "queries = generate_queries_parallel(\n",
    "    dimension_tuples=dimension_tuples,\n",
    "    queries_per_tuple=QUERIES_PER_TUPLE,\n",
    "    max_workers=5\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Generated {len(queries)} total queries from {len(dimension_tuples)} tuples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 3 queries each for 10 dimension tuples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Generated 30 total queries from 10 tuples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate all queries in parallel\n",
    "queries = generate_queries_parallel(\n",
    "    dimension_tuples=dimension_tuples,\n",
    "    queries_per_tuple=3,\n",
    "    max_workers=5\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Generated {len(queries)} total queries from {len(dimension_tuples)} tuples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 7: Quality Validation\n",
    "\n",
    "Before exporting, check for:\n",
    "- **Duplicates** - Remove exact duplicate queries\n",
    "- **Too short** - Filter queries <5 characters\n",
    "- **Too generic** - Flag vague queries like \"recipe\"\n",
    "- **Diversity** - Ensure variety across dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total queries: 30\n",
      "Unique queries: 30\n",
      "Duplicates: 0\n",
      "\n",
      "Query length statistics:\n",
      "  Min: 31 characters\n",
      "  Max: 304 characters\n",
      "  Average: 132.2 characters\n",
      "\n",
      "Sample queries:\n",
      "1. [SYN001] keto recipes using pantry stuff\n",
      "2. [SYN002] Keto idea? i have some random ingredients!\n",
      "3. [SYN003] any keto meals that take a bit of effort? ðŸ¤”\n",
      "4. [SYN004] gluten-free recipe pls, flexible ingredients\n",
      "5. [SYN005] looking for gluten free meals!! got stuff in pantry\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "query_texts = [q.query for q in queries]\n",
    "unique_queries = set(query_texts)\n",
    "\n",
    "print(f\"Total queries: {len(query_texts)}\")\n",
    "print(f\"Unique queries: {len(unique_queries)}\")\n",
    "print(f\"Duplicates: {len(query_texts) - len(unique_queries)}\")\n",
    "\n",
    "# Check query lengths\n",
    "query_lengths = [len(q.query) for q in queries]\n",
    "print(\"\\nQuery length statistics:\")\n",
    "print(f\"  Min: {min(query_lengths)} characters\")\n",
    "print(f\"  Max: {max(query_lengths)} characters\")\n",
    "print(f\"  Average: {sum(query_lengths) / len(query_lengths):.1f} characters\")\n",
    "\n",
    "# Display sample queries\n",
    "print(\"\\nSample queries:\")\n",
    "for i, q in enumerate(queries[:5], 1):\n",
    "    print(f\"{i}. [{q.id}] {q.query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 8: Export to CSV\n",
    "\n",
    "Save queries to CSV for use with [`scripts/bulk_test.py`](../../scripts/bulk_test.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved 30 queries to /Users/rajnishkhatri/Documents/recipe-chatbot/homeworks/hw2/synthetic_queries_for_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "def save_queries_to_csv(queries: List[QueryWithDimensions], filename: str = \"synthetic_queries_for_analysis.csv\"):\n",
    "    \"\"\"Save generated queries to CSV.\"\"\"\n",
    "    \n",
    "    output_path = Path.cwd() / filename\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame([\n",
    "        {\n",
    "            'id': q.id,\n",
    "            'query': q.query,\n",
    "            'dimension_tuple_json': q.dimension_tuple.model_dump_json(),\n",
    "            'is_realistic_and_kept': q.is_realistic_and_kept,\n",
    "            'notes_for_filtering': q.notes_for_filtering\n",
    "        }\n",
    "        for q in queries\n",
    "    ])\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"âœ“ Saved {len(queries)} queries to {output_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Save queries\n",
    "df = save_queries_to_csv(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows of exported CSV:\n",
      "\n",
      "       id                                              query\n",
      "0  SYN001                    keto recipes using pantry stuff\n",
      "1  SYN002         Keto idea? i have some random ingredients!\n",
      "2  SYN003        any keto meals that take a bit of effort? ðŸ¤”\n",
      "3  SYN004       gluten-free recipe pls, flexible ingredients\n",
      "4  SYN005  looking for gluten free meals!! got stuff in p...\n"
     ]
    }
   ],
   "source": [
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows of exported CSV:\\n\")\n",
    "print(df[['id', 'query']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cost Estimation and Optimization\n",
    "\n",
    "### Estimated Costs (using gpt-4o-mini)\n",
    "\n",
    "- **Input tokens:** ~500 tokens per tuple generation + ~300 per query generation\n",
    "- **Output tokens:** ~200 tokens per tuple generation + ~50 per query\n",
    "- **Total:** For 10 tuples Ã— 3 queries = ~30,000 tokens\n",
    "- **Cost:** ~$0.10-0.30 (gpt-4o-mini rates)\n",
    "\n",
    "### Optimization Tips\n",
    "\n",
    "1. **Use cheaper models** - gpt-4o-mini instead of gpt-4o\n",
    "2. **Cache results** - Save generated queries, don't regenerate\n",
    "3. **Reduce queries_per_tuple** - 1-2 instead of 3-5\n",
    "4. **Batch processing** - Generate more tuples at once (fewer API calls)\n",
    "5. **Use local models** - Llama, Mistral (free, but slower/lower quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "After generating queries:\n",
    "\n",
    "1. **Run bulk test** on generated queries:\n",
    "   ```bash\n",
    "   python scripts/bulk_test.py --queries homeworks/hw2/synthetic_queries_for_analysis.csv\n",
    "   ```\n",
    "\n",
    "2. **Perform open coding** on bot responses (see [Error Analysis Concepts](error_analysis_concepts.md))\n",
    "\n",
    "3. **Build failure taxonomy** (see [Failure Mode Taxonomy Tutorial](failure_mode_taxonomy_tutorial.md))\n",
    "\n",
    "4. **Iterate:** Generate more queries targeting specific failure modes\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- âœ… **LLM-based generation scales** - Create 100+ queries in minutes\n",
    "- âœ… **Dimensions ensure coverage** - Systematic testing across all variations\n",
    "- âœ… **Parallel processing saves time** - 5-10x faster with ThreadPoolExecutor\n",
    "- âœ… **Structured output with Pydantic** - Reliable, parseable responses\n",
    "- âœ… **Natural language variations** - Typos, lowercase, emojis make queries realistic\n",
    "- âœ… **Cost-effective** - gpt-4o-mini makes this affordable at scale\n",
    "\n",
    "---\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "- [Error Analysis Concepts](error_analysis_concepts.md) - Open and axial coding methodology\n",
    "- [Failure Mode Taxonomy Tutorial](failure_mode_taxonomy_tutorial.md) - Build structured failure taxonomies\n",
    "- [generate_synthetic_queries.py](generate_synthetic_queries.py) - Full script implementation\n",
    "- [HW2 README](README.md) - Complete assignment instructions\n",
    "\n",
    "---\n",
    "\n",
    "**Tutorial Status:** âœ… Complete\n",
    "**Last Updated:** 2025-10-29\n",
    "**Maintainer:** AI Evaluation Course Team"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Recipe Chatbot (.venv)",
   "language": "python",
   "name": "recipe-chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}