{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension Generation Tutorial\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By completing this tutorial, you will:\n",
    "- âœ… Generate dimension tuples (combinations) using LLMs\n",
    "- âœ… Convert tuples to natural language queries\n",
    "- âœ… Validate and filter generated queries\n",
    "- âœ… Optimize costs with parallel processing\n",
    "- âœ… Export queries to CSV for systematic testing\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed [Error Analysis Concepts Tutorial](error_analysis_concepts.md)\n",
    "- Identified 3-5 key dimensions for query generation\n",
    "- OpenAI API key configured in `.env` file\n",
    "\n",
    "## Estimated Time\n",
    "\n",
    "**Execution Time:** 10-15 minutes (depending on API latency)\n",
    "\n",
    "**âš ï¸ Cost Warning:** This notebook makes LLM API calls. Estimated cost: $0.10-0.30 for full execution (using gpt-4o-mini)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root to path for imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd().parent.parent))\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(Path.cwd().parent.parent / '.env')\n",
    "\n",
    "# Verify API key is loaded\n",
    "if not os.environ.get('OPENAI_API_KEY'):\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment. Check your .env file.\")\n",
    "\n",
    "print(\"âœ“ Environment configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "from litellm import completion\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Why Dimension-Based Query Generation?\n",
    "\n",
    "In **HW1**, you manually created 10+ diverse queries. This approach:\n",
    "- âœ… Works for small test sets\n",
    "- âŒ Doesn't scale to 100+ queries\n",
    "- âŒ Hard to ensure balanced coverage\n",
    "- âŒ Time-consuming and error-prone\n",
    "\n",
    "**Dimension-based generation** solves this:\n",
    "1. **Define dimensions** (cuisine, dietary, meal type, time, etc.)\n",
    "2. **Generate tuples** - LLM creates diverse combinations\n",
    "3. **Generate queries** - LLM converts tuples to natural language\n",
    "4. **Validate** - Filter unrealistic or duplicate queries\n",
    "5. **Export** - Save to CSV for systematic testing\n",
    "\n",
    "**Key Benefits:**\n",
    "- ðŸš€ Generate 50-100 queries in minutes\n",
    "- ðŸ“Š Systematic coverage across all dimensions\n",
    "- ðŸ”„ Reproducible (can regenerate with different seeds)\n",
    "- âœ… Includes natural language variations\n",
    "\n",
    "**Reference:** See [`generate_synthetic_queries.py`](generate_synthetic_queries.py) for full implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Define Your Dimensions\n",
    "\n",
    "Based on **error analysis** (HW2 Part 2), identify dimensions where your bot frequently fails or needs comprehensive testing.\n",
    "\n",
    "For our Recipe Bot, we'll use **6 dimensions**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dimension values\n",
    "\n",
    "DIMENSIONS = {\n",
    "    \"DietaryNeedsOrRestrictions\": [\n",
    "        \"vegan\", \"vegetarian\", \"gluten-free\", \"dairy-free\", \"keto\", \"paleo\",\n",
    "        \"halal\", \"kosher\", \"no restrictions\", \"pescatarian\", \"low-carb\",\n",
    "        \"low-sodium\", \"nut-free\", \"egg-free\", \"soy-free\", \"FODMAP\",\n",
    "        \"diabetic-friendly\", \"high-protein\"\n",
    "    ],\n",
    "    \n",
    "    \"AvailableIngredientsFocus\": [\n",
    "        \"must_use_specific: chicken, rice, vegetables\",\n",
    "        \"must_use_specific: pasta, tomatoes, cheese\",\n",
    "        \"must_use_specific: eggs, spinach, cheese\",\n",
    "        \"must_use_specific: salmon, lemon, herbs\",\n",
    "        \"general_pantry: basic ingredients\",\n",
    "        \"no_specific_ingredients: open to suggestions\"\n",
    "    ],\n",
    "    \n",
    "    \"CuisinePreference\": [\n",
    "        \"specific_cuisine: Italian\",\n",
    "        \"specific_cuisine: Mexican\",\n",
    "        \"specific_cuisine: Thai\",\n",
    "        \"specific_cuisine: Indian\",\n",
    "        \"specific_cuisine: Chinese\",\n",
    "        \"specific_cuisine: Mediterranean\",\n",
    "        \"specific_cuisine: Japanese\",\n",
    "        \"any_cuisine\",\n",
    "        \"avoid_specific: spicy\"\n",
    "    ],\n",
    "    \n",
    "    \"SkillLevelEffort\": [\n",
    "        \"beginner_easy_low_effort\",\n",
    "        \"intermediate_moderate_effort\",\n",
    "        \"advanced_complex_high_effort\"\n",
    "    ],\n",
    "    \n",
    "    \"TimeAvailability\": [\n",
    "        \"quick_under_30_mins\",\n",
    "        \"moderate_30_to_60_mins\",\n",
    "        \"flexible_no_time_constraint\"\n",
    "    ],\n",
    "    \n",
    "    \"QueryStyleAndDetail\": [\n",
    "        \"short_keywords_minimal_detail\",\n",
    "        \"natural_question_moderate_detail\",\n",
    "        \"detailed_request_high_detail\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Display dimension counts\n",
    "for dim, values in DIMENSIONS.items():\n",
    "    print(f\"{dim}: {len(values)} values\")\n",
    "\n",
    "print(f\"\\nTotal possible combinations: {18 * 6 * 9 * 3 * 3 * 3:,}\")\n",
    "print(\"(We'll generate a diverse subset of 10-20 tuples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Define Pydantic Models\n",
    "\n",
    "Pydantic provides **structured output** from LLM responses. This ensures we get valid, parseable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic models for structured LLM output\n",
    "\n",
    "class DimensionTuple(BaseModel):\n",
    "    \"\"\"Represents one combination of dimension values.\"\"\"\n",
    "    DietaryNeedsOrRestrictions: str\n",
    "    AvailableIngredientsFocus: str\n",
    "    CuisinePreference: str\n",
    "    SkillLevelEffort: str\n",
    "    TimeAvailability: str\n",
    "    QueryStyleAndDetail: str\n",
    "\n",
    "class DimensionTuplesList(BaseModel):\n",
    "    \"\"\"List of dimension tuples returned by LLM.\"\"\"\n",
    "    tuples: List[DimensionTuple]\n",
    "\n",
    "class QueriesList(BaseModel):\n",
    "    \"\"\"List of natural language queries.\"\"\"\n",
    "    queries: List[str]\n",
    "\n",
    "class QueryWithDimensions(BaseModel):\n",
    "    \"\"\"Query with associated dimension tuple for tracking.\"\"\"\n",
    "    id: str\n",
    "    query: str\n",
    "    dimension_tuple: DimensionTuple\n",
    "    is_realistic_and_kept: int = 1\n",
    "    notes_for_filtering: str = \"\"\n",
    "\n",
    "# Test the models\n",
    "example_tuple = DimensionTuple(\n",
    "    DietaryNeedsOrRestrictions=\"vegan\",\n",
    "    AvailableIngredientsFocus=\"general_pantry\",\n",
    "    CuisinePreference=\"specific_cuisine: Italian\",\n",
    "    SkillLevelEffort=\"beginner_easy_low_effort\",\n",
    "    TimeAvailability=\"quick_under_30_mins\",\n",
    "    QueryStyleAndDetail=\"natural_question_moderate_detail\"\n",
    ")\n",
    "\n",
    "print(\"Example Dimension Tuple:\")\n",
    "print(example_tuple.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: LLM Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MODEL_NAME = \"gpt-4o-mini\"  # Cost-effective model for generation\n",
    "\n",
    "def call_llm(messages: List[Dict[str, str]], response_format: Any) -> Any:\n",
    "    \"\"\"Call LLM with retry logic for robustness.\"\"\"\n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = completion(\n",
    "                model=MODEL_NAME,\n",
    "                messages=messages,\n",
    "                response_format=response_format\n",
    "            )\n",
    "            return response_format(**json.loads(response.choices[0].message.content))\n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                raise e\n",
    "            time.sleep(1)  # Wait before retry\n",
    "    \n",
    "print(\"âœ“ LLM helper function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4: Generate Dimension Tuples\n",
    "\n",
    "We'll ask the LLM to generate **diverse combinations** of dimension values.\n",
    "\n",
    "**Key prompt engineering principles:**\n",
    "- Emphasize **balanced coverage** (don't over-represent any value)\n",
    "- Provide **example tuples** showing realistic combinations\n",
    "- Request **weird/unusual combinations** to test edge cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dimension_tuples(num_tuples: int = 10) -> List[DimensionTuple]:\n",
    "    \"\"\"Generate diverse dimension tuples using LLM.\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"Generate {num_tuples} diverse combinations of dimension values for a recipe chatbot.\n",
    "Each combination should represent a different user scenario. Ensure balanced coverage across all dimensions - don't over-represent any particular value or combination.\n",
    "\n",
    "Important: Aim for an even distribution across all dimensions. For example:\n",
    "- Don't generate too many dietary restrictions combinations\n",
    "- Don't focus too heavily on quick recipes\n",
    "- Don't over-represent any particular cuisine\n",
    "- Vary the query styles naturally\n",
    "- Try to use weird combinations of ingredients required in AvailableIngredientsFocus\n",
    "\n",
    "DietaryNeedsOrRestrictions:\n",
    "- vegan, vegetarian, gluten-free, dairy-free, keto, paleo, halal, kosher, no restrictions, pescatarian, low-carb, low-sodium, nut-free, egg-free, soy-free, FODMAP, diabetic-friendly, high-protein\n",
    "\n",
    "AvailableIngredientsFocus:\n",
    "- must_use_specific: [list of ingredients]\n",
    "- general_pantry: basic ingredients\n",
    "- no_specific_ingredients: open to suggestions\n",
    "\n",
    "CuisinePreference:\n",
    "- specific_cuisine: [cuisine type]\n",
    "- any_cuisine\n",
    "- avoid_specific: [cuisine type]\n",
    "\n",
    "SkillLevelEffort:\n",
    "- beginner_easy_low_effort\n",
    "- intermediate_moderate_effort\n",
    "- advanced_complex_high_effort\n",
    "\n",
    "TimeAvailability:\n",
    "- quick_under_30_mins\n",
    "- moderate_30_to_60_mins\n",
    "- flexible_no_time_constraint\n",
    "\n",
    "QueryStyleAndDetail:\n",
    "- short_keywords_minimal_detail\n",
    "- natural_question_moderate_detail\n",
    "- detailed_request_high_detail\n",
    "\n",
    "Generate {num_tuples} unique dimension tuples with balanced diversity across all dimensions.\"\"\"\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    response = call_llm(messages, DimensionTuplesList)\n",
    "    return response.tuples\n",
    "\n",
    "print(\"âœ“ Tuple generation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate tuples\n",
    "print(\"Generating 10 dimension tuples...\")\n",
    "dimension_tuples = generate_dimension_tuples(num_tuples=10)\n",
    "\n",
    "print(f\"\\nâœ“ Generated {len(dimension_tuples)} tuples\\n\")\n",
    "\n",
    "# Display first 3 tuples\n",
    "for i, tuple_obj in enumerate(dimension_tuples[:3], 1):\n",
    "    print(f\"Tuple {i}:\")\n",
    "    print(json.dumps(tuple_obj.model_dump(), indent=2))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: Generate Natural Language Queries\n",
    "\n",
    "Now we convert each dimension tuple into a **realistic natural language query** that a user might ask.\n",
    "\n",
    "**Key features:**\n",
    "- Multiple queries per tuple (to increase coverage)\n",
    "- Natural language variations (typos, lowercase, emojis, text speak)\n",
    "- Realistic user query styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_queries_for_tuple(dimension_tuple: DimensionTuple, num_queries: int = 3) -> List[str]:\n",
    "    \"\"\"Generate natural language queries for a given dimension tuple.\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"Generate {num_queries} different natural language queries for a recipe chatbot based on these characteristics:\n",
    "{dimension_tuple.model_dump_json(indent=2)}\n",
    "\n",
    "The queries should:\n",
    "1. Sound like real users asking for recipe help\n",
    "2. Naturally incorporate all the dimension values\n",
    "3. Vary in style and detail level\n",
    "4. Be realistic and practical\n",
    "5. Include natural variations in typing style, such as:\n",
    "   - Some queries in all lowercase\n",
    "   - Some with random capitalization\n",
    "   - Some with common typos\n",
    "   - Some with missing punctuation\n",
    "   - Some with emojis or text speak\n",
    "\n",
    "Generate {num_queries} unique queries that match the given dimensions, varying the text style naturally.\"\"\"\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    response = call_llm(messages, QueriesList)\n",
    "    return response.queries\n",
    "\n",
    "print(\"âœ“ Query generation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query generation on first tuple\n",
    "print(\"Generating 3 queries for the first dimension tuple...\\n\")\n",
    "\n",
    "test_queries = generate_queries_for_tuple(dimension_tuples[0], num_queries=3)\n",
    "\n",
    "print(f\"Dimension Tuple:\")\n",
    "print(json.dumps(dimension_tuples[0].model_dump(), indent=2))\n",
    "print(f\"\\nGenerated Queries:\")\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"{i}. {query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Parallel Processing for Efficiency\n",
    "\n",
    "Generating queries sequentially is slow. We'll use **ThreadPoolExecutor** to parallelize LLM calls.\n",
    "\n",
    "**Benefits:**\n",
    "- ðŸš€ 5-10x faster generation\n",
    "- ðŸ“Š Progress tracking with tqdm\n",
    "- ðŸ”„ Handles failures gracefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_queries_parallel(\n",
    "    dimension_tuples: List[DimensionTuple],\n",
    "    queries_per_tuple: int = 3,\n",
    "    max_workers: int = 5\n",
    ") -> List[QueryWithDimensions]:\n",
    "    \"\"\"Generate queries in parallel for all dimension tuples.\"\"\"\n",
    "    \n",
    "    all_queries = []\n",
    "    query_id = 1\n",
    "    \n",
    "    print(f\"Generating {queries_per_tuple} queries each for {len(dimension_tuples)} dimension tuples...\")\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all tasks\n",
    "        future_to_tuple = {\n",
    "            executor.submit(generate_queries_for_tuple, dim_tuple, queries_per_tuple): i \n",
    "            for i, dim_tuple in enumerate(dimension_tuples)\n",
    "        }\n",
    "        \n",
    "        # Process completed tasks with progress bar\n",
    "        with tqdm(total=len(dimension_tuples), desc=\"Generating Queries\") as pbar:\n",
    "            for future in as_completed(future_to_tuple):\n",
    "                tuple_idx = future_to_tuple[future]\n",
    "                try:\n",
    "                    queries = future.result()\n",
    "                    for query in queries:\n",
    "                        all_queries.append(QueryWithDimensions(\n",
    "                            id=f\"SYN{query_id:03d}\",\n",
    "                            query=query,\n",
    "                            dimension_tuple=dimension_tuples[tuple_idx]\n",
    "                        ))\n",
    "                        query_id += 1\n",
    "                    pbar.update(1)\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nTuple {tuple_idx + 1} failed: {e}\")\n",
    "                    pbar.update(1)\n",
    "    \n",
    "    return all_queries\n",
    "\n",
    "print(\"âœ“ Parallel generation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all queries in parallel\n",
    "queries = generate_queries_parallel(\n",
    "    dimension_tuples=dimension_tuples,\n",
    "    queries_per_tuple=3,\n",
    "    max_workers=5\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Generated {len(queries)} total queries from {len(dimension_tuples)} tuples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 7: Quality Validation\n",
    "\n",
    "Before exporting, check for:\n",
    "- **Duplicates** - Remove exact duplicate queries\n",
    "- **Too short** - Filter queries <5 characters\n",
    "- **Too generic** - Flag vague queries like \"recipe\"\n",
    "- **Diversity** - Ensure variety across dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "query_texts = [q.query for q in queries]\n",
    "unique_queries = set(query_texts)\n",
    "\n",
    "print(f\"Total queries: {len(query_texts)}\")\n",
    "print(f\"Unique queries: {len(unique_queries)}\")\n",
    "print(f\"Duplicates: {len(query_texts) - len(unique_queries)}\")\n",
    "\n",
    "# Check query lengths\n",
    "query_lengths = [len(q.query) for q in queries]\n",
    "print(f\"\\nQuery length statistics:\")\n",
    "print(f\"  Min: {min(query_lengths)} characters\")\n",
    "print(f\"  Max: {max(query_lengths)} characters\")\n",
    "print(f\"  Average: {sum(query_lengths) / len(query_lengths):.1f} characters\")\n",
    "\n",
    "# Display sample queries\n",
    "print(f\"\\nSample queries:\")\n",
    "for i, q in enumerate(queries[:5], 1):\n",
    "    print(f\"{i}. [{q.id}] {q.query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 8: Export to CSV\n",
    "\n",
    "Save queries to CSV for use with [`scripts/bulk_test.py`](../../scripts/bulk_test.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_queries_to_csv(queries: List[QueryWithDimensions], filename: str = \"synthetic_queries_for_analysis.csv\"):\n",
    "    \"\"\"Save generated queries to CSV.\"\"\"\n",
    "    \n",
    "    output_path = Path.cwd() / filename\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame([\n",
    "        {\n",
    "            'id': q.id,\n",
    "            'query': q.query,\n",
    "            'dimension_tuple_json': q.dimension_tuple.model_dump_json(),\n",
    "            'is_realistic_and_kept': q.is_realistic_and_kept,\n",
    "            'notes_for_filtering': q.notes_for_filtering\n",
    "        }\n",
    "        for q in queries\n",
    "    ])\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"âœ“ Saved {len(queries)} queries to {output_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Save queries\n",
    "df = save_queries_to_csv(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows of exported CSV:\\n\")\n",
    "print(df[['id', 'query']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cost Estimation and Optimization\n",
    "\n",
    "### Estimated Costs (using gpt-4o-mini)\n",
    "\n",
    "- **Input tokens:** ~500 tokens per tuple generation + ~300 per query generation\n",
    "- **Output tokens:** ~200 tokens per tuple generation + ~50 per query\n",
    "- **Total:** For 10 tuples Ã— 3 queries = ~30,000 tokens\n",
    "- **Cost:** ~$0.10-0.30 (gpt-4o-mini rates)\n",
    "\n",
    "### Optimization Tips\n",
    "\n",
    "1. **Use cheaper models** - gpt-4o-mini instead of gpt-4o\n",
    "2. **Cache results** - Save generated queries, don't regenerate\n",
    "3. **Reduce queries_per_tuple** - 1-2 instead of 3-5\n",
    "4. **Batch processing** - Generate more tuples at once (fewer API calls)\n",
    "5. **Use local models** - Llama, Mistral (free, but slower/lower quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "After generating queries:\n",
    "\n",
    "1. **Run bulk test** on generated queries:\n",
    "   ```bash\n",
    "   python scripts/bulk_test.py --queries homeworks/hw2/synthetic_queries_for_analysis.csv\n",
    "   ```\n",
    "\n",
    "2. **Perform open coding** on bot responses (see [Error Analysis Concepts](error_analysis_concepts.md))\n",
    "\n",
    "3. **Build failure taxonomy** (see [Failure Mode Taxonomy Tutorial](failure_mode_taxonomy_tutorial.md))\n",
    "\n",
    "4. **Iterate:** Generate more queries targeting specific failure modes\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- âœ… **LLM-based generation scales** - Create 100+ queries in minutes\n",
    "- âœ… **Dimensions ensure coverage** - Systematic testing across all variations\n",
    "- âœ… **Parallel processing saves time** - 5-10x faster with ThreadPoolExecutor\n",
    "- âœ… **Structured output with Pydantic** - Reliable, parseable responses\n",
    "- âœ… **Natural language variations** - Typos, lowercase, emojis make queries realistic\n",
    "- âœ… **Cost-effective** - gpt-4o-mini makes this affordable at scale\n",
    "\n",
    "---\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "- [Error Analysis Concepts](error_analysis_concepts.md) - Open and axial coding methodology\n",
    "- [Failure Mode Taxonomy Tutorial](failure_mode_taxonomy_tutorial.md) - Build structured failure taxonomies\n",
    "- [generate_synthetic_queries.py](generate_synthetic_queries.py) - Full script implementation\n",
    "- [HW2 README](README.md) - Complete assignment instructions\n",
    "\n",
    "---\n",
    "\n",
    "**Tutorial Status:** âœ… Complete\n",
    "**Last Updated:** 2025-10-29\n",
    "**Maintainer:** AI Evaluation Course Team"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
