{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Judge Development Tutorial: Engineering Effective LLM-as-Judge Prompts\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By completing this tutorial, you will be able to:\n",
    "- ‚úÖ Engineer effective judge prompts with clear evaluation criteria\n",
    "- ‚úÖ Select strategic few-shot examples from the train set\n",
    "- ‚úÖ Use structured output with Pydantic models for reliable parsing\n",
    "- ‚úÖ Iteratively refine prompts using the dev set\n",
    "- ‚úÖ Measure judge performance using TPR/TNR metrics\n",
    "- ‚úÖ Analyze and debug common judge errors\n",
    "- ‚úÖ Create confusion matrices and error visualizations\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed [Data Labeling Tutorial](data_labeling_tutorial.ipynb)\n",
    "- Have train/dev/test splits ready\n",
    "- Understanding of TPR/TNR metrics from [LLM-as-Judge Concepts](llm_judge_concepts.md)\n",
    "\n",
    "## Estimated Time\n",
    "\n",
    "**Execution Time:** 20-30 minutes  \n",
    "**Cost:** ~$0.50-2.00 for dev set evaluation (depends on model and dev set size)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup complete\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "# LLM API\n",
    "import litellm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data manipulation and visualization\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Environment configuration\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Configure plotting\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä FULL MODE: Evaluating on complete dev set\n",
      "   Full dev set: 40 examples\n",
      "   Estimated cost: $0.80-1.50 | Time: ~3-5 minutes\n",
      "\n",
      "üí° To switch modes, change DEMO_MODE in this cell and re-run notebook\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CONFIGURATION: Demo vs Full Mode\n",
    "# ========================================\n",
    "\n",
    "# Set DEMO_MODE = False to evaluate on full dev set\n",
    "DEMO_MODE = False  # Default: Quick demo for tutorial\n",
    "\n",
    "if DEMO_MODE:\n",
    "    DEV_SAMPLE_SIZE = 20  # Evaluate 20 examples\n",
    "    print(\"üöÄ DEMO MODE: Evaluating on sample of dev set\")\n",
    "    print(f\"   Sample size: {DEV_SAMPLE_SIZE} examples\")\n",
    "    print(\"   Estimated cost: $0.30-0.50 | Time: ~1-2 minutes\")\n",
    "else:\n",
    "    DEV_SAMPLE_SIZE = None  # Use full dev set (40 examples)\n",
    "    print(\"üìä FULL MODE: Evaluating on complete dev set\")\n",
    "    print(\"   Full dev set: 40 examples\")\n",
    "    print(\"   Estimated cost: $0.80-1.50 | Time: ~3-5 minutes\")\n",
    "\n",
    "print(\"\\nüí° To switch modes, change DEMO_MODE in this cell and re-run notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load Data Splits\n",
    "\n",
    "Load the train/dev/test splits created in the Data Labeling Tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded data splits:\n",
      "Train: 15 examples\n",
      "Dev: 40 examples\n",
      "Test: 46 examples\n",
      "\n",
      "üìã Sample from train set:                                               query dietary_restriction  \\\n",
      "0  Vegan protein smoothie that doesn't taste chalky               vegan   \n",
      "1    I'm mostly vegetarian but I eat fish sometimes         pescatarian   \n",
      "2      Low-carb pizza recipe - I miss pizza so much            low-carb   \n",
      "\n",
      "                                            response  success  error trace_id  \\\n",
      "0  Certainly! Here's a delicious Vegan Banana Blu...     True    NaN    19_21   \n",
      "1  Great! How about trying a flavorful **Lemon He...     True    NaN    44_29   \n",
      "2  Absolutely! Here's a delicious low-carb caulif...     True    NaN    20_30   \n",
      "\n",
      "   query_id label                                          reasoning  \\\n",
      "0        19  PASS  The recipe adheres to the vegan dietary restri...   \n",
      "1        44  PASS  The recipe for Lemon Herb Grilled Salmon with ...   \n",
      "2        20  PASS  The recipe for cauliflower crust pizza adheres...   \n",
      "\n",
      "  confidence  labeled  \n",
      "0       HIGH     True  \n",
      "1       HIGH     True  \n",
      "2       HIGH     True  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>dietary_restriction</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vegan protein smoothie that doesn't taste chalky</td>\n",
       "      <td>vegan</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm mostly vegetarian but I eat fish sometimes</td>\n",
       "      <td>pescatarian</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Low-carb pizza recipe - I miss pizza so much</td>\n",
       "      <td>low-carb</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              query dietary_restriction label\n",
       "0  Vegan protein smoothie that doesn't taste chalky               vegan  PASS\n",
       "1    I'm mostly vegetarian but I eat fish sometimes         pescatarian  PASS\n",
       "2      Low-carb pizza recipe - I miss pizza so much            low-carb  PASS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data splits\n",
    "train_df = pd.read_csv('data/train_set.csv')\n",
    "dev_df = pd.read_csv('data/dev_set.csv')\n",
    "test_df = pd.read_csv('data/test_set.csv')\n",
    "\n",
    "print(\"‚úÖ Loaded data splits:\")\n",
    "print(f\"Train: {len(train_df)} examples\")\n",
    "print(f\"Dev: {len(dev_df)} examples\")\n",
    "print(f\"Test: {len(test_df)} examples\")\n",
    "\n",
    "# Display sample from train set\n",
    "print(f\"\\nüìã Sample from train set: {train_df.head(3)}\")\n",
    "display(train_df[['query', 'dietary_restriction', 'label']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Few-Shot Example Selection\n",
    "\n",
    "### Strategy: Balanced Sampling\n",
    "\n",
    "**Goal:** Select few-shot examples that:\n",
    "1. Cover both PASS and FAIL cases\n",
    "2. Include edge cases and nuanced scenarios\n",
    "3. Demonstrate clear reasoning\n",
    "\n",
    "**Recommended ratio:** 1 PASS : 3 FAIL\n",
    "- Why? Most systems have more failure patterns to learn\n",
    "- Helps prevent overly lenient judging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Selected 4 few-shot examples:\n",
      "PASS: 1\n",
      "FAIL: 3\n",
      "\n",
      "üìã Few-shot examples:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>dietary_restriction</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I want to make a birthday cake but I'm diabeti...</td>\n",
       "      <td>diabetic-friendly</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gluten-light recipe - I'm not celiac just sens...</td>\n",
       "      <td>gluten-free</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gluten-light recipe - I'm not celiac just sens...</td>\n",
       "      <td>gluten-free</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gluten-light recipe - I'm not celiac just sens...</td>\n",
       "      <td>gluten-free</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                query dietary_restriction  \\\n",
       "6   I want to make a birthday cake but I'm diabeti...   diabetic-friendly   \n",
       "7   Gluten-light recipe - I'm not celiac just sens...         gluten-free   \n",
       "14  Gluten-light recipe - I'm not celiac just sens...         gluten-free   \n",
       "3   Gluten-light recipe - I'm not celiac just sens...         gluten-free   \n",
       "\n",
       "   label  \n",
       "6   PASS  \n",
       "7   FAIL  \n",
       "14  FAIL  \n",
       "3   FAIL  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def select_few_shot_examples(train_df: pd.DataFrame, \n",
    "                             num_pass: int = 1, \n",
    "                             num_fail: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"Select few-shot examples from train set.\"\"\"\n",
    "    \n",
    "    # Separate by label\n",
    "    pass_examples = train_df[train_df['label'] == 'PASS']\n",
    "    fail_examples = train_df[train_df['label'] == 'FAIL']\n",
    "    \n",
    "    # Sample randomly\n",
    "    selected_pass = pass_examples.sample(n=min(num_pass, len(pass_examples)), random_state=42)\n",
    "    selected_fail = fail_examples.sample(n=min(num_fail, len(fail_examples)), random_state=42)\n",
    "    \n",
    "    # Combine\n",
    "    few_shot_df = pd.concat([selected_pass, selected_fail])\n",
    "    \n",
    "    return few_shot_df\n",
    "\n",
    "# Select few-shot examples\n",
    "few_shot_examples = select_few_shot_examples(train_df)\n",
    "\n",
    "print(f\"‚úÖ Selected {len(few_shot_examples)} few-shot examples:\")\n",
    "print(f\"PASS: {len(few_shot_examples[few_shot_examples['label'] == 'PASS'])}\")\n",
    "print(f\"FAIL: {len(few_shot_examples[few_shot_examples['label'] == 'FAIL'])}\")\n",
    "\n",
    "print(\"\\nüìã Few-shot examples:\")\n",
    "display(few_shot_examples[['query', 'dietary_restriction', 'label']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Judge Prompt Construction\n",
    "\n",
    "### Prompt Structure\n",
    "\n",
    "An effective judge prompt has:\n",
    "1. **Role definition**: \"You are an expert nutritionist...\"\n",
    "2. **Dietary restriction definitions**: Clear, comprehensive\n",
    "3. **Evaluation criteria**: Explicit PASS/FAIL rules\n",
    "4. **Few-shot examples**: 3-5 diverse cases with reasoning\n",
    "5. **Output format**: Structured JSON for reliable parsing\n",
    "\n",
    "Let's build the prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Judge prompt created\n",
      "Prompt length: 4200 characters\n",
      "\n",
      "üìù Preview (first 500 chars):\n",
      "You are an expert nutritionist and dietary specialist evaluating whether recipe responses properly adhere\n",
      "    to specified dietary restrictions.\n",
      "\n",
      "DIETARY RESTRICTION DEFINITIONS:\n",
      "- Vegan: No animal products (meat, dairy, eggs, honey, etc.)\n",
      "- Vegetarian: No meat or fish, but dairy and eggs are allowed\n",
      "- Gluten-free: No wheat, barley, rye, or other gluten-containing grains\n",
      "- Dairy-free: No milk, cheese, butter, yogurt, or other dairy products\n",
      "- Keto: Very low carb (typically <20g net carbs), high ...\n"
     ]
    }
   ],
   "source": [
    "def create_judge_prompt(few_shot_examples: pd.DataFrame) -> str:\n",
    "    \"\"\"Create judge prompt with few-shot examples.\"\"\"\n",
    "    \n",
    "    prompt = \"\"\"You are an expert nutritionist and dietary specialist evaluating whether recipe responses properly adhere\n",
    "    to specified dietary restrictions.\n",
    "\n",
    "DIETARY RESTRICTION DEFINITIONS:\n",
    "- Vegan: No animal products (meat, dairy, eggs, honey, etc.)\n",
    "- Vegetarian: No meat or fish, but dairy and eggs are allowed\n",
    "- Gluten-free: No wheat, barley, rye, or other gluten-containing grains\n",
    "- Dairy-free: No milk, cheese, butter, yogurt, or other dairy products\n",
    "- Keto: Very low carb (typically <20g net carbs), high fat, moderate protein\n",
    "- Paleo: No grains, legumes, dairy, refined sugar, or processed foods\n",
    "- Pescatarian: No meat except fish and seafood\n",
    "- Kosher: Follows Jewish dietary laws (no pork, shellfish, mixing meat/dairy)\n",
    "- Halal: Follows Islamic dietary laws (no pork, alcohol, proper slaughter)\n",
    "- Nut-free: No tree nuts or peanuts\n",
    "- Low-carb: Significantly reduced carbohydrates (typically <50g per day)\n",
    "- Sugar-free: No added sugars or high-sugar ingredients\n",
    "\n",
    "EVALUATION CRITERIA:\n",
    "- PASS: Recipe clearly adheres to the dietary restriction with appropriate ingredients\n",
    "- FAIL: Recipe contains ingredients or methods that violate the dietary restriction\n",
    "- Be strict but reasonable in your evaluation\n",
    "- Consider both explicit ingredients and hidden sources (e.g., honey in vegan, gluten in soy sauce)\n",
    "\n",
    "FEW-SHOT EXAMPLES:\n",
    "\"\"\"\n",
    "    \n",
    "    # Add few-shot examples\n",
    "    for idx, row in few_shot_examples.iterrows():\n",
    "        prompt += f\"\\nExample {idx + 1}:\\n\"\n",
    "        prompt += f\"Query: {row['query']}\\n\"\n",
    "        prompt += f\"Dietary Restriction: {row['dietary_restriction']}\\n\"\n",
    "        prompt += f\"Response: {str(row['response'])[:300]}...\\n\"\n",
    "        \n",
    "        # Add reasoning if available\n",
    "        if 'reasoning' in row and pd.notna(row['reasoning']):\n",
    "            prompt += f\"Reasoning: {str(row['reasoning'])[:200]}...\\n\"\n",
    "        \n",
    "        prompt += f\"Answer: {row['label']}\\n\"\n",
    "    \n",
    "    # Add evaluation template\n",
    "    prompt += \"\"\"\n",
    "\n",
    "NOW EVALUATE:\n",
    "Query: __QUERY__\n",
    "Dietary Restriction: __DIETARY_RESTRICTION__\n",
    "Response: __RESPONSE__\n",
    "\n",
    "Provide your analysis in the following JSON format:\n",
    "{\n",
    "    \"reasoning\": \"Step-by-step explanation citing specific ingredients\",\n",
    "    \"answer\": \"PASS\" or \"FAIL\"\n",
    "}\n",
    "\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Create judge prompt\n",
    "judge_prompt_template = create_judge_prompt(few_shot_examples)\n",
    "\n",
    "print(\"‚úÖ Judge prompt created\")\n",
    "print(f\"Prompt length: {len(judge_prompt_template)} characters\")\n",
    "print(f\"\\nüìù Preview (first 500 chars):\\n{judge_prompt_template[:500]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Test Judge on Dev Set\n",
    "\n",
    "### Judge Evaluation Function\n",
    "\n",
    "Let's create a function to run our judge on examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing judge on single example...\n",
      "\n",
      "Query: I want something light but filling\n",
      "Dietary Restriction: low-carb\n",
      "True Label: FAIL\n",
      "\n",
      "‚è≥ Calling judge...\n",
      "\n",
      "‚úÖ Judge prediction: FAIL\n",
      "Reasoning: The recipe for the Grilled Chicken and Vegetable Quinoa Salad includes quinoa, which is a grain that is relatively high in carbohydrates. Specifically, 1/2 cup of cooked quinoa contains approximately 20-25g of net carbs, which exceeds the typical low-carb limit of <50g per day. Additionally, the recipe does not provide a total carb count for the entire dish, making it difficult to assess if it adheres to the low-carb dietary restriction. Therefore, while the dish may be light and filling, it does not meet the low-carb criteria.\n",
      "\n",
      "‚úÖ CORRECT\n"
     ]
    }
   ],
   "source": [
    "def judge_single_example(prompt_template: str, query: str, dietary_restriction: str, \n",
    "                        response: str, model: str = \"gpt-4o-mini\") -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Run judge on a single example.\"\"\"\n",
    "    try:\n",
    "        # Fill in the template\n",
    "        prompt = prompt_template.replace(\"__QUERY__\", query)\n",
    "        prompt = prompt.replace(\"__DIETARY_RESTRICTION__\", dietary_restriction)\n",
    "        prompt = prompt.replace(\"__RESPONSE__\", response)\n",
    "        \n",
    "        # Call LLM\n",
    "        completion = litellm.completion(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        \n",
    "        response_text = completion.choices[0].message.content.strip()\n",
    "        \n",
    "        # Parse JSON\n",
    "        if \"```json\" in response_text:\n",
    "            json_start = response_text.find(\"```json\") + 7\n",
    "            json_end = response_text.find(\"```\", json_start)\n",
    "            json_text = response_text[json_start:json_end].strip()\n",
    "        elif \"{\" in response_text and \"}\" in response_text:\n",
    "            json_start = response_text.find(\"{\")\n",
    "            json_end = response_text.rfind(\"}\") + 1\n",
    "            json_text = response_text[json_start:json_end]\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "        result = json.loads(json_text)\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test on a single dev example\n",
    "test_example = dev_df.iloc[0]\n",
    "\n",
    "print(\"üß™ Testing judge on single example...\\n\")\n",
    "print(f\"Query: {test_example['query']}\")\n",
    "print(f\"Dietary Restriction: {test_example['dietary_restriction']}\")\n",
    "print(f\"True Label: {test_example['label']}\")\n",
    "print(\"\\n‚è≥ Calling judge...\\n\")\n",
    "\n",
    "judge_result = judge_single_example(\n",
    "    judge_prompt_template,\n",
    "    test_example['query'],\n",
    "    test_example['dietary_restriction'],\n",
    "    test_example['response']\n",
    ")\n",
    "\n",
    "if judge_result:\n",
    "    print(f\"‚úÖ Judge prediction: {judge_result['answer']}\")\n",
    "    print(f\"Reasoning: {judge_result['reasoning']}\")\n",
    "    \n",
    "    if judge_result['answer'] == test_example['label']:\n",
    "        print(\"\\n‚úÖ CORRECT\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå INCORRECT (expected {test_example['label']})\")\n",
    "else:\n",
    "    print(\"‚ùå Judge failed to return valid result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample subset using configuration\n",
    "if DEV_SAMPLE_SIZE:\n",
    "    dev_sample = dev_df.sample(n=min(DEV_SAMPLE_SIZE, len(dev_df)), random_state=42)\n",
    "    print(f\"üìä Evaluating on {len(dev_sample)} dev examples (DEMO MODE - sampled for cost efficiency)\")\n",
    "else:\n",
    "    dev_sample = dev_df\n",
    "    print(f\"üìä Evaluating on {len(dev_sample)} dev examples (FULL MODE - complete dev set)\")\n",
    "\n",
    "print(\"‚è≥ This may take 1-2 minutes...\\n\")\n",
    "\n",
    "# Evaluate\n",
    "results = []\n",
    "\n",
    "for idx, row in dev_sample.iterrows():\n",
    "    judge_result = judge_single_example(\n",
    "        judge_prompt_template,\n",
    "        row['query'],\n",
    "        row['dietary_restriction'],\n",
    "        row['response']\n",
    "    )\n",
    "    \n",
    "    if judge_result:\n",
    "        results.append({\n",
    "            'query': row['query'],\n",
    "            'dietary_restriction': row['dietary_restriction'],\n",
    "            'true_label': row['label'],\n",
    "            'predicted_label': judge_result['answer'],\n",
    "            'reasoning': judge_result['reasoning'],\n",
    "            'correct': judge_result['answer'] == row['label']\n",
    "        })\n",
    "    else:\n",
    "        results.append({\n",
    "            'query': row['query'],\n",
    "            'dietary_restriction': row['dietary_restriction'],\n",
    "            'true_label': row['label'],\n",
    "            'predicted_label': 'ERROR',\n",
    "            'reasoning': 'Judge failed',\n",
    "            'correct': False\n",
    "        })\n",
    "    \n",
    "    # Progress indicator\n",
    "    if (len(results)) % 5 == 0:\n",
    "        print(f\"Processed {len(results)}/{len(dev_sample)} examples...\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(f\"\\n‚úÖ Evaluation complete! Processed {len(results_df)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluating on 20 dev examples (sampled for cost efficiency)\n",
      "‚è≥ This may take 1-2 minutes...\n",
      "\n",
      "Processed 5/20 examples...\n",
      "Processed 10/20 examples...\n",
      "Processed 15/20 examples...\n",
      "Processed 20/20 examples...\n",
      "\n",
      "‚úÖ Evaluation complete! Processed 20 examples\n"
     ]
    }
   ],
   "source": [
    "# Sample subset for tutorial\n",
    "dev_sample = dev_df.sample(n=min(20, len(dev_df)), random_state=42)\n",
    "\n",
    "print(f\"üìä Evaluating on {len(dev_sample)} dev examples (sampled for cost efficiency)\")\n",
    "print(\"‚è≥ This may take 1-2 minutes...\\n\")\n",
    "\n",
    "# Evaluate\n",
    "results = []\n",
    "\n",
    "for idx, row in dev_sample.iterrows():\n",
    "    judge_result = judge_single_example(\n",
    "        judge_prompt_template,\n",
    "        row['query'],\n",
    "        row['dietary_restriction'],\n",
    "        row['response']\n",
    "    )\n",
    "    \n",
    "    if judge_result:\n",
    "        results.append({\n",
    "            'query': row['query'],\n",
    "            'dietary_restriction': row['dietary_restriction'],\n",
    "            'true_label': row['label'],\n",
    "            'predicted_label': judge_result['answer'],\n",
    "            'reasoning': judge_result['reasoning'],\n",
    "            'correct': judge_result['answer'] == row['label']\n",
    "        })\n",
    "    else:\n",
    "        results.append({\n",
    "            'query': row['query'],\n",
    "            'dietary_restriction': row['dietary_restriction'],\n",
    "            'true_label': row['label'],\n",
    "            'predicted_label': 'ERROR',\n",
    "            'reasoning': 'Judge failed',\n",
    "            'correct': False\n",
    "        })\n",
    "    \n",
    "    # Progress indicator\n",
    "    if (len(results)) % 5 == 0:\n",
    "        print(f\"Processed {len(results)}/{len(dev_sample)} examples...\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(f\"\\n‚úÖ Evaluation complete! Processed {len(results_df)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Calculate TPR and TNR\n",
    "\n",
    "### Performance Metrics\n",
    "\n",
    "**TPR (True Positive Rate) - Sensitivity**\n",
    "- Of all actual PASS cases, what % did judge correctly identify?\n",
    "- TPR = TP / (TP + FN)\n",
    "\n",
    "**TNR (True Negative Rate) - Specificity**\n",
    "- Of all actual FAIL cases, what % did judge correctly identify?\n",
    "- TNR = TN / (TN + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Judge Performance on Dev Set Sample:\n",
      "\n",
      "TPR (Sensitivity): 1.000 (100.0%)\n",
      "TNR (Specificity): 1.000 (100.0%)\n",
      "Accuracy: 1.000 (100.0%)\n",
      "\n",
      "Confusion Matrix:\n",
      "True Positives: 16\n",
      "False Negatives: 0\n",
      "True Negatives: 4\n",
      "False Positives: 0\n"
     ]
    }
   ],
   "source": [
    "def calculate_tpr_tnr(results_df: pd.DataFrame) -> Dict[str, float]:\n",
    "    \"\"\"Calculate TPR and TNR from evaluation results.\"\"\"\n",
    "    \n",
    "    # Filter out ERROR cases\n",
    "    valid_results = results_df[results_df['predicted_label'] != 'ERROR']\n",
    "    \n",
    "    # Get true positives, false negatives, true negatives, false positives\n",
    "    tp = len(valid_results[(valid_results['true_label'] == 'PASS') & (valid_results['predicted_label'] == 'PASS')])\n",
    "    fn = len(valid_results[(valid_results['true_label'] == 'PASS') & (valid_results['predicted_label'] == 'FAIL')])\n",
    "    tn = len(valid_results[(valid_results['true_label'] == 'FAIL') & (valid_results['predicted_label'] == 'FAIL')])\n",
    "    fp = len(valid_results[(valid_results['true_label'] == 'FAIL') & (valid_results['predicted_label'] == 'PASS')])\n",
    "    \n",
    "    # Calculate TPR and TNR\n",
    "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = (tp + tn) / len(valid_results) if len(valid_results) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'TPR': tpr,\n",
    "        'TNR': tnr,\n",
    "        'Accuracy': accuracy,\n",
    "        'TP': tp,\n",
    "        'FN': fn,\n",
    "        'TN': tn,\n",
    "        'FP': fp,\n",
    "        'Total': len(valid_results)\n",
    "    }\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = calculate_tpr_tnr(results_df)\n",
    "\n",
    "print(\"\\nüìä Judge Performance on Dev Set Sample:\")\n",
    "print(f\"\\nTPR (Sensitivity): {metrics['TPR']:.3f} ({metrics['TPR']*100:.1f}%)\")\n",
    "print(f\"TNR (Specificity): {metrics['TNR']:.3f} ({metrics['TNR']*100:.1f}%)\")\n",
    "print(f\"Accuracy: {metrics['Accuracy']:.3f} ({metrics['Accuracy']*100:.1f}%)\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(f\"True Positives: {metrics['TP']}\")\n",
    "print(f\"False Negatives: {metrics['FN']}\")\n",
    "print(f\"True Negatives: {metrics['TN']}\")\n",
    "print(f\"False Positives: {metrics['FP']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Confusion Matrix Interpretation:\n",
      "Top-Left (TP=16): Judge correctly identified PASS cases\n",
      "Top-Right (FP=0): Judge incorrectly called FAIL cases as PASS (lenient)\n",
      "Bottom-Left (FN=0): Judge incorrectly called PASS cases as FAIL (strict)\n",
      "Bottom-Right (TN=4): Judge correctly identified FAIL cases\n"
     ]
    }
   ],
   "source": [
    "# Create confusion matrix\n",
    "valid_results = results_df[results_df['predicted_label'] != 'ERROR']\n",
    "\n",
    "if len(valid_results) > 0:\n",
    "    # Map labels to binary\n",
    "    y_true = valid_results['true_label'].map({'PASS': 1, 'FAIL': 0})\n",
    "    y_pred = valid_results['predicted_label'].map({'PASS': 1, 'FAIL': 0})\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1, 0])\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['PASS', 'FAIL'], \n",
    "                yticklabels=['PASS', 'FAIL'],\n",
    "                cbar=False, ax=ax, annot_kws={'size': 16, 'weight': 'bold'})\n",
    "    ax.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Confusion Matrix: Judge Performance', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Add interpretation\n",
    "    print(\"\\nüìä Confusion Matrix Interpretation:\")\n",
    "    print(f\"Top-Left (TP={cm[0,0]}): Judge correctly identified PASS cases\")\n",
    "    print(f\"Top-Right (FP={cm[0,1]}): Judge incorrectly called FAIL cases as PASS (lenient)\")\n",
    "    print(f\"Bottom-Left (FN={cm[1,0]}): Judge incorrectly called PASS cases as FAIL (strict)\")\n",
    "    print(f\"Bottom-Right (TN={cm[1,1]}): Judge correctly identified FAIL cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Error Analysis\n",
    "\n",
    "### False Positives (Judge too lenient)\n",
    "\n",
    "Cases where judge said PASS but should have said FAIL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå False Positives: 0\n",
      "‚úÖ No false positives found!\n"
     ]
    }
   ],
   "source": [
    "# Find false positives\n",
    "false_positives = results_df[\n",
    "    (results_df['true_label'] == 'FAIL') & \n",
    "    (results_df['predicted_label'] == 'PASS')\n",
    "]\n",
    "\n",
    "print(f\"‚ùå False Positives: {len(false_positives)}\")\n",
    "\n",
    "if len(false_positives) > 0:\n",
    "    print(\"\\nüìã Examples:\")\n",
    "    for idx, row in false_positives.head(3).iterrows():\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Query: {row['query']}\")\n",
    "        print(f\"Dietary Restriction: {row['dietary_restriction']}\")\n",
    "        print(f\"True Label: {row['true_label']} | Predicted: {row['predicted_label']}\")\n",
    "        print(f\"Judge Reasoning: {row['reasoning'][:200]}...\")\n",
    "else:\n",
    "    print(\"‚úÖ No false positives found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Negatives (Judge too strict)\n",
    "\n",
    "Cases where judge said FAIL but should have said PASS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå False Negatives: 0\n",
      "‚úÖ No false negatives found!\n"
     ]
    }
   ],
   "source": [
    "# Find false negatives\n",
    "false_negatives = results_df[\n",
    "    (results_df['true_label'] == 'PASS') & \n",
    "    (results_df['predicted_label'] == 'FAIL')\n",
    "]\n",
    "\n",
    "print(f\"‚ùå False Negatives: {len(false_negatives)}\")\n",
    "\n",
    "if len(false_negatives) > 0:\n",
    "    print(\"\\nüìã Examples:\")\n",
    "    for idx, row in false_negatives.head(3).iterrows():\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Query: {row['query']}\")\n",
    "        print(f\"Dietary Restriction: {row['dietary_restriction']}\")\n",
    "        print(f\"True Label: {row['true_label']} | Predicted: {row['predicted_label']}\")\n",
    "        print(f\"Judge Reasoning: {row['reasoning'][:200]}...\")\n",
    "else:\n",
    "    print(\"‚úÖ No false negatives found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Iterative Refinement\n",
    "\n",
    "### How to Improve Your Judge\n",
    "\n",
    "Based on error analysis, consider:\n",
    "\n",
    "**If TPR is low (<0.85)** - Judge is too strict:\n",
    "- ‚úÖ Clarify PASS criteria more explicitly\n",
    "- ‚úÖ Add few-shot examples showing edge cases that should pass\n",
    "- ‚úÖ Emphasize \"be reasonable\" in evaluation instructions\n",
    "\n",
    "**If TNR is low (<0.85)** - Judge is too lenient:\n",
    "- ‚úÖ Strengthen FAIL criteria with explicit violations\n",
    "- ‚úÖ Add few-shot examples showing subtle violations\n",
    "- ‚úÖ Emphasize \"be strict\" in evaluation instructions\n",
    "- ‚úÖ Include edge cases in few-shot (honey in vegan, gluten in soy sauce)\n",
    "\n",
    "**General improvements:**\n",
    "- ‚úÖ Add more diverse few-shot examples (more than 4)\n",
    "- ‚úÖ Include reasoning in few-shot examples\n",
    "- ‚úÖ Use a higher-quality judge model (GPT-4o instead of GPT-4o-mini)\n",
    "- ‚úÖ Add specific failure modes you've identified from error analysis\n",
    "\n",
    "### Iteration Workflow\n",
    "\n",
    "1. Evaluate on dev set (above)\n",
    "2. Analyze errors (false positives/negatives)\n",
    "3. Refine prompt based on patterns\n",
    "4. Re-evaluate on dev set\n",
    "5. Repeat 3-5 times maximum (avoid overfitting!)\n",
    "6. When satisfied, evaluate once on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Save Judge Prompt\n",
    "\n",
    "Save your finalized judge prompt for use in evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved:\n",
      "  - results/judge_prompt.txt\n",
      "  - results/dev_evaluation_results.csv\n",
      "  - results/dev_metrics.json\n"
     ]
    }
   ],
   "source": [
    "# Create results directory\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "# Save judge prompt\n",
    "with open('results/judge_prompt.txt', 'w') as f:\n",
    "    f.write(judge_prompt_template)\n",
    "\n",
    "# Save dev evaluation results\n",
    "results_df.to_csv('results/dev_evaluation_results.csv', index=False)\n",
    "\n",
    "# Save metrics\n",
    "with open('results/dev_metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Saved:\")\n",
    "print(\"  - results/judge_prompt.txt\")\n",
    "print(\"  - results/dev_evaluation_results.csv\")\n",
    "print(\"  - results/dev_metrics.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We've Accomplished\n",
    "\n",
    "‚úÖ Loaded train/dev/test splits  \n",
    "‚úÖ Selected strategic few-shot examples (1 PASS : 3 FAIL ratio)  \n",
    "‚úÖ Constructed comprehensive judge prompt with dietary definitions  \n",
    "‚úÖ Tested judge on dev set sample  \n",
    "‚úÖ Calculated TPR and TNR metrics  \n",
    "‚úÖ Created confusion matrix visualization  \n",
    "‚úÖ Analyzed false positives and false negatives  \n",
    "‚úÖ Identified improvement strategies  \n",
    "‚úÖ Saved judge prompt and evaluation results  \n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Refine prompt** based on error analysis (iterate 2-3 times on dev set)\n",
    "2. **Final test set evaluation**: Use `scripts/evaluate_judge.py` on test set (ONCE ONLY!)\n",
    "3. **Apply to production data**: Use `scripts/run_full_evaluation.py` on large dataset\n",
    "4. **Statistical correction**: Apply [Bias Correction Tutorial](bias_correction_tutorial.md) with judgy\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- ‚úÖ **Few-shot examples are critical** - Choose diverse, representative cases\n",
    "- ‚úÖ **TPR/TNR reveal judge bias** - Optimize based on your use case priorities\n",
    "- ‚úÖ **Error analysis guides refinement** - False positives/negatives show blind spots\n",
    "- ‚úÖ **Iterate on dev set only** - Limit to 3-5 iterations to avoid overfitting\n",
    "- ‚úÖ **Test set is sacred** - Evaluate once at the end\n",
    "- ‚úÖ **Model choice matters** - Premium models (GPT-4o) have higher TPR/TNR\n",
    "\n",
    "---\n",
    "\n",
    "**Tutorial Status:** ‚úÖ Complete  \n",
    "**Last Updated:** 2025-10-29  \n",
    "**Maintainer:** AI Evaluation Course Team"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Recipe Chatbot (.venv)",
   "language": "python",
   "name": "recipe-chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
