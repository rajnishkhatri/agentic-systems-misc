{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 18: Logical Fallacy Detection\n",
    "## Part 1: Cherry-Picked Benchmarks\n",
    "\n",
    "**Objective:** Understand how \"Cherry-Picked Benchmarks\" mislead AI evaluation and learn to identify them using data-driven methods.\n",
    "\n",
    "### Learning Objectives\n",
    "By the end of this notebook, you will be able to:\n",
    "1. **Define** \"Cherry-Picked Benchmarks\" and explain why they represent a statistical Hasty Generalization.\n",
    "2. **Analyze** real-world examples (like the Gemini demo) to understand the gap between demo and reality.\n",
    "3. **Evaluate** a dispute resolution scenario where \"99% Accuracy\" is misleading.\n",
    "4. **Apply** a \"Red Flags\" checklist to audit AI performance claims."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What are Cherry-Picked Benchmarks?\n",
    "\n",
    "**Definition:** Cherry-Picking in AI benchmarks occurs when performance is reported on a specific subset of data that flatters the system, while ignoring edge cases, failures, or more representative datasets.\n",
    "\n",
    "> \"It works perfectly (on my machine).\"\n",
    "\n",
    "It is a statistical form of the **Hasty Generalization** fallacy. You take a small, non-representative sample (the \"cherry\") and generalize its properties to the entire population (the \"tree\").\n",
    "\n",
    "In AI, this often manifests as:\n",
    "- **Selection Bias:** Choosing test data that you know the model handles well.\n",
    "- **Survivorship Bias:** Reporting only the successful runs or models.\n",
    "- **Seed Hacking:** Running an experiment 100 times and reporting only the best result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Real-World Example: The Google Gemini Demo\n",
    "\n",
    "In December 2023, Google released a video showing their Gemini model interacting in real-time video. The AI seemed to respond instantly to voice and video cues with zero latency.\n",
    "\n",
    "**The Reality:**\n",
    "It was later revealed that the video was **not real-time**. It was stitched together from still image frames and text prompts. The latency was edited out.\n",
    "\n",
    "**Why this is dangerous:**\n",
    "This is a classic \"Demo-to-Production\" leap. The company \"cherry-picked\" the successful interactions and the presentation format to imply a capability (real-time video reasoning) that didn't actually exist in that form. If you built a product assuming that latency, it would fail immediately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Domain Scenario: The \"99% Accuracy\" Dispute Classifier\n",
    "\n",
    "Let's look at a concrete example from our **Dispute Resolution Chatbot**.\n",
    "\n",
    "**The Pitch:**\n",
    "> \"Our new `ReasonCodeClassifier` achieves **99% accuracy** on the golden test set! It's ready for production.\"\n",
    "\n",
    "**The Hidden Data:**\n",
    "The \"golden test set\" contained 100 records:\n",
    "- **100%** were **Visa** transactions.\n",
    "- **100%** were Reason Code **10.4**.\n",
    "\n",
    "**The Production Reality:**\n",
    "When deployed to a diverse environment (Amex, Mastercard, distinct Reason Codes), the model blindly classified everything as \"Visa 10.4\".\n",
    "\n",
    "**The Result:**\n",
    "Real-world accuracy dropped from **99%** to **~25%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. ðŸš© Red Flags Checklist\n",
    "\n",
    "When evaluating AI claims, use this checklist to spot potential cherry-picking:\n",
    "\n",
    "- [ ] **The \"Single Metric\" Flex:** Claims like \"95% Accuracy\" without defining the dataset distribution.\n",
    "- [ ] **The \"Internal\" Test Set:** \"Tested on our proprietary internal benchmark\" (which no one else can audit).\n",
    "- [ ] **\"Best of N\" Reporting:** Reporting the single best run instead of the mean and variance (Seed Hacking).\n",
    "- [ ] **Perfect Round Numbers:** \"100% success rate\" usually implies the test was too easy or data leaked."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
