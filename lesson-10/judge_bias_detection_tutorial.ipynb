{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Judge Bias Detection Tutorial\n",
    "\n",
    "## Cost Warning\n",
    "\n",
    "- **DEMO MODE**: $0.50-1.00 (30 comparisons for bias detection)\n",
    "- **FULL MODE**: $2.00-3.00 (100 comparisons for statistical significance)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "\n",
    "1. Detect self-preference bias (judges favoring their own model's outputs)\n",
    "2. Detect position bias (judges favoring first or second position in A/B tests)\n",
    "3. Detect verbosity bias (judges favoring longer responses)\n",
    "4. Visualize bias patterns with statistical tests\n",
    "5. Implement mitigation strategies (position swapping, length normalization)\n",
    "6. Understand when biases invalidate evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DEMO_MODE = True  # Set to False for full dataset\n",
    "NUM_COMPARISONS = 10 if DEMO_MODE else 40\n",
    "\n",
    "print(f\"Running in {'DEMO' if DEMO_MODE else 'FULL'} mode\")\n",
    "print(f\"Testing {NUM_COMPARISONS} comparisons per bias type = {NUM_COMPARISONS * 3} total evaluations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from scipy import stats\n",
    "from dotenv import load_dotenv\n",
    "import litellm\n",
    "\n",
    "# Add backend to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "from backend.ai_judge_framework import GenericCriteriaJudge\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API key\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY not found in environment variables\"\n",
    "print(\"âœ… Setup complete. API key verified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Type 1: Self-Preference Bias\n",
    "\n",
    "**Definition**: Judges favor outputs generated by their own model.\n",
    "\n",
    "**Detection Method**: Compare same-model judgments (GPT-4o judging GPT-4o outputs) vs cross-model judgments (GPT-4o judging Claude outputs).\n",
    "\n",
    "**Expected Behavior**: Judges should be equally critical of outputs regardless of source model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data for self-preference bias\n",
    "# We'll use identical-quality responses but label them as from different models\n",
    "\n",
    "test_queries_self_bias = [\n",
    "    {\n",
    "        \"query\": \"How do I make chocolate chip cookies?\",\n",
    "        \"response\": \"Mix butter, sugar, eggs, and flour. Add chocolate chips. Bake at 350F for 12 minutes.\",\n",
    "        \"model_a\": \"gpt-4o\",\n",
    "        \"model_b\": \"claude-sonnet\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the best way to cook salmon?\",\n",
    "        \"response\": \"Season with salt and pepper. Bake at 400F for 12-15 minutes until flaky.\",\n",
    "        \"model_a\": \"gpt-4o\",\n",
    "        \"model_b\": \"claude-sonnet\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How long to boil pasta?\",\n",
    "        \"response\": \"Boil for 8-10 minutes for al dente, or follow package instructions.\",\n",
    "        \"model_a\": \"gpt-4o\",\n",
    "        \"model_b\": \"claude-sonnet\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What temperature for roasting vegetables?\",\n",
    "        \"response\": \"Roast at 425F for 25-30 minutes, tossing halfway through.\",\n",
    "        \"model_a\": \"gpt-4o\",\n",
    "        \"model_b\": \"claude-sonnet\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How to make scrambled eggs?\",\n",
    "        \"response\": \"Beat eggs with milk. Cook in butter over medium heat, stirring gently.\",\n",
    "        \"model_a\": \"gpt-4o\",\n",
    "        \"model_b\": \"claude-sonnet\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the secret to fluffy pancakes?\",\n",
    "        \"response\": \"Don't overmix the batter and let it rest for 5 minutes before cooking.\",\n",
    "        \"model_a\": \"gpt-4o\",\n",
    "        \"model_b\": \"claude-sonnet\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How to properly season a steak?\",\n",
    "        \"response\": \"Apply salt and pepper generously to both sides at least 40 minutes before cooking.\",\n",
    "        \"model_a\": \"gpt-4o\",\n",
    "        \"model_b\": \"claude-sonnet\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the ideal coffee brewing temperature?\",\n",
    "        \"response\": \"Water should be between 195-205F for optimal extraction.\",\n",
    "        \"model_a\": \"gpt-4o\",\n",
    "        \"model_b\": \"claude-sonnet\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How long to rest meat after cooking?\",\n",
    "        \"response\": \"Let meat rest for 5-10 minutes to allow juices to redistribute.\",\n",
    "        \"model_a\": \"gpt-4o\",\n",
    "        \"model_b\": \"claude-sonnet\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the best way to reheat pizza?\",\n",
    "        \"response\": \"Reheat in a skillet over medium heat for 2-3 minutes for crispy crust.\",\n",
    "        \"model_a\": \"gpt-4o\",\n",
    "        \"model_b\": \"claude-sonnet\"\n",
    "    }\n",
    "]\n",
    "\n",
    "test_queries_self_bias = test_queries_self_bias[:NUM_COMPARISONS]\n",
    "\n",
    "# Create judge for helpfulness (binary criterion)\n",
    "judge_gpt4o = GenericCriteriaJudge(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    criteria=\"helpfulness\",\n",
    "    criteria_description=\"The response MUST fully address the user's query with sufficient detail.\",\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "# Test self-preference: Same response, but tell judge it's from different models\n",
    "print(f\"Testing self-preference bias with {len(test_queries_self_bias)} queries...\\n\")\n",
    "\n",
    "self_bias_results = []\n",
    "\n",
    "for i, example in enumerate(test_queries_self_bias, 1):\n",
    "    # Judge when told it's from GPT-4o (same model)\n",
    "    query_gpt4o = f\"{example['query']} [Generated by {example['model_a']}]\"\n",
    "    result_gpt4o = judge_gpt4o.evaluate(query=query_gpt4o, response=example['response'])\n",
    "    score_gpt4o = 1 if result_gpt4o.score == \"PASS\" else 0\n",
    "    \n",
    "    # Judge when told it's from Claude (different model)\n",
    "    query_claude = f\"{example['query']} [Generated by {example['model_b']}]\"\n",
    "    result_claude = judge_gpt4o.evaluate(query=query_claude, response=example['response'])\n",
    "    score_claude = 1 if result_claude.score == \"PASS\" else 0\n",
    "    \n",
    "    self_bias_results.append({\n",
    "        \"query\": example['query'],\n",
    "        \"score_same_model\": score_gpt4o,\n",
    "        \"score_different_model\": score_claude,\n",
    "        \"bias_detected\": score_gpt4o > score_claude\n",
    "    })\n",
    "    \n",
    "    print(f\"{i}. Same model: {score_gpt4o}, Different model: {score_claude}\")\n",
    "\n",
    "# Calculate bias\n",
    "avg_score_same = np.mean([r['score_same_model'] for r in self_bias_results])\n",
    "avg_score_diff = np.mean([r['score_different_model'] for r in self_bias_results])\n",
    "bias_magnitude = avg_score_same - avg_score_diff\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"SELF-PREFERENCE BIAS RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Average score (same model):      {avg_score_same:.3f}\")\n",
    "print(f\"Average score (different model): {avg_score_diff:.3f}\")\n",
    "print(f\"Bias magnitude:                  {bias_magnitude:.3f}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if abs(bias_magnitude) > 0.1:\n",
    "    print(f\"âš ï¸  BIAS DETECTED: Judge shows preference of {abs(bias_magnitude):.1%}\")\n",
    "else:\n",
    "    print(f\"âœ… NO SIGNIFICANT BIAS: Judge is relatively unbiased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Type 2: Position Bias\n",
    "\n",
    "**Definition**: Judges favor the first or second position in A/B comparisons.\n",
    "\n",
    "**Detection Method**: Present same pair in both orders (A vs B, then B vs A) and measure consistency.\n",
    "\n",
    "**Expected Behavior**: Judge should give same verdict regardless of position order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data for position bias\n",
    "comparison_pairs = [\n",
    "    {\n",
    "        \"query\": \"How do I make perfect rice?\",\n",
    "        \"response_a\": \"Use 2:1 water to rice ratio. Bring to boil, then simmer covered for 18 minutes.\",\n",
    "        \"response_b\": \"Rinse rice, use 1.5:1 water ratio, cook for 15 minutes, let rest 5 minutes.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the best way to poach eggs?\",\n",
    "        \"response_a\": \"Bring water to gentle simmer, add vinegar, create whirlpool, add egg, cook 3-4 minutes.\",\n",
    "        \"response_b\": \"Boil water with vinegar, crack egg into cup, slide into water, cook 3 minutes.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How to make crispy bacon?\",\n",
    "        \"response_a\": \"Bake at 400F for 15-20 minutes on a wire rack over a baking sheet.\",\n",
    "        \"response_b\": \"Cook in skillet over medium heat, flipping every 2 minutes until crispy.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the secret to moist cake?\",\n",
    "        \"response_a\": \"Don't overmix batter, use room temperature ingredients, don't overbake.\",\n",
    "        \"response_b\": \"Add sour cream or yogurt to batter, and brush with simple syrup after baking.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How to properly caramelize onions?\",\n",
    "        \"response_a\": \"Cook over low heat for 30-40 minutes, stirring occasionally.\",\n",
    "        \"response_b\": \"Slice thinly, cook over medium-low heat for 45 minutes with butter and salt.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the best method for hard-boiled eggs?\",\n",
    "        \"response_a\": \"Boil for 10 minutes, then immediately transfer to ice bath.\",\n",
    "        \"response_b\": \"Steam for 12 minutes, cool in ice water for easy peeling.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How to make fluffy mashed potatoes?\",\n",
    "        \"response_a\": \"Use Yukon Gold potatoes, mash with butter and warm milk.\",\n",
    "        \"response_b\": \"Boil russet potatoes, rice them, fold in cream and melted butter.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the ideal way to grill chicken?\",\n",
    "        \"response_a\": \"Marinate for 2 hours, grill over medium-high heat for 6-7 minutes per side.\",\n",
    "        \"response_b\": \"Brine for 30 minutes, grill at 400F for 12-15 minutes total.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How to make perfect guacamole?\",\n",
    "        \"response_a\": \"Mash avocados with lime juice, add diced tomatoes, onion, cilantro, and salt.\",\n",
    "        \"response_b\": \"Roughly mash avocados, mix in lime, jalapeÃ±o, cilantro, and salt to taste.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the best way to store fresh herbs?\",\n",
    "        \"response_a\": \"Trim stems, place in water like flowers, cover loosely with plastic bag.\",\n",
    "        \"response_b\": \"Wrap in damp paper towel, store in sealed container in refrigerator.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "comparison_pairs = comparison_pairs[:NUM_COMPARISONS]\n",
    "\n",
    "# Create pairwise comparison judge\n",
    "def compare_responses(query: str, response_a: str, response_b: str) -> str:\n",
    "    \"\"\"Compare two responses and return which is better (A or B).\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are evaluating recipe responses for helpfulness.\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Response A: {response_a}\n",
    "\n",
    "Response B: {response_b}\n",
    "\n",
    "Which response is MORE helpful and complete? Respond with JSON:\n",
    "{{\n",
    "    \"winner\": \"A\" or \"B\",\n",
    "    \"reasoning\": \"Brief explanation\"\n",
    "}}\n",
    "\"\"\"\n",
    "    \n",
    "    response = litellm.completion(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.0\n",
    "    )\n",
    "    \n",
    "    content = response.choices[0].message.content\n",
    "    \n",
    "    # Parse JSON\n",
    "    if \"```json\" in content:\n",
    "        json_start = content.find(\"```json\") + 7\n",
    "        json_end = content.find(\"```\", json_start)\n",
    "        json_text = content[json_start:json_end].strip()\n",
    "    elif \"{\" in content:\n",
    "        json_start = content.find(\"{\")\n",
    "        json_end = content.rfind(\"}\") + 1\n",
    "        json_text = content[json_start:json_end]\n",
    "    else:\n",
    "        json_text = content\n",
    "    \n",
    "    result = json.loads(json_text)\n",
    "    return result[\"winner\"]\n",
    "\n",
    "# Test position bias\n",
    "print(f\"Testing position bias with {len(comparison_pairs)} pairs...\\n\")\n",
    "\n",
    "position_bias_results = []\n",
    "\n",
    "for i, pair in enumerate(comparison_pairs, 1):\n",
    "    # Original order: A vs B\n",
    "    winner_ab = compare_responses(pair['query'], pair['response_a'], pair['response_b'])\n",
    "    \n",
    "    # Swapped order: B vs A\n",
    "    winner_ba = compare_responses(pair['query'], pair['response_b'], pair['response_a'])\n",
    "    \n",
    "    # Convert to consistent scoring (1 = A wins, 0 = B wins)\n",
    "    score_ab = 1 if winner_ab == \"A\" else 0\n",
    "    score_ba = 1 if winner_ba == \"B\" else 0  # Note: B is now in position A\n",
    "    \n",
    "    consistent = (score_ab == score_ba)\n",
    "    \n",
    "    position_bias_results.append({\n",
    "        \"query\": pair['query'],\n",
    "        \"winner_ab\": winner_ab,\n",
    "        \"winner_ba\": winner_ba,\n",
    "        \"consistent\": consistent\n",
    "    })\n",
    "    \n",
    "    print(f\"{i}. A vs B: {winner_ab} wins | B vs A: {winner_ba} wins | Consistent: {consistent}\")\n",
    "\n",
    "# Calculate bias\n",
    "consistency_rate = np.mean([r['consistent'] for r in position_bias_results])\n",
    "first_position_wins = np.mean([r['winner_ab'] == 'A' for r in position_bias_results])\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"POSITION BIAS RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Consistency rate:          {consistency_rate:.1%}\")\n",
    "print(f\"First position win rate:   {first_position_wins:.1%}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if consistency_rate < 0.8:\n",
    "    print(f\"âš ï¸  POSITION BIAS DETECTED: Only {consistency_rate:.0%} consistency\")\n",
    "else:\n",
    "    print(f\"âœ… NO SIGNIFICANT BIAS: High consistency ({consistency_rate:.0%})\")\n",
    "\n",
    "if abs(first_position_wins - 0.5) > 0.2:\n",
    "    print(f\"âš ï¸  FIRST-POSITION BIAS: {first_position_wins:.0%} of first-position responses win\")\n",
    "else:\n",
    "    print(f\"âœ… BALANCED: First position wins ~50% of the time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Type 3: Verbosity Bias\n",
    "\n",
    "**Definition**: Judges favor longer responses regardless of quality.\n",
    "\n",
    "**Detection Method**: Correlate response length with judge scores.\n",
    "\n",
    "**Expected Behavior**: Response length should not correlate with quality scores when content quality is controlled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data for verbosity bias (varying lengths with similar quality)\n",
    "verbosity_test_data = [\n",
    "    {\n",
    "        \"query\": \"How do I make scrambled eggs?\",\n",
    "        \"response\": \"Beat eggs. Cook in butter. Stir until set.\",\n",
    "        \"length\": 41\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How do I make scrambled eggs?\",\n",
    "        \"response\": \"Beat eggs with a splash of milk. Pour into a hot buttered pan. Stir gently over medium heat until just set.\",\n",
    "        \"length\": 115\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How do I make scrambled eggs?\",\n",
    "        \"response\": \"To make perfect scrambled eggs, start by cracking your eggs into a bowl and whisking them thoroughly with a small splash of milk or cream. Heat a non-stick pan over medium heat and add a tablespoon of butter. Once the butter is melted and foaming, pour in your egg mixture. Using a silicone spatula, gently push the eggs from the edges toward the center, allowing the uncooked eggs to flow to the edges. Continue this process, stirring gently and slowly, until the eggs are just set but still slightly creamy. Remove from heat immediately and season with salt and pepper to taste.\",\n",
    "        \"length\": 569\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What temperature to bake cookies?\",\n",
    "        \"response\": \"350F for 12 minutes.\",\n",
    "        \"length\": 22\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What temperature to bake cookies?\",\n",
    "        \"response\": \"Bake at 350 degrees Fahrenheit for 10-12 minutes until edges are golden brown.\",\n",
    "        \"length\": 81\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What temperature to bake cookies?\",\n",
    "        \"response\": \"For optimal chocolate chip cookie results, preheat your oven to 350 degrees Fahrenheit (175 degrees Celsius). This moderate temperature allows the cookies to bake evenly, with the edges becoming golden and slightly crispy while the centers remain soft and chewy. Baking time typically ranges from 10 to 12 minutes, depending on your oven and cookie size. Watch for visual cues: the edges should be set and lightly golden, while the centers may still look slightly underdone. Remember, cookies continue cooking on the hot baking sheet even after removal from the oven, so don't overbake!\",\n",
    "        \"length\": 549\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How long to boil pasta?\",\n",
    "        \"response\": \"8-10 minutes for al dente.\",\n",
    "        \"length\": 26\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How long to boil pasta?\",\n",
    "        \"response\": \"Boil pasta for 8-10 minutes for al dente texture, or follow the package directions.\",\n",
    "        \"length\": 84\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How long to boil pasta?\",\n",
    "        \"response\": \"The cooking time for pasta depends on the type and shape, but as a general guideline, most dried pasta should be boiled for 8-10 minutes to achieve the ideal al dente texture. Al dente means the pasta is cooked through but still has a slight firmness when bitten. To cook pasta properly, bring a large pot of salted water to a rolling boil, add the pasta, and stir occasionally to prevent sticking. Start testing the pasta a minute or two before the package's suggested cooking time by removing a piece and biting into it. The pasta should be tender but still offer a bit of resistance. Remember that pasta continues to cook slightly after draining, so it's better to err on the side of slightly underdone if you're adding it to a sauce.\",\n",
    "        \"length\": 679\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How to store fresh basil?\",\n",
    "        \"response\": \"Trim stems, place in water, refrigerate.\",\n",
    "        \"length\": 42\n",
    "    }\n",
    "]\n",
    "\n",
    "verbosity_test_data = verbosity_test_data[:NUM_COMPARISONS]\n",
    "\n",
    "# Evaluate all responses\n",
    "print(f\"Testing verbosity bias with {len(verbosity_test_data)} responses...\\n\")\n",
    "\n",
    "verbosity_bias_results = []\n",
    "\n",
    "for i, example in enumerate(verbosity_test_data, 1):\n",
    "    result = judge_gpt4o.evaluate(query=example['query'], response=example['response'])\n",
    "    score = 1 if result.score == \"PASS\" else 0\n",
    "    \n",
    "    verbosity_bias_results.append({\n",
    "        \"query\": example['query'],\n",
    "        \"length\": example['length'],\n",
    "        \"score\": score\n",
    "    })\n",
    "    \n",
    "    print(f\"{i}. Length: {example['length']:3d} chars | Score: {score}\")\n",
    "\n",
    "# Calculate correlation\n",
    "lengths = [r['length'] for r in verbosity_bias_results]\n",
    "scores = [r['score'] for r in verbosity_bias_results]\n",
    "\n",
    "if len(set(scores)) > 1:  # Only calculate if there's variance in scores\n",
    "    correlation, p_value = stats.pearsonr(lengths, scores)\n",
    "else:\n",
    "    correlation = 0.0\n",
    "    p_value = 1.0\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"VERBOSITY BIAS RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Correlation (length vs score): {correlation:.3f}\")\n",
    "print(f\"P-value:                       {p_value:.3f}\")\n",
    "print(f\"Average length:                {np.mean(lengths):.0f} chars\")\n",
    "print(f\"Average score:                 {np.mean(scores):.3f}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if correlation > 0.4 and p_value < 0.05:\n",
    "    print(f\"âš ï¸  VERBOSITY BIAS DETECTED: Strong positive correlation ({correlation:.2f})\")\n",
    "elif correlation > 0.3:\n",
    "    print(f\"âš ï¸  MODERATE VERBOSITY BIAS: Correlation = {correlation:.2f}\")\n",
    "else:\n",
    "    print(f\"âœ… NO SIGNIFICANT BIAS: Low correlation ({correlation:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Bias Patterns\n",
    "\n",
    "Let's create visualizations for all three bias types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3-panel visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Panel 1: Self-Preference Bias\n",
    "ax1 = axes[0]\n",
    "categories = ['Same Model', 'Different Model']\n",
    "scores = [avg_score_same, avg_score_diff]\n",
    "colors = ['#ff6b6b' if avg_score_same > avg_score_diff else '#51cf66', '#4dabf7']\n",
    "ax1.bar(categories, scores, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax1.set_ylabel('Average Score', fontsize=12)\n",
    "ax1.set_title(f'Self-Preference Bias\\nBias: {bias_magnitude:+.3f}', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylim([0, 1.1])\n",
    "ax1.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "for i, v in enumerate(scores):\n",
    "    ax1.text(i, v + 0.05, f'{v:.2f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Panel 2: Position Bias\n",
    "ax2 = axes[1]\n",
    "categories = ['Consistent', 'Inconsistent']\n",
    "counts = [\n",
    "    sum(r['consistent'] for r in position_bias_results),\n",
    "    sum(not r['consistent'] for r in position_bias_results)\n",
    "]\n",
    "colors = ['#51cf66' if consistency_rate >= 0.8 else '#ff6b6b', '#ffa94d']\n",
    "ax2.bar(categories, counts, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax2.set_ylabel('Number of Comparisons', fontsize=12)\n",
    "ax2.set_title(f'Position Bias\\nConsistency: {consistency_rate:.1%}', fontsize=14, fontweight='bold')\n",
    "for i, v in enumerate(counts):\n",
    "    ax2.text(i, v + 0.2, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Panel 3: Verbosity Bias\n",
    "ax3 = axes[2]\n",
    "ax3.scatter(lengths, scores, alpha=0.6, s=100, c=scores, cmap='RdYlGn', edgecolors='black')\n",
    "ax3.set_xlabel('Response Length (characters)', fontsize=12)\n",
    "ax3.set_ylabel('Judge Score', fontsize=12)\n",
    "ax3.set_title(f'Verbosity Bias\\nCorrelation: {correlation:.3f}', fontsize=14, fontweight='bold')\n",
    "ax3.set_ylim([-0.1, 1.1])\n",
    "\n",
    "# Add trend line if significant correlation\n",
    "if abs(correlation) > 0.3:\n",
    "    z = np.polyfit(lengths, scores, 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax3.plot(lengths, p(lengths), \"r--\", alpha=0.8, linewidth=2, label=f'Trend (r={correlation:.2f})')\n",
    "    ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('lesson-10/diagrams/bias_detection_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Bias visualization saved to lesson-10/diagrams/bias_detection_results.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigation Strategies\n",
    "\n",
    "### How to Address Detected Biases\n",
    "\n",
    "#### Self-Preference Bias\n",
    "- âœ… **Use different model for judging**: Don't use GPT-4o to judge GPT-4o outputs\n",
    "- âœ… **Blind evaluation**: Don't mention which model generated the response\n",
    "- âœ… **Cross-validation**: Use multiple judges from different model families\n",
    "\n",
    "#### Position Bias\n",
    "- âœ… **Position swapping**: Always evaluate both orders (A vs B, B vs A) and aggregate\n",
    "- âœ… **Randomize presentation**: Shuffle positions randomly for each comparison\n",
    "- âœ… **Use absolute judgments**: Judge responses independently, not comparatively\n",
    "\n",
    "#### Verbosity Bias\n",
    "- âœ… **Length normalization**: Explicitly instruct judge to ignore length\n",
    "- âœ… **Truncation testing**: Test with truncated versions to see if scores change\n",
    "- âœ… **Prompt modification**: Add instruction like \"Favor concise answers over verbose ones\"\n",
    "\n",
    "### Production Checklist\n",
    "\n",
    "Before deploying judges in production:\n",
    "\n",
    "- [ ] Test for self-preference bias with 20+ examples\n",
    "- [ ] Test for position bias with 20+ pairs (evaluate both orders)\n",
    "- [ ] Test for verbosity bias with length-controlled examples\n",
    "- [ ] Measure consistency: Run same input multiple times\n",
    "- [ ] Validate against ground truth: 50+ labeled examples\n",
    "- [ ] Document bias detection results in evaluation report\n",
    "- [ ] Implement mitigation strategies for detected biases\n",
    "- [ ] Monitor bias metrics over time (track in production)\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Biases are common**: Most judges exhibit some form of bias\n",
    "2. **Detection is critical**: Don't assume your judge is unbiased\n",
    "3. **Mitigation is possible**: Simple techniques (position swapping, blind evaluation) are effective\n",
    "4. **Monitor continuously**: Biases can change as models are updated\n",
    "5. **Document everything**: Keep records of bias tests for reproducibility\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Production Deployment**: Apply mitigation strategies to your judges\n",
    "- **Continuous Monitoring**: Set up automated bias detection in production\n",
    "- **Ensemble Judges**: Use multiple judges and aggregate their decisions\n",
    "- **Human Validation**: Periodically validate judge decisions with human reviewers\n",
    "\n",
    "ðŸ‘‰ Continue to: [Lesson 11 - Comparative Evaluation & Leaderboards](../lesson-11/TUTORIAL_INDEX.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
